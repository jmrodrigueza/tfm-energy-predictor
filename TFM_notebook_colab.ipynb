{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKi3Y5S9bF-E",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735052005529,
     "user_tz": -60,
     "elapsed": 26838,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     }
    },
    "outputId": "cc328cee-9efd-41d4-9625-f95061d552e1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "env: BASE_PATH_TFM=/content/drive/Othercomputers/Mi portátil/_google_drive-tfm-energy-predictor\n",
      "env: TF_ENABLE_ONEDNN_OPTS=0\n",
      "Collecting pysolar\n",
      "  Downloading pysolar-0.11-py3-none-any.whl.metadata (331 bytes)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pysolar) (1.26.4)\n",
      "Downloading pysolar-0.11-py3-none-any.whl (47 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.1/47.1 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: pysolar\n",
      "Successfully installed pysolar-0.11\n",
      "total 1403\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 AEMET-data\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 common\n",
      "-rw------- 1 root root    1003 Dec 19 18:58 Dockerfile\n",
      "-rw------- 1 root root   25157 Dec 24 12:33 energy_base_predictor.py\n",
      "-rw------- 1 root root    3086 Dec 24 12:33 energy_demand_predictor.py\n",
      "-rw------- 1 root root    3571 Dec 24 12:33 energy_emission_predictor.py\n",
      "-rw------- 1 root root    3978 Dec 24 12:33 energy_gen_predictor.py\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 energy_meteo_files\n",
      "-rw------- 1 root root    2196 Dec 24 12:33 energy_sim_emi_predictor.py\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 EUMESAT-data\n",
      "-rw------- 1 root root     523 Dec 19 18:03 httpd.conf\n",
      "-rw------- 1 root root    8840 Dec 24 12:33 meteo_energy_databuilder.py\n",
      "-rw------- 1 root root   17062 Dec  7 16:09 observation_data_builder.py\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 output_figures\n",
      "drwx------ 2 root root    4096 Dec 23 11:06 __pycache__\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 REE-data\n",
      "-rw------- 1 root root     297 Dec 16 09:26 requirements.txt\n",
      "drwx------ 2 root root    4096 Dec 23 15:41 tfm-energy-predictor\n",
      "drwx------ 2 root root    4096 Dec 22 14:00 tfm-energy-predictor-backend\n",
      "drwx------ 2 root root    4096 Dec 22 14:02 tfm-energy-predictor-web\n",
      "-rw------- 1 root root 1307857 Dec 24 14:53 TFM_notebook_colab.ipynb\n",
      "drwx------ 2 root root    4096 Dec 22 14:02 trained_models\n",
      "-rw------- 1 root root   14444 Dec 24 12:33 train_models.py\n",
      "PRETTY_NAME=\"Ubuntu 22.04.3 LTS\"\n",
      "NAME=\"Ubuntu\"\n",
      "VERSION_ID=\"22.04\"\n",
      "VERSION=\"22.04.3 LTS (Jammy Jellyfish)\"\n",
      "VERSION_CODENAME=jammy\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "UBUNTU_CODENAME=jammy\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%matplotlib inline\n",
    "%env BASE_PATH_TFM=/content/drive/Othercomputers/Mi portátil/_google_drive-tfm-energy-predictor\n",
    "%env TF_ENABLE_ONEDNN_OPTS=0\n",
    "\n",
    "!python -m pip install pysolar\n",
    "!ls -l \"${BASE_PATH_TFM}\"\n",
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358585,
     "status": "ok",
     "timestamp": 1733087082604,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     },
     "user_tz": -60
    },
    "id": "Qx85xkp-T6nJ",
    "outputId": "b309c5f7-19d2-440e-f1ca-ffd599f59f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
      "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n",
      "Fetched 19.5 MB in 4s (4,391 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libnvinfer-dispatch10 libnvinfer-headers-dev libnvinfer-lean10 libnvinfer-plugin10\n",
      "  libnvinfer-vc-plugin10 libnvinfer10 libnvonnxparsers10\n",
      "The following NEW packages will be installed:\n",
      "  libnvinfer-bin libnvinfer-dev libnvinfer-dispatch10 libnvinfer-headers-dev libnvinfer-lean10\n",
      "  libnvinfer-plugin10 libnvinfer-plugin8 libnvinfer-vc-plugin10 libnvinfer10 libnvinfer8\n",
      "  libnvonnxparsers10 libnvonnxparsers8 libnvparsers8\n",
      "0 upgraded, 13 newly installed, 0 to remove and 57 not upgraded.\n",
      "Need to get 3,009 MB of archives.\n",
      "After this operation, 7,780 MB of additional disk space will be used.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer10 10.6.0.26-1+cuda12.6 [1,239 MB]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-lean10 10.6.0.26-1+cuda12.6 [8,229 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin10 10.6.0.26-1+cuda12.6 [9,490 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-vc-plugin10 10.6.0.26-1+cuda12.6 [223 kB]\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dispatch10 10.6.0.26-1+cuda12.6 [211 kB]\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers10 10.6.0.26-1+cuda12.6 [1,327 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-bin 10.6.0.26-1+cuda12.6 [454 kB]\n",
      "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-dev 10.6.0.26-1+cuda12.6 [105 kB]\n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dev 10.6.0.26-1+cuda12.6 [1,245 MB]\n",
      "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer8 8.6.1.6-1+cuda12.0 [492 MB]\n",
      "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin8 8.6.1.6-1+cuda12.0 [11.7 MB]\n",
      "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers8 8.6.1.6-1+cuda12.0 [711 kB]\n",
      "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvparsers8 8.6.1.6-1+cuda12.0 [804 kB]\n",
      "Fetched 3,009 MB in 38s (78.7 MB/s)\n",
      "Selecting previously unselected package libnvinfer10.\n",
      "(Reading database ... 123630 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libnvinfer10_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer10 (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-lean10.\n",
      "Preparing to unpack .../01-libnvinfer-lean10_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-lean10 (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-plugin10.\n",
      "Preparing to unpack .../02-libnvinfer-plugin10_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-plugin10 (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-vc-plugin10.\n",
      "Preparing to unpack .../03-libnvinfer-vc-plugin10_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-vc-plugin10 (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-dispatch10.\n",
      "Preparing to unpack .../04-libnvinfer-dispatch10_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-dispatch10 (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvonnxparsers10.\n",
      "Preparing to unpack .../05-libnvonnxparsers10_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvonnxparsers10 (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-bin.\n",
      "Preparing to unpack .../06-libnvinfer-bin_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-bin (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-headers-dev.\n",
      "Preparing to unpack .../07-libnvinfer-headers-dev_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-headers-dev (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer-dev.\n",
      "Preparing to unpack .../08-libnvinfer-dev_10.6.0.26-1+cuda12.6_amd64.deb ...\n",
      "Unpacking libnvinfer-dev (10.6.0.26-1+cuda12.6) ...\n",
      "Selecting previously unselected package libnvinfer8.\n",
      "Preparing to unpack .../09-libnvinfer8_8.6.1.6-1+cuda12.0_amd64.deb ...\n",
      "Unpacking libnvinfer8 (8.6.1.6-1+cuda12.0) ...\n",
      "Selecting previously unselected package libnvinfer-plugin8.\n",
      "Preparing to unpack .../10-libnvinfer-plugin8_8.6.1.6-1+cuda12.0_amd64.deb ...\n",
      "Unpacking libnvinfer-plugin8 (8.6.1.6-1+cuda12.0) ...\n",
      "Selecting previously unselected package libnvonnxparsers8.\n",
      "Preparing to unpack .../11-libnvonnxparsers8_8.6.1.6-1+cuda12.0_amd64.deb ...\n",
      "Unpacking libnvonnxparsers8 (8.6.1.6-1+cuda12.0) ...\n",
      "Selecting previously unselected package libnvparsers8.\n",
      "Preparing to unpack .../12-libnvparsers8_8.6.1.6-1+cuda12.0_amd64.deb ...\n",
      "Unpacking libnvparsers8 (8.6.1.6-1+cuda12.0) ...\n",
      "Setting up libnvinfer-headers-dev (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer10 (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer-plugin10 (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer-vc-plugin10 (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvonnxparsers10 (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer-dispatch10 (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer-dev (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer-lean10 (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvinfer8 (8.6.1.6-1+cuda12.0) ...\n",
      "Setting up libnvparsers8 (8.6.1.6-1+cuda12.0) ...\n",
      "Setting up libnvinfer-plugin8 (8.6.1.6-1+cuda12.0) ...\n",
      "Setting up libnvinfer-bin (10.6.0.26-1+cuda12.6) ...\n",
      "Setting up libnvonnxparsers8 (8.6.1.6-1+cuda12.0) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    libnvinfer8 libnvinfer-plugin8 libnvonnxparsers8 libnvparsers8 \\\n",
    "    libnvinfer-bin libnvinfer-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHMGrlEHVFsx",
    "outputId": "04c382cb-7aa5-486b-e2a1-ebdbbd02cc4a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1734886958029,
     "user_tz": -60,
     "elapsed": 1935585,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001B[0m\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m7s\u001B[0m 41ms/step - loss: 0.3351 - mae: 0.4038/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 41ms/step - loss: 0.3319 - mae: 0.3983\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2393 - mae: 0.3180\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1763 - mae: 0.2641\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1727 - mae: 0.2682\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1480 - mae: 0.2490\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1503 - mae: 0.2477\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1460 - mae: 0.24552024-12-22 16:46:54.662127: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:46:54.662207: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:46:54.662293: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1477 - mae: 0.2447\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.1326 - mae: 0.2252\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 0.1342 - mae: 0.2245\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.1423 - mae: 0.23752024-12-22 16:46:56.727514: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:46:56.727583: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:46:56.727605: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1426 - mae: 0.2357\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1248 - mae: 0.2181\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1253 - mae: 0.2177\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 262ms/step\n",
      "R^2 score: 0.23423314094543457\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  0016A  nº:  42  of: 75\n",
      "df_x.shape:  (709, 24)  df_y.shape:  (709, 5)\n",
      "df_x.shape:  (178, 24)  df_y.shape:  (178, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     13/Unknown \u001B[1m8s\u001B[0m 41ms/step - loss: 0.3457 - mae: 0.4186W0000 00:00:1734886036.121524    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.122386    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.123137    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.123885    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.124631    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.125420    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.126154    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.126889    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.127626    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.128361    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.129121    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.129872    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.130641    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.131438    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.132188    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.133077    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.142152    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.142887    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.143573    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.144272    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.144960    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.145633    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.146332    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.147018    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.147691    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.148400    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.149080    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.149776    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.150481    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.151173    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.151938    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.156761    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.157505    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.158235    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.159088    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.159866    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.160612    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.161354    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.162067    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.162784    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.169137    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.169987    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.170824    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.171722    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.172620    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.173527    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.174425    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.175266    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.176126    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.205133    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.206094    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.207060    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.207851    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.208596    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.209414    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.210562    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.211784    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.212605    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.220233    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.221113    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.222251    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.223046    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.224039    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.224813    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.225666    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.226542    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.227330    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.228175    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.232886    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.233759    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.237342    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.238100    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.238821    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.239544    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.240281    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.241094    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.241938    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.242939    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.244054    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.247048    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.247975    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.248978    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.249930    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.250804    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.251774    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.252876    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.253828    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886036.254733    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     14/Unknown \u001B[1m8s\u001B[0m 50ms/step - loss: 0.3442 - mae: 0.4149/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 51ms/step - loss: 0.3429 - mae: 0.4117\n",
      "Epoch 2/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2347 - mae: 0.3187\n",
      "Epoch 3/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1856 - mae: 0.28072024-12-22 16:47:17.766787: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:17.766865: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:17.766889: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1896 - mae: 0.2786\n",
      "Epoch 4/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1711 - mae: 0.2660\n",
      "Epoch 5/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1527 - mae: 0.2424\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1547 - mae: 0.2421\n",
      "Epoch 6/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1395 - mae: 0.2355\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1411 - mae: 0.2346\n",
      "Epoch 7/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1384 - mae: 0.2294\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1401 - mae: 0.2286\n",
      "Epoch 8/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1178 - mae: 0.21522024-12-22 16:47:20.611636: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1194 - mae: 0.2152\n",
      "Epoch 9/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1113 - mae: 0.1938\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1140 - mae: 0.1937\n",
      "      1/Unknown \u001B[1m1s\u001B[0m 545ms/stepW0000 00:00:1734886042.229789    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.230626    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.231412    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.232232    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.233094    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.233932    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.234750    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.235507    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.236301    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.241309    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.242065    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.242783    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.243508    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.244289    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.245035    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.245766    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.246464    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.247178    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.255339    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.256079    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.256792    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.257486    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.258200    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.258917    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.259634    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.260342    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.261046    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.261747    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.262456    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.263171    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.263887    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.264629    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.265342    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.266171    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.274205    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.274905    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.275580    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.276285    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.276971    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.277642    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.278331    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.279034    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.279725    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.280415    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.281247    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.281957    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.282653    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.283354    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886042.284114    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 300ms/step\n",
      "R^2 score: 0.04336754232645035\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  0201D  nº:  43  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (196, 24)  df_y.shape:  (196, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 38ms/step - loss: 0.5675 - mae: 0.4590/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - loss: 0.5647 - mae: 0.4561\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.4092 - mae: 0.3598\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.4001 - mae: 0.36292024-12-22 16:47:38.140100: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:38.140168: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:38.140190: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.4008 - mae: 0.3603\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.3452 - mae: 0.3074\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.3024 - mae: 0.28202024-12-22 16:47:39.448970: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:39.449044: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:39.449145: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 0.3036 - mae: 0.2811\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2910 - mae: 0.2638\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.2978 - mae: 0.27832024-12-22 16:47:40.878785: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:40.878852: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:40.878876: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.2985 - mae: 0.2768\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 0.2894 - mae: 0.26752024-12-22 16:47:41.761790: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:41.761844: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:41.761948: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 0.2915 - mae: 0.2661\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.2798 - mae: 0.26592024-12-22 16:47:42.979259: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:42.979327: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:42.979412: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 9: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.2819 - mae: 0.2633\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.2654 - mae: 0.24612024-12-22 16:47:43.822092: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:43.822156: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:43.822184: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 10: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.2682 - mae: 0.2444\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 0.2608 - mae: 0.24992024-12-22 16:47:44.770527: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:47:44.770595: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:47:44.770693: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 11: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 0.2637 - mae: 0.2472\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.2580 - mae: 0.2439\n",
      "Epoch 12: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.2604 - mae: 0.2410\n",
      "Epoch 13/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.2432 - mae: 0.2283\n",
      "Epoch 13: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 0.2467 - mae: 0.2265\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 179ms/step\n",
      "R^2 score: 0.10096754133701324\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  0244X  nº:  44  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (196, 24)  df_y.shape:  (196, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m8s\u001B[0m 39ms/step - loss: 0.4732 - mae: 0.4373/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - loss: 0.4713 - mae: 0.4327\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.4041 - mae: 0.3992\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3186 - mae: 0.3515\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2486 - mae: 0.2813\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2239 - mae: 0.2809\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1857 - mae: 0.2546\n",
      "Epoch 6: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1885 - mae: 0.2527\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1738 - mae: 0.2485\n",
      "Epoch 7: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1759 - mae: 0.2466\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1912 - mae: 0.2536\n",
      "Epoch 8: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1936 - mae: 0.2505\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2113 - mae: 0.2572\n",
      "Epoch 9: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2145 - mae: 0.2541\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2113 - mae: 0.2472\n",
      "Epoch 10: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2161 - mae: 0.2468\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 187ms/step\n",
      "R^2 score: 0.29182130098342896\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  0367  nº:  45  of: 75\n",
      "df_x.shape:  (778, 24)  df_y.shape:  (778, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m6s\u001B[0m 39ms/step - loss: 0.4132 - mae: 0.4358W0000 00:00:1734886104.571965    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.572821    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.573569    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.574342    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.575087    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.575827    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.576555    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.577294    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.578026    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.578779    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.579507    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.580317    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.581130    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.581938    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.582877    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.583733    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.588422    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.589265    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.590068    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.590814    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.591568    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.592432    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.593179    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.593981    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.594780    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.603095    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.603824    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.604500    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.605179    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.605849    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.606517    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.607187    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.607854    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.608528    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.609201    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.609859    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.610518    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.611196    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.611869    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.612604    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.617182    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.617921    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.618647    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.619335    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.620044    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.620788    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.621461    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.622160    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.622882    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.640191    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.640938    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.641804    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.642490    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.643166    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.643857    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.644606    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.645305    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.645987    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.649439    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.650145    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.650907    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.651583    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.652312    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.653010    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.653714    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.654401    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.655072    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.655762    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.658241    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.658943    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.661222    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.661905    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.662559    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.663220    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.663871    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.664537    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.665230    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.665947    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.666708    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.668743    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.669474    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.670206    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.670916    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.671604    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.672320    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.673079    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.673792    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886104.674484    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 45ms/step - loss: 0.4111 - mae: 0.4318/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 46ms/step - loss: 0.4093 - mae: 0.4282\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 0.2664 - mae: 0.3170\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.2110 - mae: 0.27852024-12-22 16:48:26.072332: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:48:26.072403: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:48:26.072486: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 0.2151 - mae: 0.2764\n",
      "Epoch 4/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 0.1968 - mae: 0.27032024-12-22 16:48:26.940027: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:48:26.940104: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:48:26.940188: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 4: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.2007 - mae: 0.2677\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 0.1593 - mae: 0.2286\n",
      "Epoch 5: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.1645 - mae: 0.2276\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 0.1676 - mae: 0.2359\n",
      "Epoch 6: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 52ms/step - loss: 0.1698 - mae: 0.2353\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1620 - mae: 0.22162024-12-22 16:48:29.935799: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:48:29.935859: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:48:29.935885: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.1647 - mae: 0.2212\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1528 - mae: 0.2221\n",
      "Epoch 8: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1571 - mae: 0.2208\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 180ms/step\n",
      "R^2 score: 0.3445109724998474\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  9677  nº:  46  of: 75\n",
      "df_x.shape:  (778, 24)  df_y.shape:  (778, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m8s\u001B[0m 38ms/step - loss: 55.8254 - mae: 1.5869/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - loss: 55.2542 - mae: 1.5994\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 35.4101 - mae: 1.4447\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 25.0632 - mae: 1.1803\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 13.8523 - mae: 0.94502024-12-22 16:48:50.378650: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:48:50.378733: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 12123069749933752713\n",
      "2024-12-22 16:48:50.378755: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:48:50.378774: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 14.0645 - mae: 0.9507\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 12.3180 - mae: 0.8905\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 13.4446 - mae: 0.9489\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 11.8858 - mae: 0.9669\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 10.6407 - mae: 0.8723\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 8.4568 - mae: 0.83562024-12-22 16:48:53.403652: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:48:53.403728: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:48:53.403755: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 8.7323 - mae: 0.8422\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 7.3377 - mae: 0.7810\n",
      "Epoch 11/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 7.3083 - mae: 0.7764\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 9.6995 - mae: 0.81682024-12-22 16:48:55.179998: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 9.8797 - mae: 0.8254\n",
      "Epoch 13/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 11.7639 - mae: 0.8587\n",
      "Epoch 14/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 9.5719 - mae: 0.84442024-12-22 16:48:56.700550: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:48:56.700612: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:48:56.700684: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 10.0219 - mae: 0.8588\n",
      "Epoch 15/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 12.0539 - mae: 0.8788\n",
      "Epoch 16/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 25.3120 - mae: 1.1372\n",
      "Epoch 17/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 23.2499 - mae: 0.98682024-12-22 16:49:00.122788: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:00.122852: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:00.122875: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 52ms/step - loss: 22.4737 - mae: 0.9843\n",
      "Epoch 18/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 12.4901 - mae: 0.8541\n",
      "Epoch 19/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 7.5842 - mae: 0.8185\n",
      "Epoch 20/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 6.2037 - mae: 0.7964\n",
      "Epoch 21/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 8.2447 - mae: 0.7650\n",
      "Epoch 22/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 5.4040 - mae: 0.7103\n",
      "Epoch 23/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 4.3369 - mae: 0.6675\n",
      "Epoch 24/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 6.4476 - mae: 0.7063\n",
      "Epoch 25/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 7.9821 - mae: 0.72752024-12-22 16:49:05.155280: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:05.155352: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:05.155374: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 7.9962 - mae: 0.7278\n",
      "Epoch 26/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 4.8824 - mae: 0.65802024-12-22 16:49:05.757781: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:05.757852: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:05.757876: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 4.9388 - mae: 0.6603\n",
      "Epoch 27/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 5.1559 - mae: 0.6254\n",
      "Epoch 28/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 4.1577 - mae: 0.6382\n",
      "Epoch 29/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 3.1794 - mae: 0.5692\n",
      "Epoch 30/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 4.0000 - mae: 0.5899\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 182ms/step\n",
      "R^2 score: -9.411111831665039\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  9946X  nº:  47  of: 75\n",
      "df_x.shape:  (777, 24)  df_y.shape:  (777, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m7s\u001B[0m 39ms/step - loss: 0.5276 - mae: 0.4229/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 40ms/step - loss: 0.5393 - mae: 0.4174\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.4086 - mae: 0.32262024-12-22 16:49:25.779947: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:25.780012: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:25.780024: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 16:49:25.780045: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.4159 - mae: 0.3214\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.3423 - mae: 0.27562024-12-22 16:49:27.075829: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:27.075887: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:27.075904: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 16:49:27.075923: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.3506 - mae: 0.2754\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 52ms/step - loss: 0.3229 - mae: 0.2515\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.3129 - mae: 0.2414\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.3432 - mae: 0.2709\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2804 - mae: 0.2641\n",
      "Epoch 7: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2925 - mae: 0.2624\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2547 - mae: 0.2440\n",
      "Epoch 8: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2657 - mae: 0.2442\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2244 - mae: 0.2285\n",
      "Epoch 9: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2370 - mae: 0.2293\n",
      "Epoch 10/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.2295 - mae: 0.2406\n",
      "Epoch 10: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2451 - mae: 0.2391\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2212 - mae: 0.2277\n",
      "Epoch 11: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2351 - mae: 0.2290\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 179ms/step\n",
      "R^2 score: 0.24047355353832245\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  8025  nº:  48  of: 75\n",
      "df_x.shape:  (773, 24)  df_y.shape:  (773, 5)\n",
      "df_x.shape:  (194, 24)  df_y.shape:  (194, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     14/Unknown \u001B[1m7s\u001B[0m 42ms/step - loss: 0.2743 - mae: 0.3774W0000 00:00:1734886189.309087    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.309999    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.310812    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.311848    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.312783    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.313667    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.314420    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.315226    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.316027    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.321045    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.321800    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.322530    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.323225    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.323945    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.324716    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.325379    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.326110    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.326842    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.336431    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.337148    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.337835    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.338526    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.339224    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.339910    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.340589    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.341303    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.342011    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.342728    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.343408    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.344071    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.344740    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.345426    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.346130    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.346955    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.355088    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.355794    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.356461    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.357141    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.357805    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.358461    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.359126    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.359782    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.360445    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.361120    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.361773    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.362413    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.363078    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.363783    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.364637    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.381393    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.382098    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.382787    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.383449    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.384101    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.384775    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.385470    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.386136    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.386785    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.388933    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.389611    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.390281    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.390943    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.391607    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.392274    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.392958    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.393610    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.394320    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.396458    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.397138    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.397782    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.398431    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.399069    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.399733    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.400391    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.401073    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.401780    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.403861    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.404557    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.405251    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.405932    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.406600    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.407281    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.407996    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.408667    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886189.409330    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 46ms/step - loss: 0.2713 - mae: 0.3742/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 47ms/step - loss: 0.2701 - mae: 0.3729\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2086 - mae: 0.3153\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1768 - mae: 0.2919\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1452 - mae: 0.26202024-12-22 16:49:51.257794: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:51.257883: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:51.257906: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1448 - mae: 0.2613\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1289 - mae: 0.2414\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1288 - mae: 0.2411\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1053 - mae: 0.21752024-12-22 16:49:52.419809: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:52.419881: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:52.419904: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1071 - mae: 0.2188\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1006 - mae: 0.20812024-12-22 16:49:53.030811: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:49:53.030876: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:49:53.030900: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1024 - mae: 0.2085\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.1025 - mae: 0.2024\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.1027 - mae: 0.2024\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.0893 - mae: 0.1947\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.0909 - mae: 0.1948\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 261ms/step\n",
      "R^2 score: 0.46548527479171753\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  8036Y  nº:  49  of: 75\n",
      "df_x.shape:  (777, 24)  df_y.shape:  (777, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m8s\u001B[0m 38ms/step - loss: 0.3106 - mae: 0.3920/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - loss: 0.3101 - mae: 0.3884\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1928 - mae: 0.29052024-12-22 16:50:15.178094: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:50:15.178153: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:50:15.178233: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1967 - mae: 0.2903\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1749 - mae: 0.2799\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1937 - mae: 0.2914\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1305 - mae: 0.23382024-12-22 16:50:16.950351: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:50:16.950400: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:50:16.950428: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1357 - mae: 0.2344\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1199 - mae: 0.2205\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1241 - mae: 0.2214\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1195 - mae: 0.2282\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1229 - mae: 0.2287\n",
      "Epoch 8/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1160 - mae: 0.2248\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.1210 - mae: 0.2254\n",
      "Epoch 9/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.1080 - mae: 0.2077\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1142 - mae: 0.2087\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 186ms/step\n",
      "R^2 score: 0.2222755402326584\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  8270X  nº:  50  of: 75\n",
      "df_x.shape:  (693, 24)  df_y.shape:  (693, 5)\n",
      "df_x.shape:  (174, 24)  df_y.shape:  (174, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     12/Unknown \u001B[1m7s\u001B[0m 38ms/step - loss: 0.4516 - mae: 0.4326W0000 00:00:1734886235.680156    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.681076    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.681919    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.682790    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.683639    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.684542    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.685357    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.686188    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.687029    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.693406    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.694229    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.695021    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.695746    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.696518    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.697324    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.698066    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.698804    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.699545    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.707783    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.708504    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.709197    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.709892    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.710563    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.711486    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.712168    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.712864    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.713549    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.714247    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.714917    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.715592    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.716304    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.716992    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.717791    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.726601    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.727347    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.728046    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.728762    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.729477    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.730161    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.730921    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.731613    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.732315    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.733024    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.733758    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.734445    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.735149    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.735884    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.736584    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.737366    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.754137    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.754898    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.755749    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.756477    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.757187    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.757926    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.758803    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.759549    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.760283    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.763587    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.764350    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.765250    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.765971    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.766794    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.767498    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.768237    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.768985    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.769687    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.770424    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.773830    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.774608    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.777070    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.777784    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.778443    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.779117    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.779870    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.780583    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.781320    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.782145    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.783032    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.785112    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.785905    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.786740    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.787538    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.788314    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.789117    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.790002    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.790796    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886235.791559    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     14/Unknown \u001B[1m7s\u001B[0m 44ms/step - loss: 0.4612 - mae: 0.4273/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 45ms/step - loss: 0.4661 - mae: 0.4251\n",
      "Epoch 2/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 0.3667 - mae: 0.3502\n",
      "Epoch 3/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2796 - mae: 0.2895\n",
      "Epoch 4/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.2621 - mae: 0.29482024-12-22 16:50:38.205121: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:50:38.205198: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:50:38.205229: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.2754 - mae: 0.2935\n",
      "Epoch 5/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.2432 - mae: 0.2604\n",
      "Epoch 6/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.2311 - mae: 0.2569\n",
      "Epoch 7/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - loss: 0.2105 - mae: 0.2404\n",
      "Epoch 7: metric under threshold (1/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 0.2204 - mae: 0.2406\n",
      "Epoch 8/30\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.2006 - mae: 0.2384\n",
      "Epoch 8: metric under threshold (2/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.2067 - mae: 0.2385\n",
      "Epoch 9/30\n",
      "\u001B[1m12/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1887 - mae: 0.2348\n",
      "Epoch 9: metric under threshold (3/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2063 - mae: 0.2333\n",
      "Epoch 10/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1916 - mae: 0.2483\n",
      "Epoch 10: metric under threshold (4/5).\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2015 - mae: 0.2471\n",
      "Epoch 11/30\n",
      "\u001B[1m13/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1801 - mae: 0.22312024-12-22 16:50:44.421388: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 6547487746809057678\n",
      "2024-12-22 16:50:44.421458: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:50:44.421480: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:50:44.421496: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 16:50:44.421514: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 11: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1895 - mae: 0.2238\n",
      "      1/Unknown \u001B[1m1s\u001B[0m 512ms/stepW0000 00:00:1734886245.598938    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.599785    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.600554    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.601333    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.602153    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.603033    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.603817    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.604573    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.605348    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.613741    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.614493    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.615207    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.615944    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.616645    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.617346    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.618077    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.618779    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.619531    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.620279    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.621021    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.621739    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.622474    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.623328    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.624054    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.632852    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.633564    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.634267    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.634959    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.635650    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.636356    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.637037    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.637725    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.638405    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.639088    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.639805    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.640506    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.641207    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.641954    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.642650    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.643452    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.651127    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.651813    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.652477    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.653153    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.653834    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.654508    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.655171    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.655832    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.656493    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.657183    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.657853    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.658525    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.659216    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.659882    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886245.660592    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 304ms/step\n",
      "R^2 score: -0.08018487691879272\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  8500A  nº:  51  of: 75\n",
      "df_x.shape:  (777, 24)  df_y.shape:  (777, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m8s\u001B[0m 39ms/step - loss: 0.4388 - mae: 0.3876/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - loss: 0.4794 - mae: 0.3875\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.3785 - mae: 0.3210\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.3139 - mae: 0.2810\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2644 - mae: 0.2616\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2733 - mae: 0.25672024-12-22 16:51:03.852476: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:51:03.852553: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:51:03.852642: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3125 - mae: 0.2601\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2346 - mae: 0.2667\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.3237 - mae: 0.2643\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2137 - mae: 0.2320\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1903 - mae: 0.2326\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2464 - mae: 0.2217\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1877 - mae: 0.2189\n",
      "Epoch 11: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 0.2108 - mae: 0.2216\n",
      "Epoch 12/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.1564 - mae: 0.2051\n",
      "Epoch 12: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.1646 - mae: 0.2064\n",
      "Epoch 13/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1397 - mae: 0.1984\n",
      "Epoch 13: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1470 - mae: 0.2000\n",
      "Epoch 14/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.1416 - mae: 0.21112024-12-22 16:51:10.845456: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:51:10.845527: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:51:10.845699: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 14: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.1566 - mae: 0.2135\n",
      "Epoch 15/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.1543 - mae: 0.2082\n",
      "Epoch 15: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.1617 - mae: 0.2091\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 188ms/step\n",
      "R^2 score: 0.26325273513793945\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  3104Y  nº:  52  of: 75\n",
      "df_x.shape:  (608, 24)  df_y.shape:  (608, 5)\n",
      "df_x.shape:  (153, 24)  df_y.shape:  (153, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     11/Unknown \u001B[1m8s\u001B[0m 41ms/step - loss: 0.6982 - mae: 0.5453W0000 00:00:1734886289.123966    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.124949    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.125845    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.126753    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.127665    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.128587    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.129475    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.130358    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.131204    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.136997    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.137971    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.138732    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.139481    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.140265    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.141054    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.141812    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.142575    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.143333    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.153894    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.154659    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.155379    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.156109    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.157048    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.157795    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.158503    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.159226    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.159947    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.160659    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.161517    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.162499    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.163331    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.164179    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.165115    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.166547    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.179569    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.180310    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.181044    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.181761    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.182477    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.183185    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.183948    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.184715    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.185447    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.186180    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.186880    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.187589    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.188323    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.189046    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.189834    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.216396    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.217231    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.218242    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.219081    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.219850    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.220679    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.221966    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.222777    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.223533    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.228495    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.229300    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.230732    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.231533    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.232516    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.233308    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.234122    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.234953    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.235712    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.236521    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.240864    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.241805    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.245262    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.246008    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.246743    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.247462    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.248181    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.248941    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.249765    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.250728    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.251758    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.254676    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.255601    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.256623    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.257531    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.258361    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.259301    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.260312    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.261143    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886289.261979    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     12/Unknown \u001B[1m8s\u001B[0m 52ms/step - loss: 0.6928 - mae: 0.5435/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 53ms/step - loss: 0.6883 - mae: 0.5420\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.7541 - mae: 0.5816\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.5200 - mae: 0.4932\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.3355 - mae: 0.4054\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2752 - mae: 0.3475\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2662 - mae: 0.3488\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2398 - mae: 0.3119\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1974 - mae: 0.2857\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1924 - mae: 0.2802\n",
      "Epoch 10/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1909 - mae: 0.28772024-12-22 16:51:34.462786: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 7587057067284363685\n",
      "2024-12-22 16:51:34.462856: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 9581631076558437551\n",
      "2024-12-22 16:51:34.462874: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14622749425951569513\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1899 - mae: 0.2874\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1920 - mae: 0.2827\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2045 - mae: 0.2978\n",
      "Epoch 13/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1405 - mae: 0.23782024-12-22 16:51:36.221108: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 7587057067284363685\n",
      "2024-12-22 16:51:36.221168: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 9581631076558437551\n",
      "2024-12-22 16:51:36.221190: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14622749425951569513\n",
      "\n",
      "Epoch 13: metric under threshold (1/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.1413 - mae: 0.2393\n",
      "Epoch 14/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1404 - mae: 0.23132024-12-22 16:51:36.669794: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 7587057067284363685\n",
      "2024-12-22 16:51:36.669869: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 9581631076558437551\n",
      "2024-12-22 16:51:36.669970: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14622749425951569513\n",
      "\n",
      "Epoch 14: metric under threshold (2/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1410 - mae: 0.2328\n",
      "Epoch 15/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1255 - mae: 0.22282024-12-22 16:51:37.125969: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14622749425951569513\n",
      "\n",
      "Epoch 15: metric under threshold (3/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1257 - mae: 0.2237\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.1204 - mae: 0.2176\n",
      "Epoch 16: metric under threshold (4/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 0.1209 - mae: 0.2182\n",
      "Epoch 17/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1216 - mae: 0.22332024-12-22 16:51:38.293577: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 7587057067284363685\n",
      "2024-12-22 16:51:38.293638: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 9581631076558437551\n",
      "2024-12-22 16:51:38.293756: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14622749425951569513\n",
      "\n",
      "Epoch 17: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 0.1215 - mae: 0.2236\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 382ms/step\n",
      "R^2 score: -2.899792432785034\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  3266A  nº:  53  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (196, 24)  df_y.shape:  (196, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m8s\u001B[0m 51ms/step - loss: 0.7354 - mae: 0.5238/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 52ms/step - loss: 0.7223 - mae: 0.5186\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.7916 - mae: 0.5589\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.4028 - mae: 0.4248\n",
      "Epoch 4/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2972 - mae: 0.34592024-12-22 16:51:59.280681: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:51:59.280770: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:51:59.280867: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2941 - mae: 0.3422\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2382 - mae: 0.3050\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2216 - mae: 0.2932\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1977 - mae: 0.28132024-12-22 16:52:01.142311: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:52:01.142373: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:52:01.142390: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1964 - mae: 0.2787\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1709 - mae: 0.2566\n",
      "Epoch 8: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1708 - mae: 0.2550\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1782 - mae: 0.2647\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1761 - mae: 0.26442024-12-22 16:52:02.959141: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:52:02.959213: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:52:02.959240: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 10: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1748 - mae: 0.2616\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1646 - mae: 0.2571\n",
      "Epoch 11: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.1641 - mae: 0.2552\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1614 - mae: 0.25052024-12-22 16:52:04.208936: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:52:04.208994: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:52:04.209090: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 12: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1605 - mae: 0.2485\n",
      "Epoch 13/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1828 - mae: 0.2655\n",
      "Epoch 13: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1761 - mae: 0.2581\n",
      "Epoch 14/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1678 - mae: 0.2573\n",
      "Epoch 14: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1660 - mae: 0.2553\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 179ms/step\n",
      "R^2 score: -1422.6422119140625\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  3475X  nº:  54  of: 75\n",
      "df_x.shape:  (625, 24)  df_y.shape:  (625, 5)\n",
      "df_x.shape:  (157, 24)  df_y.shape:  (157, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     11/Unknown \u001B[1m7s\u001B[0m 52ms/step - loss: 0.5636 - mae: 0.4544W0000 00:00:1734886341.997483    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886341.998360    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886341.999149    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.003693    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.004687    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.005519    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.006372    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.007327    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.010601    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.025272    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.026071    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.026827    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.027600    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.030496    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.031296    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.032087    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.032888    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.033669    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.034460    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.035279    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.036081    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.036902    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.038494    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.039331    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.119686    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.140645    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.141503    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.142280    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.143063    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.143833    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.144586    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.145349    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.146114    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.146886    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.147662    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.148426    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.149159    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.149902    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.150685    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.151453    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.152367    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.164791    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.165587    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.166352    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.167105    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.167843    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.168588    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.169344    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.170078    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.170824    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.171581    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.172308    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.173037    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.173774    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.174522    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.175383    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.197313    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.198195    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.198998    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.199746    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.200469    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.201234    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.202022    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.202766    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.203524    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.206464    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.207222    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.207948    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.208672    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.209399    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.210126    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.210855    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.211590    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.212375    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.215374    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.216159    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.216945    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.217749    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.218507    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.219304    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.220092    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.221920    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.222737    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.225626    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.226420    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.227198    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.227970    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.228753    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.229492    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.230247    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.231511    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886342.232266    1733 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     13/Unknown \u001B[1m7s\u001B[0m 69ms/step - loss: 0.5535 - mae: 0.4462/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 72ms/step - loss: 0.5494 - mae: 0.4430\n",
      "Epoch 2/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.4275 - mae: 0.3701\n",
      "Epoch 3/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.3564 - mae: 0.3524\n",
      "Epoch 4/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 0.3302 - mae: 0.3343\n",
      "Epoch 5/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 53ms/step - loss: 0.2676 - mae: 0.2977\n",
      "Epoch 6/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 0.2517 - mae: 0.2918\n",
      "Epoch 7/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2015 - mae: 0.2614\n",
      "Epoch 8/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1878 - mae: 0.2549\n",
      "Epoch 9/30\n",
      "\u001B[1m12/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1767 - mae: 0.2434\n",
      "Epoch 9: metric under threshold (1/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1748 - mae: 0.2408\n",
      "Epoch 10/30\n",
      "\u001B[1m12/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1740 - mae: 0.2510\n",
      "Epoch 10: metric under threshold (2/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1711 - mae: 0.2471\n",
      "Epoch 11/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1378 - mae: 0.22042024-12-22 16:52:29.124220: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:52:29.124300: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:52:29.124319: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 11: metric under threshold (3/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1372 - mae: 0.2194\n",
      "Epoch 12/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1265 - mae: 0.2085\n",
      "Epoch 12: metric under threshold (4/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1264 - mae: 0.2081\n",
      "Epoch 13/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1237 - mae: 0.2104\n",
      "Epoch 13: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1236 - mae: 0.2099\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 273ms/step\n",
      "R^2 score: 0.28416913747787476\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  3504X  nº:  55  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (196, 24)  df_y.shape:  (196, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 39ms/step - loss: 0.9123 - mae: 0.5487/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 40ms/step - loss: 0.9119 - mae: 0.5462\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.6666 - mae: 0.4281\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.5465 - mae: 0.3913\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.4424 - mae: 0.3496\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.3431 - mae: 0.3112\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.3975 - mae: 0.3316\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.4193 - mae: 0.3229\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.4083 - mae: 0.3211\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.3736 - mae: 0.2869\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 0.3065 - mae: 0.2859\n",
      "Epoch 11/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3041 - mae: 0.2829\n",
      "Epoch 12/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2893 - mae: 0.2895\n",
      "Epoch 13/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.2262 - mae: 0.2596\n",
      "Epoch 14/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2162 - mae: 0.2717\n",
      "Epoch 15/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2330 - mae: 0.28982024-12-22 16:52:59.566655: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:52:59.566809: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:52:59.566832: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 16:52:59.566850: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2322 - mae: 0.2875\n",
      "Epoch 16/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2091 - mae: 0.2770\n",
      "Epoch 17/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2005 - mae: 0.2579\n",
      "Epoch 18/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2510 - mae: 0.2904\n",
      "Epoch 19/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2394 - mae: 0.28192024-12-22 16:53:01.998149: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:01.998206: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:01.998234: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2375 - mae: 0.2793\n",
      "Epoch 20/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1996 - mae: 0.2610\n",
      "Epoch 20: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2006 - mae: 0.2595\n",
      "Epoch 21/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1874 - mae: 0.2447\n",
      "Epoch 21: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1884 - mae: 0.2435\n",
      "Epoch 22/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1672 - mae: 0.2321\n",
      "Epoch 22: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1673 - mae: 0.2314\n",
      "Epoch 23/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.1528 - mae: 0.2271\n",
      "Epoch 23: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1521 - mae: 0.2254\n",
      "Epoch 24/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.1553 - mae: 0.2304\n",
      "Epoch 24: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 0.1543 - mae: 0.2289\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 234ms/step\n",
      "R^2 score: -30.950420379638672\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  3526X  nº:  56  of: 75\n",
      "df_x.shape:  (775, 24)  df_y.shape:  (775, 5)\n",
      "df_x.shape:  (194, 24)  df_y.shape:  (194, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m8s\u001B[0m 53ms/step - loss: 0.7317 - mae: 0.4618/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 54ms/step - loss: 0.7271 - mae: 0.4590\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.5647 - mae: 0.39982024-12-22 16:53:24.257444: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:24.257526: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:24.257616: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.5597 - mae: 0.3958\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.4891 - mae: 0.36132024-12-22 16:53:25.260035: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:25.260098: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:25.260121: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.4877 - mae: 0.3600\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.4063 - mae: 0.3016\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.3822 - mae: 0.29272024-12-22 16:53:26.436680: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:26.436808: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:26.436901: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.3806 - mae: 0.2911\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3509 - mae: 0.2983\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.3177 - mae: 0.27892024-12-22 16:53:27.692018: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:27.692090: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:27.692189: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.3154 - mae: 0.2762\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2840 - mae: 0.24902024-12-22 16:53:28.311092: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:28.311173: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:28.311268: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 8: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2850 - mae: 0.2482\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2854 - mae: 0.2459\n",
      "Epoch 9: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2846 - mae: 0.2445\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2507 - mae: 0.2376\n",
      "Epoch 10: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2490 - mae: 0.2364\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2597 - mae: 0.2356\n",
      "Epoch 11: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2586 - mae: 0.2345\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2169 - mae: 0.2327\n",
      "Epoch 12: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2167 - mae: 0.2318\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 182ms/step\n",
      "R^2 score: -3.7924132347106934\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  3562X  nº:  57  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (196, 24)  df_y.shape:  (196, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m7s\u001B[0m 39ms/step - loss: 0.5464 - mae: 0.4328/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - loss: 0.5428 - mae: 0.4258\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.3864 - mae: 0.32052024-12-22 16:53:49.151802: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:49.151960: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:49.151987: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.3892 - mae: 0.3166\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.3365 - mae: 0.28662024-12-22 16:53:50.010267: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:50.010343: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:50.010365: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.3426 - mae: 0.2847\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.3196 - mae: 0.2582\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.3179 - mae: 0.2596\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.2894 - mae: 0.2352\n",
      "Epoch 6: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.2965 - mae: 0.2343\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2744 - mae: 0.2248\n",
      "Epoch 7: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.2826 - mae: 0.2240\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.2634 - mae: 0.21332024-12-22 16:53:55.428747: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:53:55.428817: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:53:55.428837: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 8: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.2722 - mae: 0.2133\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2648 - mae: 0.2160\n",
      "Epoch 9: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2735 - mae: 0.2157\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.3038 - mae: 0.2402\n",
      "Epoch 10: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3065 - mae: 0.2393\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 182ms/step\n",
      "R^2 score: 0.09445841610431671\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  4340  nº:  58  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (196, 24)  df_y.shape:  (196, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 37ms/step - loss: 0.3908 - mae: 0.4155/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - loss: 0.3881 - mae: 0.4132\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2764 - mae: 0.3320\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2265 - mae: 0.2968\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1879 - mae: 0.2606\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1667 - mae: 0.2318\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1681 - mae: 0.2320\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2022 - mae: 0.2659\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 0.2069 - mae: 0.2717\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.1604 - mae: 0.2311\n",
      "Epoch 8: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.1628 - mae: 0.2306\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.1423 - mae: 0.21342024-12-22 16:54:20.225796: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 6547487746809057678\n",
      "2024-12-22 16:54:20.225877: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:54:20.225906: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:54:20.225922: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 16:54:20.225942: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 9: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1454 - mae: 0.2133\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1402 - mae: 0.19642024-12-22 16:54:21.010339: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:54:21.010411: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:54:21.010503: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 10: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 0.1425 - mae: 0.1964\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.1444 - mae: 0.2071\n",
      "Epoch 11: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.1462 - mae: 0.2059\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 0.1321 - mae: 0.1950\n",
      "Epoch 12: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 0.1346 - mae: 0.1945\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 180ms/step\n",
      "R^2 score: 0.6092398762702942\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1387E  nº:  59  of: 75\n",
      "df_x.shape:  (770, 24)  df_y.shape:  (770, 5)\n",
      "df_x.shape:  (193, 24)  df_y.shape:  (193, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m8s\u001B[0m 40ms/step - loss: 0.5046 - mae: 0.4671/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 40ms/step - loss: 0.4951 - mae: 0.4630\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.3733 - mae: 0.3914\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.3035 - mae: 0.34462024-12-22 16:54:42.259108: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:54:42.259200: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:54:42.259289: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2999 - mae: 0.3429\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3025 - mae: 0.3313\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2404 - mae: 0.29952024-12-22 16:54:43.498818: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:54:43.498970: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:54:43.498994: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2371 - mae: 0.2973\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2322 - mae: 0.2939\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2207 - mae: 0.2809\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.2074 - mae: 0.2692\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2006 - mae: 0.26032024-12-22 16:54:46.001242: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:54:46.001305: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:54:46.001341: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 9: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1975 - mae: 0.2583\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1920 - mae: 0.24262024-12-22 16:54:46.591723: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "\n",
      "Epoch 10: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1896 - mae: 0.2421\n",
      "Epoch 11/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1779 - mae: 0.2506\n",
      "Epoch 11: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1747 - mae: 0.2489\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1723 - mae: 0.2416\n",
      "Epoch 12: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1701 - mae: 0.2405\n",
      "Epoch 13/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.1798 - mae: 0.2576\n",
      "Epoch 13: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.1770 - mae: 0.2554\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 273ms/step\n",
      "R^2 score: -67.32627868652344\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1390X  nº:  60  of: 75\n",
      "df_x.shape:  (640, 24)  df_y.shape:  (640, 5)\n",
      "df_x.shape:  (161, 24)  df_y.shape:  (161, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     12/Unknown \u001B[1m8s\u001B[0m 39ms/step - loss: 0.6317 - mae: 0.5214/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - loss: 0.6219 - mae: 0.5167\n",
      "Epoch 2/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.4909 - mae: 0.4766\n",
      "Epoch 3/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 0.3452 - mae: 0.3643\n",
      "Epoch 4/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2798 - mae: 0.3348\n",
      "Epoch 5/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2362 - mae: 0.2878\n",
      "Epoch 6/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2384 - mae: 0.3033\n",
      "Epoch 7/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.3376 - mae: 0.32632024-12-22 16:55:11.905216: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 6547487746809057678\n",
      "2024-12-22 16:55:11.905283: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "2024-12-22 16:55:11.905311: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:55:11.905339: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.3342 - mae: 0.3248\n",
      "Epoch 8/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2537 - mae: 0.3102\n",
      "Epoch 9/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2472 - mae: 0.29942024-12-22 16:55:13.029681: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:55:13.029774: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:55:13.029798: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2461 - mae: 0.2984\n",
      "Epoch 10/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2200 - mae: 0.2956\n",
      "Epoch 11/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.1664 - mae: 0.2377\n",
      "Epoch 11: metric under threshold (1/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.1655 - mae: 0.2369\n",
      "Epoch 12/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1645 - mae: 0.24492024-12-22 16:55:14.909384: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:55:14.909453: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:55:14.909479: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 12: metric under threshold (2/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1635 - mae: 0.2435\n",
      "Epoch 13/30\n",
      "\u001B[1m12/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.1655 - mae: 0.2364\n",
      "Epoch 13: metric under threshold (3/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.1640 - mae: 0.2342\n",
      "Epoch 14/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1596 - mae: 0.2317\n",
      "Epoch 14: metric under threshold (4/5).\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.1585 - mae: 0.2306\n",
      "Epoch 15/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1622 - mae: 0.2274\n",
      "Epoch 15: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1607 - mae: 0.2261\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 256ms/step\n",
      "R^2 score: -7.0733489990234375\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1466A  nº:  61  of: 75\n",
      "df_x.shape:  (618, 24)  df_y.shape:  (618, 5)\n",
      "df_x.shape:  (155, 24)  df_y.shape:  (155, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     11/Unknown \u001B[1m7s\u001B[0m 58ms/step - loss: 0.8315 - mae: 0.51142024-12-22 16:55:34.577598: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:55:34.577712: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:55:34.577827: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 60ms/step - loss: 0.8000 - mae: 0.5033\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 0.5561 - mae: 0.4428\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 0.4265 - mae: 0.3807\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.3506 - mae: 0.3438\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.3274 - mae: 0.3298\n",
      "Epoch 6/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.3201 - mae: 0.32282024-12-22 16:55:38.628195: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:55:38.628266: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:55:38.628348: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.3093 - mae: 0.3179\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2781 - mae: 0.2979\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2673 - mae: 0.2985\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2556 - mae: 0.2856\n",
      "Epoch 10/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2372 - mae: 0.2752\n",
      "Epoch 10: metric under threshold (1/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.2297 - mae: 0.2707\n",
      "Epoch 11/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2162 - mae: 0.25922024-12-22 16:55:41.254870: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:55:41.254950: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:55:41.255056: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 11: metric under threshold (2/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2104 - mae: 0.2563\n",
      "Epoch 12/30\n",
      "\u001B[1m11/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2141 - mae: 0.2493\n",
      "Epoch 12: metric under threshold (3/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2087 - mae: 0.2472\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2180 - mae: 0.2664\n",
      "Epoch 13: metric under threshold (4/5).\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2149 - mae: 0.2643\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2350 - mae: 0.2735\n",
      "Epoch 14: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2304 - mae: 0.2707\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 309ms/step\n",
      "R^2 score: -0.2061302661895752\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1475X  nº:  62  of: 75\n",
      "df_x.shape:  (775, 24)  df_y.shape:  (775, 5)\n",
      "df_x.shape:  (194, 24)  df_y.shape:  (194, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m7s\u001B[0m 39ms/step - loss: 55.2713 - mae: 2.06492024-12-22 16:56:00.955788: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:00.955883: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:00.955981: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - loss: 53.3896 - mae: 2.0338\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 45.0326 - mae: 1.94462024-12-22 16:56:02.300645: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:02.300747: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:02.300839: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 43.5459 - mae: 1.9111\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 31.5738 - mae: 1.6573\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 25.2441 - mae: 1.49722024-12-22 16:56:04.410577: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:04.410632: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:04.410724: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 24.9475 - mae: 1.4859\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 21.3661 - mae: 1.35422024-12-22 16:56:05.206582: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:05.206641: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:05.206735: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 21.1701 - mae: 1.3437\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 20.0506 - mae: 1.2882\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 19.5616 - mae: 1.2327\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 21.7179 - mae: 1.30102024-12-22 16:56:07.691821: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:07.691971: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:07.692002: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 21.2395 - mae: 1.2849\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 17.5510 - mae: 1.1796\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 15.9899 - mae: 1.18312024-12-22 16:56:08.848366: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 15.5617 - mae: 1.1630\n",
      "Epoch 11/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 15.0999 - mae: 1.0535\n",
      "Epoch 12/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 13.4425 - mae: 1.0557\n",
      "Epoch 13/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 11.8951 - mae: 1.0668\n",
      "Epoch 14/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 10.9327 - mae: 0.94082024-12-22 16:56:11.296826: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:11.296918: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:11.296954: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 10.7626 - mae: 0.9332\n",
      "Epoch 15/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 10.2327 - mae: 1.01632024-12-22 16:56:11.889691: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 10.0253 - mae: 1.0021\n",
      "Epoch 16/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 10.6315 - mae: 0.9520\n",
      "Epoch 17/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 14.1503 - mae: 1.0392\n",
      "Epoch 18/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 13.1842 - mae: 1.0350\n",
      "Epoch 19/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 9.6983 - mae: 0.89432024-12-22 16:56:14.278787: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:14.278845: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "2024-12-22 16:56:14.279467: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 18037352656043838387\n",
      "2024-12-22 16:56:14.279525: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 9.4672 - mae: 0.8839\n",
      "Epoch 20/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 8.2256 - mae: 0.8962\n",
      "Epoch 21/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 8.2945 - mae: 0.88482024-12-22 16:56:15.460776: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:15.460861: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:15.460884: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 8.1107 - mae: 0.8714\n",
      "Epoch 22/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 8.9129 - mae: 0.89052024-12-22 16:56:16.051759: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:16.051828: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:16.051908: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 8.7412 - mae: 0.8800\n",
      "Epoch 23/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 6.9791 - mae: 0.7740\n",
      "Epoch 24/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 6.6585 - mae: 0.8169\n",
      "Epoch 25/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 6.4576 - mae: 0.8197\n",
      "Epoch 26/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 6.3403 - mae: 0.7558\n",
      "Epoch 27/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 4.3265 - mae: 0.6403\n",
      "Epoch 28/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 5.0654 - mae: 0.7191\n",
      "Epoch 29/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 6.1833 - mae: 0.71622024-12-22 16:56:23.007837: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:23.007906: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:23.007931: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 5.9725 - mae: 0.7061\n",
      "Epoch 30/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 5.0443 - mae: 0.6573\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 182ms/step\n",
      "R^2 score: -30357.666015625\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1719  nº:  63  of: 75\n",
      "df_x.shape:  (640, 24)  df_y.shape:  (640, 5)\n",
      "df_x.shape:  (161, 24)  df_y.shape:  (161, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     12/Unknown \u001B[1m7s\u001B[0m 42ms/step - loss: 25.0327 - mae: 1.43102024-12-22 16:56:41.839395: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:41.839489: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:41.839511: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 41ms/step - loss: 23.8167 - mae: 1.3910\n",
      "Epoch 2/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 18.9285 - mae: 1.2933\n",
      "Epoch 3/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 20.1716 - mae: 1.12582024-12-22 16:56:42.867339: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:42.867413: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:42.867506: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 19.7311 - mae: 1.1129\n",
      "Epoch 4/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 14.4309 - mae: 1.09732024-12-22 16:56:43.350828: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:43.350902: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:43.350929: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 14.1358 - mae: 1.0799\n",
      "Epoch 5/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 11.6380 - mae: 1.0375\n",
      "Epoch 6/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 10.9003 - mae: 0.99722024-12-22 16:56:44.445686: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 10.6733 - mae: 0.9815\n",
      "Epoch 7/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 9.3491 - mae: 0.9469 \n",
      "Epoch 8/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 7.7944 - mae: 0.8699\n",
      "Epoch 9/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 7.4039 - mae: 0.8220\n",
      "Epoch 10/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 7.1313 - mae: 0.8181\n",
      "Epoch 11/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 5.8916 - mae: 0.7482\n",
      "Epoch 12/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 5.2680 - mae: 0.7105\n",
      "Epoch 13/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 4.3412 - mae: 0.6466\n",
      "Epoch 14/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 3.6843 - mae: 0.5916\n",
      "Epoch 15/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 4.1644 - mae: 0.6240\n",
      "Epoch 16/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 5.6441 - mae: 0.6934\n",
      "Epoch 17/30\n",
      "\u001B[1m12/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 6.5239 - mae: 0.76122024-12-22 16:56:52.227890: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:52.227945: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:52.228027: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 6.1477 - mae: 0.7358\n",
      "Epoch 18/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.7416 - mae: 0.76882024-12-22 16:56:53.253342: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:53.253400: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:53.253427: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 6.5881 - mae: 0.7579\n",
      "Epoch 19/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 3.4011 - mae: 0.6893\n",
      "Epoch 20/30\n",
      "\u001B[1m12/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 2.4121 - mae: 0.59462024-12-22 16:56:54.368863: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:54.368919: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:54.368944: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 2.3136 - mae: 0.5808\n",
      "Epoch 21/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 1.8510 - mae: 0.5237\n",
      "Epoch 22/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 1.7188 - mae: 0.4820\n",
      "Epoch 23/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 1.6448 - mae: 0.4677\n",
      "Epoch 24/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.4378 - mae: 0.45052024-12-22 16:56:56.724541: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:56.724601: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 18037352656043838387\n",
      "2024-12-22 16:56:56.724616: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:56.724631: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 1.4163 - mae: 0.4460\n",
      "Epoch 25/30\n",
      "\u001B[1m12/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 1.6193 - mae: 0.46092024-12-22 16:56:57.213928: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:56:57.213983: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:56:57.214072: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 1.5557 - mae: 0.4519\n",
      "Epoch 26/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 1.7988 - mae: 0.4758\n",
      "Epoch 27/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 2.3059 - mae: 0.50472024-12-22 16:56:58.177324: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 2.2477 - mae: 0.4990\n",
      "Epoch 28/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 2.1629 - mae: 0.4928\n",
      "Epoch 29/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 1.8587 - mae: 0.5046\n",
      "Epoch 30/30\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 1.6386 - mae: 0.4744\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275ms/step\n",
      "R^2 score: -1420.93603515625\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  B275E  nº:  64  of: 75\n",
      "df_x.shape:  (775, 24)  df_y.shape:  (775, 5)\n",
      "df_x.shape:  (194, 24)  df_y.shape:  (194, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 53ms/step - loss: 0.3123 - mae: 0.3795/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 54ms/step - loss: 0.3203 - mae: 0.3775\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.2526 - mae: 0.3073\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.2296 - mae: 0.2929\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.1893 - mae: 0.2507\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.1441 - mae: 0.2246\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 0.1662 - mae: 0.2247\n",
      "Epoch 6/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1170 - mae: 0.2052\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1523 - mae: 0.2066\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1172 - mae: 0.1884\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1401 - mae: 0.1897\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1308 - mae: 0.1912\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1412 - mae: 0.1915\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1067 - mae: 0.1781\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1296 - mae: 0.1791\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 189ms/step\n",
      "R^2 score: 0.2524828016757965\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  B569X  nº:  65  of: 75\n",
      "df_x.shape:  (771, 24)  df_y.shape:  (771, 5)\n",
      "df_x.shape:  (193, 24)  df_y.shape:  (193, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     14/Unknown \u001B[1m7s\u001B[0m 41ms/step - loss: 0.3186 - mae: 0.3948W0000 00:00:1734886663.638496    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.639304    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.640029    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.640725    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.641404    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.642153    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.642869    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.643575    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.644262    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.647114    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.647836    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.648517    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.649205    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.649894    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.650566    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.651264    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.651944    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.652659    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.655606    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.656347    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.657064    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.659055    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.659738    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.660398    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.661100    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.661929    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.662605    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.663296    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.665821    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.666520    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.667205    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.667886    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.668560    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.669283    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.670021    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.670778    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886663.671496    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 42ms/step - loss: 0.3210 - mae: 0.3891/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 43ms/step - loss: 0.3220 - mae: 0.3868\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2196 - mae: 0.30202024-12-22 16:57:44.758800: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:57:44.758895: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:57:44.758998: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2245 - mae: 0.2992\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1879 - mae: 0.2649\n",
      "Epoch 4/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1713 - mae: 0.2616\n",
      "Epoch 4: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1773 - mae: 0.2594\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1361 - mae: 0.2296\n",
      "Epoch 5: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1441 - mae: 0.2287\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.1254 - mae: 0.2126\n",
      "Epoch 6: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 0.1336 - mae: 0.2124\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.1205 - mae: 0.20872024-12-22 16:57:48.719790: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:57:48.719899: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:57:48.720008: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.1283 - mae: 0.2075\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.1193 - mae: 0.20392024-12-22 16:57:49.546791: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:57:49.546857: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:57:49.546876: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 8: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.1236 - mae: 0.2040\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 276ms/step\n",
      "R^2 score: 0.059542395174503326\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  B760X  nº:  66  of: 75\n",
      "df_x.shape:  (776, 24)  df_y.shape:  (776, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     14/Unknown \u001B[1m8s\u001B[0m 39ms/step - loss: 0.3227 - mae: 0.38972024-12-22 16:58:09.871040: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 38ms/step - loss: 0.3771 - mae: 0.3816\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2258 - mae: 0.27412024-12-22 16:58:10.503533: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:58:10.503611: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:58:10.503635: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2657 - mae: 0.2743\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2356 - mae: 0.2514\n",
      "Epoch 4/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1842 - mae: 0.26012024-12-22 16:58:11.724403: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:58:11.724470: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:58:11.724566: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2192 - mae: 0.2619\n",
      "Epoch 5/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.1304 - mae: 0.2155\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1754 - mae: 0.2193\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1694 - mae: 0.23302024-12-22 16:58:12.963787: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:58:12.963862: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:58:12.963886: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.2003 - mae: 0.2344\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1601 - mae: 0.22322024-12-22 16:58:13.576582: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:58:13.576654: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:58:13.576672: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 16:58:13.576690: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.1715 - mae: 0.2239\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1620 - mae: 0.2347\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1702 - mae: 0.2349\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1273 - mae: 0.20122024-12-22 16:58:14.791628: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1448 - mae: 0.2022\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 199ms/step\n",
      "R^2 score: 0.306008905172348\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  B925  nº:  67  of: 75\n",
      "df_x.shape:  (752, 24)  df_y.shape:  (752, 5)\n",
      "df_x.shape:  (189, 24)  df_y.shape:  (189, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     14/Unknown \u001B[1m8s\u001B[0m 57ms/step - loss: 0.2948 - mae: 0.3946/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 56ms/step - loss: 0.2885 - mae: 0.3876\n",
      "Epoch 2/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 0.2289 - mae: 0.3213\n",
      "Epoch 3/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1599 - mae: 0.2667\n",
      "Epoch 3: metric under threshold (1/5).\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.1594 - mae: 0.2653\n",
      "Epoch 4/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1243 - mae: 0.2344\n",
      "Epoch 4: metric under threshold (2/5).\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1251 - mae: 0.2344\n",
      "Epoch 5/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1295 - mae: 0.2440\n",
      "Epoch 5: metric under threshold (3/5).\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1297 - mae: 0.2431\n",
      "Epoch 6/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0988 - mae: 0.20662024-12-22 16:58:37.189600: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:58:37.189665: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:58:37.189688: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 6: metric under threshold (4/5).\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.0999 - mae: 0.2066\n",
      "Epoch 7/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1142 - mae: 0.2234\n",
      "Epoch 7: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1143 - mae: 0.2223\n",
      "      1/Unknown \u001B[1m1s\u001B[0m 515ms/stepW0000 00:00:1734886718.968324    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.969196    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.969992    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.970830    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.971726    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.972556    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.973407    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.974188    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.974957    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.984073    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.984804    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.985529    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.986303    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.987070    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.987763    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.988453    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.989142    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.989812    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.990526    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.991204    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.991885    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.992579    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.993270    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886718.994081    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.003134    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.003856    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.004546    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.005259    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.005965    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.006660    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.007360    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.008064    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.008774    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.009467    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.010201    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.010927    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.011661    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.012426    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.013141    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.013925    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.019026    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.019757    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.020478    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.021226    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.021998    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.022741    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.023515    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.024209    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734886719.024906    1734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 308ms/step\n",
      "R^2 score: 0.1404060423374176\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  9257X  nº:  68  of: 75\n",
      "df_x.shape:  (778, 24)  df_y.shape:  (778, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 39ms/step - loss: 0.4687 - mae: 0.4379/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 40ms/step - loss: 0.4651 - mae: 0.4353\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.3047 - mae: 0.3384\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2578 - mae: 0.3057\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2629 - mae: 0.3284\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1961 - mae: 0.2681\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2015 - mae: 0.2583\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.1868 - mae: 0.2603\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.2040 - mae: 0.27112024-12-22 16:59:00.998854: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:59:01.000773: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:01.000908: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 8: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 0.2021 - mae: 0.2681\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1607 - mae: 0.2269\n",
      "Epoch 9: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1610 - mae: 0.2270\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1313 - mae: 0.2001\n",
      "Epoch 10: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 0.1325 - mae: 0.2001\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.1566 - mae: 0.2064\n",
      "Epoch 11: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 0.1545 - mae: 0.2039\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1516 - mae: 0.2014\n",
      "Epoch 12: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1496 - mae: 0.1996\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 176ms/step\n",
      "R^2 score: 0.2893795967102051\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  9301X  nº:  69  of: 75\n",
      "df_x.shape:  (776, 24)  df_y.shape:  (776, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     14/Unknown \u001B[1m8s\u001B[0m 40ms/step - loss: 0.3557 - mae: 0.41022024-12-22 16:59:23.497238: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:23.497355: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - loss: 0.3403 - mae: 0.3986\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2346 - mae: 0.31292024-12-22 16:59:24.628403: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:24.628470: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2293 - mae: 0.3082\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1714 - mae: 0.2603\n",
      "Epoch 3: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1689 - mae: 0.2575\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1911 - mae: 0.2778\n",
      "Epoch 5/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.1384 - mae: 0.22792024-12-22 16:59:26.540785: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:59:26.540858: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:26.540881: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 0.1367 - mae: 0.2265\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1710 - mae: 0.25402024-12-22 16:59:27.114579: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:27.114648: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1666 - mae: 0.2499\n",
      "Epoch 7/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1579 - mae: 0.23412024-12-22 16:59:27.764826: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:27.764889: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1514 - mae: 0.2284\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1316 - mae: 0.2143\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1303 - mae: 0.2134\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1176 - mae: 0.1977\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1165 - mae: 0.1977\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 252ms/step\n",
      "R^2 score: 0.02161611244082451\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1025X  nº:  70  of: 75\n",
      "df_x.shape:  (777, 24)  df_y.shape:  (777, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m8s\u001B[0m 41ms/step - loss: 0.5401 - mae: 0.45022024-12-22 16:59:49.674318: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:59:49.674387: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:49.674408: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 41ms/step - loss: 0.5371 - mae: 0.4463\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.3959 - mae: 0.3750\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.3385 - mae: 0.3385\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2902 - mae: 0.3060\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.2322 - mae: 0.2697\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2117 - mae: 0.2534\n",
      "Epoch 6: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2125 - mae: 0.2528\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2129 - mae: 0.2544\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2178 - mae: 0.2657\n",
      "Epoch 8: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2184 - mae: 0.2634\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1876 - mae: 0.2310\n",
      "Epoch 9: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.1885 - mae: 0.2300\n",
      "Epoch 10/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1871 - mae: 0.2140\n",
      "Epoch 10: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1865 - mae: 0.2130\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1854 - mae: 0.2237\n",
      "Epoch 11: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1850 - mae: 0.2218\n",
      "Epoch 12/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1855 - mae: 0.22552024-12-22 16:59:56.917634: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 16:59:56.917692: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 16:59:56.917786: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 12: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.1855 - mae: 0.2250\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 172ms/step\n",
      "R^2 score: 0.39207735657691956\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1056K  nº:  71  of: 75\n",
      "df_x.shape:  (777, 24)  df_y.shape:  (777, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m7s\u001B[0m 52ms/step - loss: 0.5143 - mae: 0.4833/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 53ms/step - loss: 0.5129 - mae: 0.4813\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 52ms/step - loss: 0.3647 - mae: 0.4062\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 0.2859 - mae: 0.35092024-12-22 17:00:17.427509: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:17.427587: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:17.427668: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.2843 - mae: 0.3477\n",
      "Epoch 4/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.2702 - mae: 0.32482024-12-22 17:00:18.185466: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:18.185521: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:18.185535: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 17:00:18.185552: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 0.2756 - mae: 0.3217\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.2614 - mae: 0.3204\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.2284 - mae: 0.2890\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2163 - mae: 0.28602024-12-22 17:00:20.537460: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:20.537520: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:20.537541: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2150 - mae: 0.2842\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2077 - mae: 0.27072024-12-22 17:00:21.093771: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:21.093832: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:21.093858: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2066 - mae: 0.2698\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1883 - mae: 0.27992024-12-22 17:00:21.737799: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:21.737856: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:21.737881: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1872 - mae: 0.2774\n",
      "Epoch 10/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1623 - mae: 0.2475\n",
      "Epoch 10: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1629 - mae: 0.2465\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1406 - mae: 0.2339\n",
      "Epoch 11: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1404 - mae: 0.2327\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.1324 - mae: 0.21992024-12-22 17:00:23.563770: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:23.563853: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:23.563877: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 12: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1319 - mae: 0.2190\n",
      "Epoch 13/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1263 - mae: 0.21652024-12-22 17:00:24.197237: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:24.197300: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:24.197341: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 13: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1263 - mae: 0.2164\n",
      "Epoch 14/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1307 - mae: 0.2231\n",
      "Epoch 14: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1315 - mae: 0.2232\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 184ms/step\n",
      "R^2 score: 0.2184278666973114\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  1074C  nº:  72  of: 75\n",
      "df_x.shape:  (777, 24)  df_y.shape:  (777, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     16/Unknown \u001B[1m6s\u001B[0m 44ms/step - loss: 0.4694 - mae: 0.43432024-12-22 17:00:42.692305: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:42.692384: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:42.692477: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 46ms/step - loss: 0.4681 - mae: 0.4323\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 0.3607 - mae: 0.3755\n",
      "Epoch 3/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.2759 - mae: 0.30812024-12-22 17:00:44.832096: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:44.832160: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:44.832236: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.2762 - mae: 0.3073\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 0.2843 - mae: 0.3233\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.2428 - mae: 0.28282024-12-22 17:00:46.933151: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:46.933270: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:46.933454: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 0.2424 - mae: 0.2820\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.2463 - mae: 0.29162024-12-22 17:00:47.784854: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 6547487746809057678\n",
      "2024-12-22 17:00:47.784923: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:47.784948: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:47.784966: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11872812463709321161\n",
      "2024-12-22 17:00:47.784986: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.2462 - mae: 0.2905\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.2525 - mae: 0.2936\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2409 - mae: 0.2708\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2048 - mae: 0.2558\n",
      "Epoch 9: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2032 - mae: 0.2544\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.2037 - mae: 0.2564\n",
      "Epoch 11/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1912 - mae: 0.2565\n",
      "Epoch 11: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1893 - mae: 0.2544\n",
      "Epoch 12/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1875 - mae: 0.2434\n",
      "Epoch 12: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1859 - mae: 0.2422\n",
      "Epoch 13/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1847 - mae: 0.2397\n",
      "Epoch 13: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1816 - mae: 0.2371\n",
      "Epoch 14/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2018 - mae: 0.25592024-12-22 17:00:52.483694: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:00:52.483782: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:00:52.483805: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 14: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1983 - mae: 0.2537\n",
      "Epoch 15/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1800 - mae: 0.2389\n",
      "Epoch 15: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1779 - mae: 0.2362\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 185ms/step\n",
      "R^2 score: 0.18745362758636475\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  7195X  nº:  73  of: 75\n",
      "df_x.shape:  (776, 24)  df_y.shape:  (776, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     14/Unknown \u001B[1m6s\u001B[0m 37ms/step - loss: 0.3681 - mae: 0.4163/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - loss: 0.3630 - mae: 0.4070\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 0.2490 - mae: 0.3128\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 0.1896 - mae: 0.2660\n",
      "Epoch 4/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - loss: 0.1786 - mae: 0.25792024-12-22 17:01:14.299564: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:01:14.299634: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:01:14.299723: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 0.1821 - mae: 0.2578\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1619 - mae: 0.23592024-12-22 17:01:15.104865: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:01:15.104920: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:01:15.104940: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 5: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1638 - mae: 0.2357\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.1552 - mae: 0.2343\n",
      "Epoch 6: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 0.1567 - mae: 0.2335\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1372 - mae: 0.20622024-12-22 17:01:16.691499: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:01:16.691550: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:01:16.691622: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 0.1390 - mae: 0.2063\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1198 - mae: 0.1956\n",
      "Epoch 8: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1234 - mae: 0.1962\n",
      "Epoch 9/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1204 - mae: 0.2014\n",
      "Epoch 9: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1235 - mae: 0.2014\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 179ms/step\n",
      "R^2 score: 0.042418062686920166\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Processing station:  7275C  nº:  74  of: 75\n",
      "df_x.shape:  (780, 24)  df_y.shape:  (780, 5)\n",
      "df_x.shape:  (195, 24)  df_y.shape:  (195, 5)\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m24\u001B[0m)       │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │        \u001B[32m144,512\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)      │         \u001B[32m70,784\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_2 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m67,840\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_3 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │         \u001B[32m30,976\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm (\u001B[94mLSTM\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_1 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m394,240\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_2 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lstm_3 (\u001B[94mLSTM\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m525,312\u001B[0m │ conv1d_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1024\u001B[0m)     │              \u001B[32m0\u001B[0m │ lstm[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],            │\n",
      "│                           │                        │                │ lstm_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│                           │                        │                │ lstm_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m524,800\u001B[0m │ concatenate[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m64\u001B[0m)       │         \u001B[32m32,832\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)        │             \u001B[32m65\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda (\u001B[94mLambda\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_1 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_2 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_3 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ lambda_4 (\u001B[94mLambda\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate_1             │ (\u001B[96mNone\u001B[0m, \u001B[32m5\u001B[0m)              │              \u001B[32m0\u001B[0m │ lambda[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],          │\n",
      "│ (\u001B[94mConcatenate\u001B[0m)             │                        │                │ lambda_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ lambda_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]         │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m2,711,173\u001B[0m (10.34 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "Epoch 1/30\n",
      "     15/Unknown \u001B[1m7s\u001B[0m 37ms/step - loss: 0.3207 - mae: 0.41132024-12-22 17:01:36.339756: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:01:36.339828: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:01:36.339851: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - loss: 0.3124 - mae: 0.4045\n",
      "Epoch 2/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2149 - mae: 0.31902024-12-22 17:01:37.510513: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:01:37.510575: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:01:37.510653: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.2106 - mae: 0.3153\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1507 - mae: 0.2643\n",
      "Epoch 4/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1266 - mae: 0.2427\n",
      "Epoch 4: metric under threshold (1/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.1259 - mae: 0.2416\n",
      "Epoch 5/30\n",
      "\u001B[1m14/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.1028 - mae: 0.2170\n",
      "Epoch 5: metric under threshold (2/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 0.1016 - mae: 0.2146\n",
      "Epoch 6/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1020 - mae: 0.21462024-12-22 17:01:39.981957: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "\n",
      "Epoch 6: metric under threshold (3/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.1008 - mae: 0.2127\n",
      "Epoch 7/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0839 - mae: 0.19222024-12-22 17:01:40.560724: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10988748934025240697\n",
      "2024-12-22 17:01:40.560787: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3275268451873623449\n",
      "2024-12-22 17:01:40.560809: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1938122332794099280\n",
      "\n",
      "Epoch 7: metric under threshold (4/5).\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.0838 - mae: 0.1916\n",
      "Epoch 8/30\n",
      "\u001B[1m15/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0829 - mae: 0.1928\n",
      "Epoch 8: metric under threshold (5/5).\n",
      "\n",
      "Stable metric during 5 epoch. Stopping training.\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 0.0832 - mae: 0.1925\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 176ms/step\n",
      "R^2 score: 0.23386530578136444\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "End of training...\n",
      "Model loaded for station_ids: dict_keys(['5390Y', '5402', '5582A', '5598X', '5612X', '5906X', '5972X', '6045X', '6172X', '6268Y', '6307X', '6312E', '8486X', '9434', '9573X', '9814X', '9843A', '1186P', '1279X', 'C148F', 'C249I', 'C619Y', 'C639M', 'C649R', 'C659H', 'C659M', '1111X', '9016X', '2044B', '2048A', '2331', '2734D', '2777K', '2873X', '2891A', '2946X', '9352A', '3140Y', '4096Y', '7066Y', '8177A', '9377Y', '0016A', '0201D', '0244X', '0367', '9677', '9946X', '8025', '8036Y', '8270X', '8500A', '3104Y', '3266A', '3475X', '3504X', '3526X', '3562X', '4340', '1387E', '1390X', '1466A', '1475X', '1719', 'B275E', 'B569X', 'B760X', 'B925', '9257X', '9301X', '1025X', '1056K', '1074C', '7195X', '7275C'])\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python \"${BASE_PATH_TFM}/train_models.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1734346551191,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     },
     "user_tz": -60
    },
    "id": "Ti70fe6aKfeI",
    "outputId": "11f59e32-bc75-4605-cef9-146a55c9a981"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/Othercomputers/Mi portátil/tfm-energy-predictor/observation_data_builder.py\", line 5, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\", line 119, in <module>\n",
      "    from pandas.core.computation.api import eval\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/api.py\", line 2, in <module>\n",
      "    from pandas.core.computation.eval import eval\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/eval.py\", line 15, in <module>\n",
      "    from pandas.core.computation.engines import ENGINES\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/engines.py\", line 15, in <module>\n",
      "    from pandas.core.computation.ops import (\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/ops.py\", line 30, in <module>\n",
      "    from pandas.core.computation.scope import DEFAULT_GLOBALS\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python \"${BASE_PATH_TFM}/observation_data_builder.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41373,
     "status": "ok",
     "timestamp": 1733727711006,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     },
     "user_tz": -60
    },
    "id": "m9KoVxRkK-IS",
    "outputId": "6057c06a-1a63-454d-e00b-2e985a110d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'datetime'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/Othercomputers/Mi portátil/tfm-energy-predictor/meteo_energy_databuilder.py\", line 131, in <module>\n",
      "    df_emi, df_gen, df_dem = load_ree_data()\n",
      "  File \"/content/drive/Othercomputers/Mi portátil/tfm-energy-predictor/meteo_energy_databuilder.py\", line 66, in load_ree_data\n",
      "    df_generation = dm.convert_datetime_cols_to_day_hour_cols(df_generation, 'Hora')\n",
      "  File \"/content/drive/Othercomputers/Mi portátil/tfm-energy-predictor/common/dataframe_manager.py\", line 90, in convert_datetime_cols_to_day_hour_cols\n",
      "    df = convert_date_time_to_day_hour(df, 'datetime')\n",
      "  File \"/content/drive/Othercomputers/Mi portátil/tfm-energy-predictor/common/dataframe_manager.py\", line 72, in convert_date_time_to_day_hour\n",
      "    df_out['Ano'] = df_out[date_time_col].dt.year\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\", line 4102, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'datetime'\n"
     ]
    }
   ],
   "source": [
    "!python \"${BASE_PATH_TFM}/meteo_energy_databuilder.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222232,
     "status": "ok",
     "timestamp": 1735056160819,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     },
     "user_tz": -60
    },
    "id": "piBo72CwsM1c",
    "outputId": "4ed100d4-f5d0-4716-9ea5-5606f84a84a6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2024-12-24 15:59:00.940093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-24 15:59:00.959567: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-24 15:59:00.965733: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-24 15:59:00.979856: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-24 15:59:02.477600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "    Ano  Mes  Dia  Hora  Minuto  0016A_Altitud  0201D_Altitud  0244X_Altitud  0367_Altitud  1025X_Altitud  1056K_Altitud  1074C_Altitud  1111X_Altitud  1186P_Altitud  1279X_Altitud  1387E_Altitud  1390X_Altitud  1466A_Altitud  1475X_Altitud  1719_Altitud  2044B_Altitud  2048A_Altitud  2331_Altitud  2734D_Altitud  2777K_Altitud  2873X_Altitud  2891A_Altitud  2946X_Altitud  3104Y_Altitud  3140Y_Altitud  3266A_Altitud  3475X_Altitud  3504X_Altitud  3526X_Altitud  3562X_Altitud  4096Y_Altitud  4340_Altitud  5390Y_Altitud  5402_Altitud  5582A_Altitud  5598X_Altitud  5612X_Altitud  5906X_Altitud  5972X_Altitud  6045X_Altitud  6172X_Altitud  6268Y_Altitud  6307X_Altitud  6312E_Altitud  7066Y_Altitud  7195X_Altitud  7275C_Altitud  8025_Altitud  8036Y_Altitud  8177A_Altitud  8270X_Altitud  8486X_Altitud  8500A_Altitud  9016X_Altitud  9257X_Altitud  9301X_Altitud  9352A_Altitud  9377Y_Altitud  9434_Altitud  9573X_Altitud  9677_Altitud  9814X_Altitud  9843A_Altitud  9946X_Altitud  \\\n",
      "0  2022    9   18     0       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "1  2022    9   18     1       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "2  2022    9   18     2       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "3  2022    9   18     3       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "4  2022    9   18     4       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "\n",
      "   B275E_Altitud  B569X_Altitud  B760X_Altitud  B925_Altitud  C148F_Altitud  C249I_Altitud  C619Y_Altitud  C639M_Altitud  C649R_Altitud  C659H_Altitud  C659M_Altitud  0016A_Humedad_relativa  0201D_Humedad_relativa  0244X_Humedad_relativa  0367_Humedad_relativa  1025X_Humedad_relativa  1056K_Humedad_relativa  1074C_Humedad_relativa  1111X_Humedad_relativa  1186P_Humedad_relativa  1279X_Humedad_relativa  1387E_Humedad_relativa  1390X_Humedad_relativa  1466A_Humedad_relativa  1475X_Humedad_relativa  1719_Humedad_relativa  2044B_Humedad_relativa  2048A_Humedad_relativa  2331_Humedad_relativa  2734D_Humedad_relativa  2777K_Humedad_relativa  2873X_Humedad_relativa  2891A_Humedad_relativa  2946X_Humedad_relativa  3104Y_Humedad_relativa  3140Y_Humedad_relativa  3266A_Humedad_relativa  3475X_Humedad_relativa  3504X_Humedad_relativa  3526X_Humedad_relativa  3562X_Humedad_relativa  4096Y_Humedad_relativa  4340_Humedad_relativa  5390Y_Humedad_relativa  5402_Humedad_relativa  \\\n",
      "0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "1           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "2           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "3           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "4           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "\n",
      "   5582A_Humedad_relativa  5598X_Humedad_relativa  5612X_Humedad_relativa  5906X_Humedad_relativa  5972X_Humedad_relativa  6045X_Humedad_relativa  6172X_Humedad_relativa  6268Y_Humedad_relativa  6307X_Humedad_relativa  6312E_Humedad_relativa  7066Y_Humedad_relativa  7195X_Humedad_relativa  7275C_Humedad_relativa  8025_Humedad_relativa  8036Y_Humedad_relativa  8177A_Humedad_relativa  8270X_Humedad_relativa  8486X_Humedad_relativa  8500A_Humedad_relativa  9016X_Humedad_relativa  9257X_Humedad_relativa  9301X_Humedad_relativa  9352A_Humedad_relativa  9377Y_Humedad_relativa  9434_Humedad_relativa  9573X_Humedad_relativa  9677_Humedad_relativa  9814X_Humedad_relativa  9843A_Humedad_relativa  9946X_Humedad_relativa  B275E_Humedad_relativa  B569X_Humedad_relativa  B760X_Humedad_relativa  B925_Humedad_relativa  C148F_Humedad_relativa  C249I_Humedad_relativa  C619Y_Humedad_relativa  C639M_Humedad_relativa  C649R_Humedad_relativa  C659H_Humedad_relativa  C659M_Humedad_relativa  \\\n",
      "0                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "1                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "2                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "3                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "4                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "\n",
      "   0016A_Precipitacion  0201D_Precipitacion  0244X_Precipitacion  0367_Precipitacion  1025X_Precipitacion  1056K_Precipitacion  1074C_Precipitacion  1111X_Precipitacion  1186P_Precipitacion  1279X_Precipitacion  1387E_Precipitacion  1390X_Precipitacion  1466A_Precipitacion  1475X_Precipitacion  1719_Precipitacion  2044B_Precipitacion  2048A_Precipitacion  2331_Precipitacion  2734D_Precipitacion  2777K_Precipitacion  2873X_Precipitacion  2891A_Precipitacion  2946X_Precipitacion  3104Y_Precipitacion  3140Y_Precipitacion  3266A_Precipitacion  3475X_Precipitacion  3504X_Precipitacion  3526X_Precipitacion  3562X_Precipitacion  4096Y_Precipitacion  4340_Precipitacion  5390Y_Precipitacion  5402_Precipitacion  5582A_Precipitacion  5598X_Precipitacion  5612X_Precipitacion  5906X_Precipitacion  5972X_Precipitacion  6045X_Precipitacion  6172X_Precipitacion  6268Y_Precipitacion  6307X_Precipitacion  6312E_Precipitacion  7066Y_Precipitacion  7195X_Precipitacion  7275C_Precipitacion  \\\n",
      "0                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "1                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "2                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "3                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "4                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "\n",
      "   8025_Precipitacion  8036Y_Precipitacion  8177A_Precipitacion  8270X_Precipitacion  8486X_Precipitacion  8500A_Precipitacion  9016X_Precipitacion  9257X_Precipitacion  9301X_Precipitacion  9352A_Precipitacion  9377Y_Precipitacion  9434_Precipitacion  9573X_Precipitacion  9677_Precipitacion  9814X_Precipitacion  9843A_Precipitacion  9946X_Precipitacion  B275E_Precipitacion  B569X_Precipitacion  B760X_Precipitacion  B925_Precipitacion  C148F_Precipitacion  C249I_Precipitacion  C619Y_Precipitacion  C639M_Precipitacion  C649R_Precipitacion  C659H_Precipitacion  C659M_Precipitacion  0016A_Presion  0201D_Presion  0244X_Presion  0367_Presion  1025X_Presion  1056K_Presion  1074C_Presion  1111X_Presion  1186P_Presion  1279X_Presion  1387E_Presion  1390X_Presion  1466A_Presion  1475X_Presion  1719_Presion  2044B_Presion  2048A_Presion  2331_Presion  2734D_Presion  2777K_Presion  2873X_Presion  2891A_Presion  2946X_Presion  3104Y_Presion  3140Y_Presion  3266A_Presion  3475X_Presion  \\\n",
      "0               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "1               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "2               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "3               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "4               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "\n",
      "   3504X_Presion  3526X_Presion  3562X_Presion  4096Y_Presion  4340_Presion  5390Y_Presion  5402_Presion  5582A_Presion  5598X_Presion  5612X_Presion  5906X_Presion  5972X_Presion  6045X_Presion  6172X_Presion  6268Y_Presion  6307X_Presion  6312E_Presion  7066Y_Presion  7195X_Presion  7275C_Presion  8025_Presion  8036Y_Presion  8177A_Presion  8270X_Presion  8486X_Presion  8500A_Presion  9016X_Presion  9257X_Presion  9301X_Presion  9352A_Presion  9377Y_Presion  9434_Presion  9573X_Presion  9677_Presion  9814X_Presion  9843A_Presion  9946X_Presion  B275E_Presion  B569X_Presion  B760X_Presion  B925_Presion  C148F_Presion  C249I_Presion  C619Y_Presion  C639M_Presion  C649R_Presion  C659H_Presion  C659M_Presion  0016A_Temperatura  0201D_Temperatura  0244X_Temperatura  0367_Temperatura  1025X_Temperatura  1056K_Temperatura  1074C_Temperatura  1111X_Temperatura  1186P_Temperatura  1279X_Temperatura  1387E_Temperatura  1390X_Temperatura  1466A_Temperatura  1475X_Temperatura  \\\n",
      "0       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "1       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "2       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "3       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "4       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "\n",
      "   1719_Temperatura  2044B_Temperatura  2048A_Temperatura  2331_Temperatura  2734D_Temperatura  2777K_Temperatura  2873X_Temperatura  2891A_Temperatura  2946X_Temperatura  3104Y_Temperatura  3140Y_Temperatura  3266A_Temperatura  3475X_Temperatura  3504X_Temperatura  3526X_Temperatura  3562X_Temperatura  4096Y_Temperatura  4340_Temperatura  5390Y_Temperatura  5402_Temperatura  5582A_Temperatura  5598X_Temperatura  5612X_Temperatura  5906X_Temperatura  5972X_Temperatura  6045X_Temperatura  6172X_Temperatura  6268Y_Temperatura  6307X_Temperatura  6312E_Temperatura  7066Y_Temperatura  7195X_Temperatura  7275C_Temperatura  8025_Temperatura  8036Y_Temperatura  8177A_Temperatura  8270X_Temperatura  8486X_Temperatura  8500A_Temperatura  9016X_Temperatura  9257X_Temperatura  9301X_Temperatura  9352A_Temperatura  9377Y_Temperatura  9434_Temperatura  9573X_Temperatura  9677_Temperatura  9814X_Temperatura  9843A_Temperatura  9946X_Temperatura  B275E_Temperatura  B569X_Temperatura  \\\n",
      "0              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "1              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "2              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "3              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "4              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "\n",
      "   B760X_Temperatura  B925_Temperatura  C148F_Temperatura  C249I_Temperatura  C619Y_Temperatura  C639M_Temperatura  C649R_Temperatura  C659H_Temperatura  C659M_Temperatura  0016A_Viento  0201D_Viento  0244X_Viento  0367_Viento  1025X_Viento  1056K_Viento  1074C_Viento  1111X_Viento  1186P_Viento  1279X_Viento  1387E_Viento  1390X_Viento  1466A_Viento  1475X_Viento  1719_Viento  2044B_Viento  2048A_Viento  2331_Viento  2734D_Viento  2777K_Viento  2873X_Viento  2891A_Viento  2946X_Viento  3104Y_Viento  3140Y_Viento  3266A_Viento  3475X_Viento  3504X_Viento  3526X_Viento  3562X_Viento  4096Y_Viento  4340_Viento  5390Y_Viento  5402_Viento  5582A_Viento  5598X_Viento  5612X_Viento  5906X_Viento  5972X_Viento  6045X_Viento  6172X_Viento  6268Y_Viento  6307X_Viento  6312E_Viento  7066Y_Viento  7195X_Viento  7275C_Viento  8025_Viento  8036Y_Viento  8177A_Viento  8270X_Viento  8486X_Viento  8500A_Viento  9016X_Viento  9257X_Viento  9301X_Viento  9352A_Viento  9377Y_Viento  9434_Viento  \\\n",
      "0               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "1               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "2               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "3               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "4               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "\n",
      "   9573X_Viento  9677_Viento  9814X_Viento  9843A_Viento  9946X_Viento  B275E_Viento  B569X_Viento  B760X_Viento  B925_Viento  C148F_Viento  C249I_Viento  C619Y_Viento  C639M_Viento  C649R_Viento  C659H_Viento  C659M_Viento  0016A_Viento_pred  0201D_Viento_pred  0244X_Viento_pred  0367_Viento_pred  1025X_Viento_pred  1056K_Viento_pred  1074C_Viento_pred  1111X_Viento_pred  1186P_Viento_pred  1279X_Viento_pred  1387E_Viento_pred  1390X_Viento_pred  1466A_Viento_pred  1475X_Viento_pred  1719_Viento_pred  2044B_Viento_pred  2048A_Viento_pred  2331_Viento_pred  2734D_Viento_pred  2777K_Viento_pred  2873X_Viento_pred  2891A_Viento_pred  2946X_Viento_pred  3104Y_Viento_pred  3140Y_Viento_pred  3266A_Viento_pred  3475X_Viento_pred  3504X_Viento_pred  3526X_Viento_pred  3562X_Viento_pred  4096Y_Viento_pred  4340_Viento_pred  5390Y_Viento_pred  5402_Viento_pred  5582A_Viento_pred  5598X_Viento_pred  5612X_Viento_pred  5906X_Viento_pred  5972X_Viento_pred  6045X_Viento_pred  6172X_Viento_pred  \\\n",
      "0           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           1.943829          1.479449           1.717177           0.506113           1.437103           0.699526           3.077921           0.797038           1.062248           3.079559           3.527321           1.770954          1.337379           1.186921           2.935063          1.764040           2.938147           1.502103           0.730523           1.471103           3.309237           3.144737           0.259190           0.981486           4.000695           3.736689           1.493466           1.996737           1.195477          1.024277           2.434672          1.944605           2.109376           1.610348           1.629929           1.736365           3.704096           2.812637           1.707109   \n",
      "1           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.025627          1.457594           1.667195           0.492925           1.464666           0.664485           3.110943           0.811082           1.106938           3.229418           3.642670           1.949584          1.315120           1.224410           2.888891          1.706343           2.938147           1.464919           0.729428           1.427311           3.227292           3.150652           0.264778           0.989055           3.962834           3.664406           1.347394           2.030380           1.172130          1.019138           2.420578          1.943563           2.091232           1.623601           1.689690           1.710809           3.710280           2.743318           1.758798   \n",
      "2           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.107308          1.434844           1.613085           0.485157           1.472447           0.618887           3.161249           0.799005           1.142866           3.380415           3.731186           2.081025          1.288763           1.264261           2.847514          1.644860           2.938147           1.396322           0.749744           1.403989           3.169053           3.222362           0.267762           0.999338           3.968915           3.658546           1.350777           2.057055           1.172484          1.027750           2.358795          1.932282           2.047971           1.625315           1.725357           1.686483           3.724195           2.714513           1.833021   \n",
      "3           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.025588          1.457296           1.665819           0.494732           1.458072           0.660966           3.116704           0.802375           1.104017           3.229798           3.633726           1.933855          1.313754           1.225197           2.890489          1.705081           2.938147           1.454448           0.736565           1.434134           3.235194           3.172584           0.263910           0.989960           3.977481           3.686547           1.397212           2.028057           1.180030          1.023721           2.404682          1.940150           2.082860           1.619754           1.681658           1.711219           3.712857           2.756823           1.766309   \n",
      "4           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.066467          1.446219           1.640140           0.489041           1.468556           0.641686           3.136096           0.805043           1.124902           3.304917           3.686928           2.015305          1.301941           1.244335           2.868203          1.675602           2.938147           1.430620           0.739586           1.415650           3.198173           3.186507           0.266270           0.994196           3.965875           3.661476           1.349085           2.043717           1.172307          1.023444           2.389687          1.937923           2.069601           1.624458           1.707523           1.698646           3.717237           2.728915           1.795909   \n",
      "\n",
      "   6268Y_Viento_pred  6307X_Viento_pred  6312E_Viento_pred  7066Y_Viento_pred  7195X_Viento_pred  7275C_Viento_pred  8025_Viento_pred  8036Y_Viento_pred  8177A_Viento_pred  8270X_Viento_pred  8486X_Viento_pred  8500A_Viento_pred  9016X_Viento_pred  9257X_Viento_pred  9301X_Viento_pred  9352A_Viento_pred  9377Y_Viento_pred  9434_Viento_pred  9573X_Viento_pred  9677_Viento_pred  9814X_Viento_pred  9843A_Viento_pred  9946X_Viento_pred  B275E_Viento_pred  B569X_Viento_pred  B760X_Viento_pred  B925_Viento_pred  C148F_Viento_pred  C249I_Viento_pred  C619Y_Viento_pred  C639M_Viento_pred  C649R_Viento_pred  C659H_Viento_pred  C659M_Viento_pred  Eolica_emi  Nuclear_emi  Carbon_emi  Ciclo_combinado_emi  Hidraulica_emi  Intercambios_int_emi  Solar_fotovoltaica_emi  Solar_termica_emi  Termica_renovable_emi  Motores_diesel_emi  Turbina_de_gas_emi  Turbina_de_vapor_emi  Generacion_auxiliar_emi  Cogeneracion_y_residuos_emi  Eolica_gen  Nuclear_gen  Carbon_gen  Ciclo_combinado_gen  Hidraulica_gen  \\\n",
      "0           2.288238           1.668124           1.463399           1.543373           1.609731           1.681400          1.123778           1.092416           1.326636           1.744443           0.665541           2.803017           2.650606           1.352547           1.823641           1.945526           3.260815          1.681861           3.027253          1.064673           6.580015           0.725655           0.297869           1.420418           1.862333           6.593983      9.762467e-02           0.437168           2.352216           4.554829           3.253805           1.457402           2.993989           3.296067           0            0       838.0               3559.0               0                     0                       0                  0                      0               220.0                38.0                 201.0                     0.68                        332.0      7998.0         6919         882                 9275          1927.0   \n",
      "1           2.149992           1.555193           1.463399           1.490385           1.627858           1.668701          1.062609           1.090597           1.331954           1.874320           0.591695           2.808985           2.783953           1.333456           1.842270           1.968959           3.128641          1.678815           2.942154          1.082016           6.583877           0.634895           0.297869           1.496873           1.890221           6.922064      4.126525e-03           0.365818           2.262426           4.531088           3.111320           1.455245           2.964689           3.282041           0            0       720.0               2858.0               0                     0                       0                  0                      0               194.0                43.0                 185.0                     1.40                        331.0      7488.0         6937         758                 7389          2040.0   \n",
      "2           2.008414           1.488367           1.463399           1.447117           1.645798           1.657706          0.999261           1.097296           1.339877           1.978168           0.519294           2.841664           2.904712           1.301297           1.900480           1.991143           3.010926          1.683544           2.827603          1.100459           6.648502           0.582916           0.297869           1.558116           1.909944           7.241610     -1.430512e-07           0.300860           2.192507           4.476672           3.063415           1.471645           2.924891           3.265723           0            0       672.0               3027.0               0                     0                       0                  0                      0               150.0                42.0                 124.0                     0.00                        331.0      6948.0         6939         707                 7809          1525.0   \n",
      "3           2.148881           1.570561           1.463399           1.493625           1.627796           1.669269          1.061883           1.093437           1.332822           1.865644           0.592177           2.817889           2.779757           1.329100           1.855464           1.968543           3.133461          1.681406           2.932337          1.082383           6.604131           0.647822           0.297869           1.491802           1.887499           6.919219      3.391702e-02           0.367949           2.269049           4.520863           3.142847           1.461431           2.961189           3.281277           0            0       674.0               2866.0               0                     0                       0                  0                      0               151.0                43.0                 114.0                     0.00                        333.0      6405.0         6939         709                 7391          1638.0   \n",
      "4           2.079203           1.521780           1.463399           1.468751           1.636828           1.663203          1.030935           1.093947           1.335915           1.926244           0.555495           2.825325           2.844333           1.317377           1.871375           1.980051           3.069784          1.681179           2.884878          1.091238           6.616189           0.608906           0.297869           1.527494           1.900083           7.081837      2.063191e-03           0.333339           2.227466           4.503880           3.087368           1.463445           2.944790           3.273882           0            0       674.0               2858.0               0                     0                       0                  0                      0               150.0                43.0                 114.0                     0.00                        333.0      5926.0         6938         709                 7387          1780.0   \n",
      "\n",
      "   Intercambios_int_gen  Solar_fotovoltaica_gen  Solar_termica_gen  Termica_renovable_gen  Motores_diesel_gen  Turbina_de_gas_gen  Turbina_de_vapor_gen  Generacion_auxiliar_gen  Cogeneracion_y_residuos_gen     Real  Prevista  Programada                                file  Asturias  Cantabria   Navarra  País Vasco  Cataluña    Aragón   Galicia  Islas Baleares  La Rioja  Valencia  Castilla y León  Castilla La Mancha  Extremadura  Andalucía    Murcia    Madrid  Solar_altitude  is_weekend  Eolica_gen_1day_before  Eolica_gen_2days_before  Eolica_gen_3days_before  Hidraulica_gen_1day_before  Hidraulica_gen_2days_before  Hidraulica_gen_3days_before  Solar_fotovoltaica_gen_1day_before  Solar_fotovoltaica_gen_2days_before  Solar_fotovoltaica_gen_3days_before  Solar_termica_gen_1day_before  Solar_termica_gen_2days_before  Solar_termica_gen_3days_before  \n",
      "0                 -4994                    34.0              376.0                    458                 323                  39                   223                        1                         1191  24602.0   24581.0     24568.0  image_2022-09-18T00-00-00.000Z.png  1.000000   1.000000  1.000000    1.000000  0.882925  0.829349  0.822483        0.789877  0.657171  0.622616         0.400481            0.171011     0.121783   0.100546  0.052420  0.001263             0.0           1                  7998.0                   7998.0                   7998.0                      1927.0                       1927.0                       1927.0                                34.0                                 34.0                                 34.0                          376.0                           376.0                           376.0  \n",
      "1                 -4272                    33.0              339.0                    506                 286                  44                   205                        2                         1190  22860.0   23275.0     22934.0  image_2022-09-18T01-00-00.000Z.png  1.000000   0.987258  0.999529    0.925593  0.876782  0.704849  0.716930        0.855061  0.431284  0.579425         0.380731            0.171980     0.112889   0.092299  0.135067  0.219204             0.0           1                  7488.0                   7488.0                   7488.0                      2040.0                       2040.0                       2040.0                                33.0                                 33.0                                 33.0                          339.0                           339.0                           339.0  \n",
      "2                 -4183                    17.0              234.0                    520                 220                  43                   138                        0                         1189  22023.0   22126.0     21911.0  image_2022-09-18T02-00-00.000Z.png  1.000000   0.954224  0.964664    0.811646  0.904278  0.623915  0.674565        0.957055  0.130935  0.628286         0.314095            0.179288     0.113952   0.090697  0.318326  0.680354             0.0           1                  6948.0                   6948.0                   6948.0                      1525.0                       1525.0                       1525.0                                17.0                                 17.0                                 17.0                          234.0                           234.0                           234.0  \n",
      "3                 -3933                    16.0              151.0                    512                 222                  44                   127                        0                         1195  21324.0   21277.0     21384.0  image_2022-09-18T03-00-00.000Z.png  0.964781   0.693723  0.841932    0.854781  0.928629  0.563372  0.551460        0.837040  0.288856  0.720544         0.202483            0.222614     0.150145   0.127495  0.381526  0.551169             0.0           1                  6405.0                   6405.0                   6405.0                      1638.0                       1638.0                       1638.0                                16.0                                 16.0                                 16.0                          151.0                           151.0                           151.0  \n",
      "4                 -3959                    16.0               24.0                    518                 220                  44                   127                        0                         1195  20834.0   20803.0     20853.0  image_2022-09-18T04-00-00.000Z.png  0.453761   0.220387  0.733569    0.924515  0.938867  0.536491  0.395724        0.849310  0.033483  0.718586         0.107176            0.187683     0.190255   0.103147  0.363560  0.110865             0.0           1                  5926.0                   5926.0                   5926.0                      1780.0                       1780.0                       1780.0                                16.0                                 16.0                                 16.0                           24.0                            24.0                            24.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17544 entries, 0 to 17543\n",
      "Data columns (total 592 columns):\n",
      " #    Column                               Non-Null Count  Dtype  \n",
      "---   ------                               --------------  -----  \n",
      " 0    Ano                                  17544 non-null  int64  \n",
      " 1    Mes                                  17544 non-null  int64  \n",
      " 2    Dia                                  17544 non-null  int64  \n",
      " 3    Hora                                 17544 non-null  int64  \n",
      " 4    Minuto                               17544 non-null  int64  \n",
      " 5    0016A_Altitud                        17544 non-null  float64\n",
      " 6    0201D_Altitud                        17544 non-null  float64\n",
      " 7    0244X_Altitud                        17544 non-null  float64\n",
      " 8    0367_Altitud                         17544 non-null  float64\n",
      " 9    1025X_Altitud                        17544 non-null  float64\n",
      " 10   1056K_Altitud                        17544 non-null  float64\n",
      " 11   1074C_Altitud                        17544 non-null  float64\n",
      " 12   1111X_Altitud                        17544 non-null  float64\n",
      " 13   1186P_Altitud                        17544 non-null  float64\n",
      " 14   1279X_Altitud                        17544 non-null  float64\n",
      " 15   1387E_Altitud                        17544 non-null  float64\n",
      " 16   1390X_Altitud                        17544 non-null  float64\n",
      " 17   1466A_Altitud                        17544 non-null  float64\n",
      " 18   1475X_Altitud                        17544 non-null  float64\n",
      " 19   1719_Altitud                         17544 non-null  float64\n",
      " 20   2044B_Altitud                        17544 non-null  float64\n",
      " 21   2048A_Altitud                        17544 non-null  float64\n",
      " 22   2331_Altitud                         17544 non-null  float64\n",
      " 23   2734D_Altitud                        17544 non-null  float64\n",
      " 24   2777K_Altitud                        17544 non-null  float64\n",
      " 25   2873X_Altitud                        17544 non-null  float64\n",
      " 26   2891A_Altitud                        17544 non-null  float64\n",
      " 27   2946X_Altitud                        17544 non-null  float64\n",
      " 28   3104Y_Altitud                        17544 non-null  float64\n",
      " 29   3140Y_Altitud                        17544 non-null  float64\n",
      " 30   3266A_Altitud                        17544 non-null  float64\n",
      " 31   3475X_Altitud                        17544 non-null  float64\n",
      " 32   3504X_Altitud                        17544 non-null  float64\n",
      " 33   3526X_Altitud                        17544 non-null  float64\n",
      " 34   3562X_Altitud                        17544 non-null  float64\n",
      " 35   4096Y_Altitud                        17544 non-null  float64\n",
      " 36   4340_Altitud                         17544 non-null  float64\n",
      " 37   5390Y_Altitud                        17544 non-null  float64\n",
      " 38   5402_Altitud                         17544 non-null  float64\n",
      " 39   5582A_Altitud                        17544 non-null  float64\n",
      " 40   5598X_Altitud                        17544 non-null  float64\n",
      " 41   5612X_Altitud                        17544 non-null  float64\n",
      " 42   5906X_Altitud                        17544 non-null  float64\n",
      " 43   5972X_Altitud                        17544 non-null  float64\n",
      " 44   6045X_Altitud                        17544 non-null  float64\n",
      " 45   6172X_Altitud                        17544 non-null  float64\n",
      " 46   6268Y_Altitud                        17544 non-null  float64\n",
      " 47   6307X_Altitud                        17544 non-null  float64\n",
      " 48   6312E_Altitud                        17544 non-null  float64\n",
      " 49   7066Y_Altitud                        17544 non-null  float64\n",
      " 50   7195X_Altitud                        17544 non-null  float64\n",
      " 51   7275C_Altitud                        17544 non-null  float64\n",
      " 52   8025_Altitud                         17544 non-null  float64\n",
      " 53   8036Y_Altitud                        17544 non-null  float64\n",
      " 54   8177A_Altitud                        17544 non-null  float64\n",
      " 55   8270X_Altitud                        17544 non-null  float64\n",
      " 56   8486X_Altitud                        17544 non-null  float64\n",
      " 57   8500A_Altitud                        17544 non-null  float64\n",
      " 58   9016X_Altitud                        17544 non-null  float64\n",
      " 59   9257X_Altitud                        17544 non-null  float64\n",
      " 60   9301X_Altitud                        17544 non-null  float64\n",
      " 61   9352A_Altitud                        17544 non-null  float64\n",
      " 62   9377Y_Altitud                        17544 non-null  float64\n",
      " 63   9434_Altitud                         17544 non-null  float64\n",
      " 64   9573X_Altitud                        17544 non-null  float64\n",
      " 65   9677_Altitud                         17544 non-null  float64\n",
      " 66   9814X_Altitud                        17544 non-null  float64\n",
      " 67   9843A_Altitud                        17544 non-null  float64\n",
      " 68   9946X_Altitud                        17544 non-null  float64\n",
      " 69   B275E_Altitud                        17544 non-null  float64\n",
      " 70   B569X_Altitud                        17544 non-null  float64\n",
      " 71   B760X_Altitud                        17544 non-null  float64\n",
      " 72   B925_Altitud                         17544 non-null  float64\n",
      " 73   C148F_Altitud                        17544 non-null  float64\n",
      " 74   C249I_Altitud                        17544 non-null  float64\n",
      " 75   C619Y_Altitud                        17544 non-null  float64\n",
      " 76   C639M_Altitud                        17544 non-null  float64\n",
      " 77   C649R_Altitud                        17544 non-null  float64\n",
      " 78   C659H_Altitud                        17544 non-null  float64\n",
      " 79   C659M_Altitud                        17544 non-null  float64\n",
      " 80   0016A_Humedad_relativa               17544 non-null  float64\n",
      " 81   0201D_Humedad_relativa               17544 non-null  float64\n",
      " 82   0244X_Humedad_relativa               17544 non-null  float64\n",
      " 83   0367_Humedad_relativa                17544 non-null  float64\n",
      " 84   1025X_Humedad_relativa               17544 non-null  float64\n",
      " 85   1056K_Humedad_relativa               17544 non-null  float64\n",
      " 86   1074C_Humedad_relativa               17544 non-null  float64\n",
      " 87   1111X_Humedad_relativa               17544 non-null  float64\n",
      " 88   1186P_Humedad_relativa               17544 non-null  float64\n",
      " 89   1279X_Humedad_relativa               17544 non-null  float64\n",
      " 90   1387E_Humedad_relativa               17544 non-null  float64\n",
      " 91   1390X_Humedad_relativa               17544 non-null  float64\n",
      " 92   1466A_Humedad_relativa               17544 non-null  float64\n",
      " 93   1475X_Humedad_relativa               17544 non-null  float64\n",
      " 94   1719_Humedad_relativa                17544 non-null  float64\n",
      " 95   2044B_Humedad_relativa               17544 non-null  float64\n",
      " 96   2048A_Humedad_relativa               17544 non-null  float64\n",
      " 97   2331_Humedad_relativa                17544 non-null  float64\n",
      " 98   2734D_Humedad_relativa               17544 non-null  float64\n",
      " 99   2777K_Humedad_relativa               17544 non-null  float64\n",
      " 100  2873X_Humedad_relativa               17544 non-null  float64\n",
      " 101  2891A_Humedad_relativa               17544 non-null  float64\n",
      " 102  2946X_Humedad_relativa               17544 non-null  float64\n",
      " 103  3104Y_Humedad_relativa               17544 non-null  float64\n",
      " 104  3140Y_Humedad_relativa               17544 non-null  float64\n",
      " 105  3266A_Humedad_relativa               17544 non-null  float64\n",
      " 106  3475X_Humedad_relativa               17544 non-null  float64\n",
      " 107  3504X_Humedad_relativa               17544 non-null  float64\n",
      " 108  3526X_Humedad_relativa               17544 non-null  float64\n",
      " 109  3562X_Humedad_relativa               17544 non-null  float64\n",
      " 110  4096Y_Humedad_relativa               17544 non-null  float64\n",
      " 111  4340_Humedad_relativa                17544 non-null  float64\n",
      " 112  5390Y_Humedad_relativa               17544 non-null  float64\n",
      " 113  5402_Humedad_relativa                17544 non-null  float64\n",
      " 114  5582A_Humedad_relativa               17544 non-null  float64\n",
      " 115  5598X_Humedad_relativa               17544 non-null  float64\n",
      " 116  5612X_Humedad_relativa               17544 non-null  float64\n",
      " 117  5906X_Humedad_relativa               17544 non-null  float64\n",
      " 118  5972X_Humedad_relativa               17544 non-null  float64\n",
      " 119  6045X_Humedad_relativa               17544 non-null  float64\n",
      " 120  6172X_Humedad_relativa               17544 non-null  float64\n",
      " 121  6268Y_Humedad_relativa               17544 non-null  float64\n",
      " 122  6307X_Humedad_relativa               17544 non-null  float64\n",
      " 123  6312E_Humedad_relativa               17544 non-null  float64\n",
      " 124  7066Y_Humedad_relativa               17544 non-null  float64\n",
      " 125  7195X_Humedad_relativa               17544 non-null  float64\n",
      " 126  7275C_Humedad_relativa               17544 non-null  float64\n",
      " 127  8025_Humedad_relativa                17544 non-null  float64\n",
      " 128  8036Y_Humedad_relativa               17544 non-null  float64\n",
      " 129  8177A_Humedad_relativa               17544 non-null  float64\n",
      " 130  8270X_Humedad_relativa               17544 non-null  float64\n",
      " 131  8486X_Humedad_relativa               17544 non-null  float64\n",
      " 132  8500A_Humedad_relativa               17544 non-null  float64\n",
      " 133  9016X_Humedad_relativa               17544 non-null  float64\n",
      " 134  9257X_Humedad_relativa               17544 non-null  float64\n",
      " 135  9301X_Humedad_relativa               17544 non-null  float64\n",
      " 136  9352A_Humedad_relativa               17544 non-null  float64\n",
      " 137  9377Y_Humedad_relativa               17544 non-null  float64\n",
      " 138  9434_Humedad_relativa                17544 non-null  float64\n",
      " 139  9573X_Humedad_relativa               17544 non-null  float64\n",
      " 140  9677_Humedad_relativa                17544 non-null  float64\n",
      " 141  9814X_Humedad_relativa               17544 non-null  float64\n",
      " 142  9843A_Humedad_relativa               17544 non-null  float64\n",
      " 143  9946X_Humedad_relativa               17544 non-null  float64\n",
      " 144  B275E_Humedad_relativa               17544 non-null  float64\n",
      " 145  B569X_Humedad_relativa               17544 non-null  float64\n",
      " 146  B760X_Humedad_relativa               17544 non-null  float64\n",
      " 147  B925_Humedad_relativa                17544 non-null  float64\n",
      " 148  C148F_Humedad_relativa               17544 non-null  float64\n",
      " 149  C249I_Humedad_relativa               17544 non-null  float64\n",
      " 150  C619Y_Humedad_relativa               17544 non-null  float64\n",
      " 151  C639M_Humedad_relativa               17544 non-null  float64\n",
      " 152  C649R_Humedad_relativa               17544 non-null  float64\n",
      " 153  C659H_Humedad_relativa               17544 non-null  float64\n",
      " 154  C659M_Humedad_relativa               17544 non-null  float64\n",
      " 155  0016A_Precipitacion                  17544 non-null  float64\n",
      " 156  0201D_Precipitacion                  17544 non-null  float64\n",
      " 157  0244X_Precipitacion                  17544 non-null  float64\n",
      " 158  0367_Precipitacion                   17544 non-null  float64\n",
      " 159  1025X_Precipitacion                  17544 non-null  float64\n",
      " 160  1056K_Precipitacion                  17544 non-null  float64\n",
      " 161  1074C_Precipitacion                  17544 non-null  float64\n",
      " 162  1111X_Precipitacion                  17544 non-null  float64\n",
      " 163  1186P_Precipitacion                  17544 non-null  float64\n",
      " 164  1279X_Precipitacion                  17544 non-null  float64\n",
      " 165  1387E_Precipitacion                  17544 non-null  float64\n",
      " 166  1390X_Precipitacion                  17544 non-null  float64\n",
      " 167  1466A_Precipitacion                  17544 non-null  float64\n",
      " 168  1475X_Precipitacion                  17544 non-null  float64\n",
      " 169  1719_Precipitacion                   17544 non-null  float64\n",
      " 170  2044B_Precipitacion                  17544 non-null  float64\n",
      " 171  2048A_Precipitacion                  17544 non-null  float64\n",
      " 172  2331_Precipitacion                   17544 non-null  float64\n",
      " 173  2734D_Precipitacion                  17544 non-null  float64\n",
      " 174  2777K_Precipitacion                  17544 non-null  float64\n",
      " 175  2873X_Precipitacion                  17544 non-null  float64\n",
      " 176  2891A_Precipitacion                  17544 non-null  float64\n",
      " 177  2946X_Precipitacion                  17544 non-null  float64\n",
      " 178  3104Y_Precipitacion                  17544 non-null  float64\n",
      " 179  3140Y_Precipitacion                  17544 non-null  float64\n",
      " 180  3266A_Precipitacion                  17544 non-null  float64\n",
      " 181  3475X_Precipitacion                  17544 non-null  float64\n",
      " 182  3504X_Precipitacion                  17544 non-null  float64\n",
      " 183  3526X_Precipitacion                  17544 non-null  float64\n",
      " 184  3562X_Precipitacion                  17544 non-null  float64\n",
      " 185  4096Y_Precipitacion                  17544 non-null  float64\n",
      " 186  4340_Precipitacion                   17544 non-null  float64\n",
      " 187  5390Y_Precipitacion                  17544 non-null  float64\n",
      " 188  5402_Precipitacion                   17544 non-null  float64\n",
      " 189  5582A_Precipitacion                  17544 non-null  float64\n",
      " 190  5598X_Precipitacion                  17544 non-null  float64\n",
      " 191  5612X_Precipitacion                  17544 non-null  float64\n",
      " 192  5906X_Precipitacion                  17544 non-null  float64\n",
      " 193  5972X_Precipitacion                  17544 non-null  float64\n",
      " 194  6045X_Precipitacion                  17544 non-null  float64\n",
      " 195  6172X_Precipitacion                  17544 non-null  float64\n",
      " 196  6268Y_Precipitacion                  17544 non-null  float64\n",
      " 197  6307X_Precipitacion                  17544 non-null  float64\n",
      " 198  6312E_Precipitacion                  17544 non-null  float64\n",
      " 199  7066Y_Precipitacion                  17544 non-null  float64\n",
      " 200  7195X_Precipitacion                  17544 non-null  float64\n",
      " 201  7275C_Precipitacion                  17544 non-null  float64\n",
      " 202  8025_Precipitacion                   17544 non-null  float64\n",
      " 203  8036Y_Precipitacion                  17544 non-null  float64\n",
      " 204  8177A_Precipitacion                  17544 non-null  float64\n",
      " 205  8270X_Precipitacion                  17544 non-null  float64\n",
      " 206  8486X_Precipitacion                  17544 non-null  float64\n",
      " 207  8500A_Precipitacion                  17544 non-null  float64\n",
      " 208  9016X_Precipitacion                  17544 non-null  float64\n",
      " 209  9257X_Precipitacion                  17544 non-null  float64\n",
      " 210  9301X_Precipitacion                  17544 non-null  float64\n",
      " 211  9352A_Precipitacion                  17544 non-null  float64\n",
      " 212  9377Y_Precipitacion                  17544 non-null  float64\n",
      " 213  9434_Precipitacion                   17544 non-null  float64\n",
      " 214  9573X_Precipitacion                  17544 non-null  float64\n",
      " 215  9677_Precipitacion                   17544 non-null  float64\n",
      " 216  9814X_Precipitacion                  17544 non-null  float64\n",
      " 217  9843A_Precipitacion                  17544 non-null  float64\n",
      " 218  9946X_Precipitacion                  17544 non-null  float64\n",
      " 219  B275E_Precipitacion                  17544 non-null  float64\n",
      " 220  B569X_Precipitacion                  17544 non-null  float64\n",
      " 221  B760X_Precipitacion                  17544 non-null  float64\n",
      " 222  B925_Precipitacion                   17544 non-null  float64\n",
      " 223  C148F_Precipitacion                  17544 non-null  float64\n",
      " 224  C249I_Precipitacion                  17544 non-null  float64\n",
      " 225  C619Y_Precipitacion                  17544 non-null  float64\n",
      " 226  C639M_Precipitacion                  17544 non-null  float64\n",
      " 227  C649R_Precipitacion                  17544 non-null  float64\n",
      " 228  C659H_Precipitacion                  17544 non-null  float64\n",
      " 229  C659M_Precipitacion                  17544 non-null  float64\n",
      " 230  0016A_Presion                        17544 non-null  float64\n",
      " 231  0201D_Presion                        17544 non-null  float64\n",
      " 232  0244X_Presion                        17544 non-null  float64\n",
      " 233  0367_Presion                         17544 non-null  float64\n",
      " 234  1025X_Presion                        17544 non-null  float64\n",
      " 235  1056K_Presion                        17544 non-null  float64\n",
      " 236  1074C_Presion                        17544 non-null  float64\n",
      " 237  1111X_Presion                        17544 non-null  float64\n",
      " 238  1186P_Presion                        17544 non-null  float64\n",
      " 239  1279X_Presion                        17544 non-null  float64\n",
      " 240  1387E_Presion                        17544 non-null  float64\n",
      " 241  1390X_Presion                        17544 non-null  float64\n",
      " 242  1466A_Presion                        17544 non-null  float64\n",
      " 243  1475X_Presion                        17544 non-null  float64\n",
      " 244  1719_Presion                         17544 non-null  float64\n",
      " 245  2044B_Presion                        17544 non-null  float64\n",
      " 246  2048A_Presion                        17544 non-null  float64\n",
      " 247  2331_Presion                         17544 non-null  float64\n",
      " 248  2734D_Presion                        17544 non-null  float64\n",
      " 249  2777K_Presion                        17544 non-null  float64\n",
      " 250  2873X_Presion                        17544 non-null  float64\n",
      " 251  2891A_Presion                        17544 non-null  float64\n",
      " 252  2946X_Presion                        17544 non-null  float64\n",
      " 253  3104Y_Presion                        17544 non-null  float64\n",
      " 254  3140Y_Presion                        17544 non-null  float64\n",
      " 255  3266A_Presion                        17544 non-null  float64\n",
      " 256  3475X_Presion                        17544 non-null  float64\n",
      " 257  3504X_Presion                        17544 non-null  float64\n",
      " 258  3526X_Presion                        17544 non-null  float64\n",
      " 259  3562X_Presion                        17544 non-null  float64\n",
      " 260  4096Y_Presion                        17544 non-null  float64\n",
      " 261  4340_Presion                         17544 non-null  float64\n",
      " 262  5390Y_Presion                        17544 non-null  float64\n",
      " 263  5402_Presion                         17544 non-null  float64\n",
      " 264  5582A_Presion                        17544 non-null  float64\n",
      " 265  5598X_Presion                        17544 non-null  float64\n",
      " 266  5612X_Presion                        17544 non-null  float64\n",
      " 267  5906X_Presion                        17544 non-null  float64\n",
      " 268  5972X_Presion                        17544 non-null  float64\n",
      " 269  6045X_Presion                        17544 non-null  float64\n",
      " 270  6172X_Presion                        17544 non-null  float64\n",
      " 271  6268Y_Presion                        17544 non-null  float64\n",
      " 272  6307X_Presion                        17544 non-null  float64\n",
      " 273  6312E_Presion                        17544 non-null  float64\n",
      " 274  7066Y_Presion                        17544 non-null  float64\n",
      " 275  7195X_Presion                        17544 non-null  float64\n",
      " 276  7275C_Presion                        17544 non-null  float64\n",
      " 277  8025_Presion                         17544 non-null  float64\n",
      " 278  8036Y_Presion                        17544 non-null  float64\n",
      " 279  8177A_Presion                        17544 non-null  float64\n",
      " 280  8270X_Presion                        17544 non-null  float64\n",
      " 281  8486X_Presion                        17544 non-null  float64\n",
      " 282  8500A_Presion                        17544 non-null  float64\n",
      " 283  9016X_Presion                        17544 non-null  float64\n",
      " 284  9257X_Presion                        17544 non-null  float64\n",
      " 285  9301X_Presion                        17544 non-null  float64\n",
      " 286  9352A_Presion                        17544 non-null  float64\n",
      " 287  9377Y_Presion                        17544 non-null  float64\n",
      " 288  9434_Presion                         17544 non-null  float64\n",
      " 289  9573X_Presion                        17544 non-null  float64\n",
      " 290  9677_Presion                         17544 non-null  float64\n",
      " 291  9814X_Presion                        17544 non-null  float64\n",
      " 292  9843A_Presion                        17544 non-null  float64\n",
      " 293  9946X_Presion                        17544 non-null  float64\n",
      " 294  B275E_Presion                        17544 non-null  float64\n",
      " 295  B569X_Presion                        17544 non-null  float64\n",
      " 296  B760X_Presion                        17544 non-null  float64\n",
      " 297  B925_Presion                         17544 non-null  float64\n",
      " 298  C148F_Presion                        17544 non-null  float64\n",
      " 299  C249I_Presion                        17544 non-null  float64\n",
      " 300  C619Y_Presion                        17544 non-null  float64\n",
      " 301  C639M_Presion                        17544 non-null  float64\n",
      " 302  C649R_Presion                        17544 non-null  float64\n",
      " 303  C659H_Presion                        17544 non-null  float64\n",
      " 304  C659M_Presion                        17544 non-null  float64\n",
      " 305  0016A_Temperatura                    17544 non-null  float64\n",
      " 306  0201D_Temperatura                    17544 non-null  float64\n",
      " 307  0244X_Temperatura                    17544 non-null  float64\n",
      " 308  0367_Temperatura                     17544 non-null  float64\n",
      " 309  1025X_Temperatura                    17544 non-null  float64\n",
      " 310  1056K_Temperatura                    17544 non-null  float64\n",
      " 311  1074C_Temperatura                    17544 non-null  float64\n",
      " 312  1111X_Temperatura                    17544 non-null  float64\n",
      " 313  1186P_Temperatura                    17544 non-null  float64\n",
      " 314  1279X_Temperatura                    17544 non-null  float64\n",
      " 315  1387E_Temperatura                    17544 non-null  float64\n",
      " 316  1390X_Temperatura                    17544 non-null  float64\n",
      " 317  1466A_Temperatura                    17544 non-null  float64\n",
      " 318  1475X_Temperatura                    17544 non-null  float64\n",
      " 319  1719_Temperatura                     17544 non-null  float64\n",
      " 320  2044B_Temperatura                    17544 non-null  float64\n",
      " 321  2048A_Temperatura                    17544 non-null  float64\n",
      " 322  2331_Temperatura                     17544 non-null  float64\n",
      " 323  2734D_Temperatura                    17544 non-null  float64\n",
      " 324  2777K_Temperatura                    17544 non-null  float64\n",
      " 325  2873X_Temperatura                    17544 non-null  float64\n",
      " 326  2891A_Temperatura                    17544 non-null  float64\n",
      " 327  2946X_Temperatura                    17544 non-null  float64\n",
      " 328  3104Y_Temperatura                    17544 non-null  float64\n",
      " 329  3140Y_Temperatura                    17544 non-null  float64\n",
      " 330  3266A_Temperatura                    17544 non-null  float64\n",
      " 331  3475X_Temperatura                    17544 non-null  float64\n",
      " 332  3504X_Temperatura                    17544 non-null  float64\n",
      " 333  3526X_Temperatura                    17544 non-null  float64\n",
      " 334  3562X_Temperatura                    17544 non-null  float64\n",
      " 335  4096Y_Temperatura                    17544 non-null  float64\n",
      " 336  4340_Temperatura                     17544 non-null  float64\n",
      " 337  5390Y_Temperatura                    17544 non-null  float64\n",
      " 338  5402_Temperatura                     17544 non-null  float64\n",
      " 339  5582A_Temperatura                    17544 non-null  float64\n",
      " 340  5598X_Temperatura                    17544 non-null  float64\n",
      " 341  5612X_Temperatura                    17544 non-null  float64\n",
      " 342  5906X_Temperatura                    17544 non-null  float64\n",
      " 343  5972X_Temperatura                    17544 non-null  float64\n",
      " 344  6045X_Temperatura                    17544 non-null  float64\n",
      " 345  6172X_Temperatura                    17544 non-null  float64\n",
      " 346  6268Y_Temperatura                    17544 non-null  float64\n",
      " 347  6307X_Temperatura                    17544 non-null  float64\n",
      " 348  6312E_Temperatura                    17544 non-null  float64\n",
      " 349  7066Y_Temperatura                    17544 non-null  float64\n",
      " 350  7195X_Temperatura                    17544 non-null  float64\n",
      " 351  7275C_Temperatura                    17544 non-null  float64\n",
      " 352  8025_Temperatura                     17544 non-null  float64\n",
      " 353  8036Y_Temperatura                    17544 non-null  float64\n",
      " 354  8177A_Temperatura                    17544 non-null  float64\n",
      " 355  8270X_Temperatura                    17544 non-null  float64\n",
      " 356  8486X_Temperatura                    17544 non-null  float64\n",
      " 357  8500A_Temperatura                    17544 non-null  float64\n",
      " 358  9016X_Temperatura                    17544 non-null  float64\n",
      " 359  9257X_Temperatura                    17544 non-null  float64\n",
      " 360  9301X_Temperatura                    17544 non-null  float64\n",
      " 361  9352A_Temperatura                    17544 non-null  float64\n",
      " 362  9377Y_Temperatura                    17544 non-null  float64\n",
      " 363  9434_Temperatura                     17544 non-null  float64\n",
      " 364  9573X_Temperatura                    17544 non-null  float64\n",
      " 365  9677_Temperatura                     17544 non-null  float64\n",
      " 366  9814X_Temperatura                    17544 non-null  float64\n",
      " 367  9843A_Temperatura                    17544 non-null  float64\n",
      " 368  9946X_Temperatura                    17544 non-null  float64\n",
      " 369  B275E_Temperatura                    17544 non-null  float64\n",
      " 370  B569X_Temperatura                    17544 non-null  float64\n",
      " 371  B760X_Temperatura                    17544 non-null  float64\n",
      " 372  B925_Temperatura                     17544 non-null  float64\n",
      " 373  C148F_Temperatura                    17544 non-null  float64\n",
      " 374  C249I_Temperatura                    17544 non-null  float64\n",
      " 375  C619Y_Temperatura                    17544 non-null  float64\n",
      " 376  C639M_Temperatura                    17544 non-null  float64\n",
      " 377  C649R_Temperatura                    17544 non-null  float64\n",
      " 378  C659H_Temperatura                    17544 non-null  float64\n",
      " 379  C659M_Temperatura                    17544 non-null  float64\n",
      " 380  0016A_Viento                         17544 non-null  float64\n",
      " 381  0201D_Viento                         17544 non-null  float64\n",
      " 382  0244X_Viento                         17544 non-null  float64\n",
      " 383  0367_Viento                          17544 non-null  float64\n",
      " 384  1025X_Viento                         17544 non-null  float64\n",
      " 385  1056K_Viento                         17544 non-null  float64\n",
      " 386  1074C_Viento                         17544 non-null  float64\n",
      " 387  1111X_Viento                         17544 non-null  float64\n",
      " 388  1186P_Viento                         17544 non-null  float64\n",
      " 389  1279X_Viento                         17544 non-null  float64\n",
      " 390  1387E_Viento                         17544 non-null  float64\n",
      " 391  1390X_Viento                         17544 non-null  float64\n",
      " 392  1466A_Viento                         17544 non-null  float64\n",
      " 393  1475X_Viento                         17544 non-null  float64\n",
      " 394  1719_Viento                          17544 non-null  float64\n",
      " 395  2044B_Viento                         17544 non-null  float64\n",
      " 396  2048A_Viento                         17544 non-null  float64\n",
      " 397  2331_Viento                          17544 non-null  float64\n",
      " 398  2734D_Viento                         17544 non-null  float64\n",
      " 399  2777K_Viento                         17544 non-null  float64\n",
      " 400  2873X_Viento                         17544 non-null  float64\n",
      " 401  2891A_Viento                         17544 non-null  float64\n",
      " 402  2946X_Viento                         17544 non-null  float64\n",
      " 403  3104Y_Viento                         17544 non-null  float64\n",
      " 404  3140Y_Viento                         17544 non-null  float64\n",
      " 405  3266A_Viento                         17544 non-null  float64\n",
      " 406  3475X_Viento                         17544 non-null  float64\n",
      " 407  3504X_Viento                         17544 non-null  float64\n",
      " 408  3526X_Viento                         17544 non-null  float64\n",
      " 409  3562X_Viento                         17544 non-null  float64\n",
      " 410  4096Y_Viento                         17544 non-null  float64\n",
      " 411  4340_Viento                          17544 non-null  float64\n",
      " 412  5390Y_Viento                         17544 non-null  float64\n",
      " 413  5402_Viento                          17544 non-null  float64\n",
      " 414  5582A_Viento                         17544 non-null  float64\n",
      " 415  5598X_Viento                         17544 non-null  float64\n",
      " 416  5612X_Viento                         17544 non-null  float64\n",
      " 417  5906X_Viento                         17544 non-null  float64\n",
      " 418  5972X_Viento                         17544 non-null  float64\n",
      " 419  6045X_Viento                         17544 non-null  float64\n",
      " 420  6172X_Viento                         17544 non-null  float64\n",
      " 421  6268Y_Viento                         17544 non-null  float64\n",
      " 422  6307X_Viento                         17544 non-null  float64\n",
      " 423  6312E_Viento                         17544 non-null  float64\n",
      " 424  7066Y_Viento                         17544 non-null  float64\n",
      " 425  7195X_Viento                         17544 non-null  float64\n",
      " 426  7275C_Viento                         17544 non-null  float64\n",
      " 427  8025_Viento                          17544 non-null  float64\n",
      " 428  8036Y_Viento                         17544 non-null  float64\n",
      " 429  8177A_Viento                         17544 non-null  float64\n",
      " 430  8270X_Viento                         17544 non-null  float64\n",
      " 431  8486X_Viento                         17544 non-null  float64\n",
      " 432  8500A_Viento                         17544 non-null  float64\n",
      " 433  9016X_Viento                         17544 non-null  float64\n",
      " 434  9257X_Viento                         17544 non-null  float64\n",
      " 435  9301X_Viento                         17544 non-null  float64\n",
      " 436  9352A_Viento                         17544 non-null  float64\n",
      " 437  9377Y_Viento                         17544 non-null  float64\n",
      " 438  9434_Viento                          17544 non-null  float64\n",
      " 439  9573X_Viento                         17544 non-null  float64\n",
      " 440  9677_Viento                          17544 non-null  float64\n",
      " 441  9814X_Viento                         17544 non-null  float64\n",
      " 442  9843A_Viento                         17544 non-null  float64\n",
      " 443  9946X_Viento                         17544 non-null  float64\n",
      " 444  B275E_Viento                         17544 non-null  float64\n",
      " 445  B569X_Viento                         17544 non-null  float64\n",
      " 446  B760X_Viento                         17544 non-null  float64\n",
      " 447  B925_Viento                          17544 non-null  float64\n",
      " 448  C148F_Viento                         17544 non-null  float64\n",
      " 449  C249I_Viento                         17544 non-null  float64\n",
      " 450  C619Y_Viento                         17544 non-null  float64\n",
      " 451  C639M_Viento                         17544 non-null  float64\n",
      " 452  C649R_Viento                         17544 non-null  float64\n",
      " 453  C659H_Viento                         17544 non-null  float64\n",
      " 454  C659M_Viento                         17544 non-null  float64\n",
      " 455  0016A_Viento_pred                    17544 non-null  float64\n",
      " 456  0201D_Viento_pred                    17544 non-null  float64\n",
      " 457  0244X_Viento_pred                    17544 non-null  float64\n",
      " 458  0367_Viento_pred                     17544 non-null  float64\n",
      " 459  1025X_Viento_pred                    17544 non-null  float64\n",
      " 460  1056K_Viento_pred                    17544 non-null  float64\n",
      " 461  1074C_Viento_pred                    17544 non-null  float64\n",
      " 462  1111X_Viento_pred                    17544 non-null  float64\n",
      " 463  1186P_Viento_pred                    17544 non-null  float64\n",
      " 464  1279X_Viento_pred                    17544 non-null  float64\n",
      " 465  1387E_Viento_pred                    17544 non-null  float64\n",
      " 466  1390X_Viento_pred                    17544 non-null  float64\n",
      " 467  1466A_Viento_pred                    17544 non-null  float64\n",
      " 468  1475X_Viento_pred                    17544 non-null  float64\n",
      " 469  1719_Viento_pred                     17544 non-null  float64\n",
      " 470  2044B_Viento_pred                    17544 non-null  float64\n",
      " 471  2048A_Viento_pred                    17544 non-null  float64\n",
      " 472  2331_Viento_pred                     17544 non-null  float64\n",
      " 473  2734D_Viento_pred                    17544 non-null  float64\n",
      " 474  2777K_Viento_pred                    17544 non-null  float64\n",
      " 475  2873X_Viento_pred                    17544 non-null  float64\n",
      " 476  2891A_Viento_pred                    17544 non-null  float64\n",
      " 477  2946X_Viento_pred                    17544 non-null  float64\n",
      " 478  3104Y_Viento_pred                    17544 non-null  float64\n",
      " 479  3140Y_Viento_pred                    17544 non-null  float64\n",
      " 480  3266A_Viento_pred                    17544 non-null  float64\n",
      " 481  3475X_Viento_pred                    17544 non-null  float64\n",
      " 482  3504X_Viento_pred                    17544 non-null  float64\n",
      " 483  3526X_Viento_pred                    17544 non-null  float64\n",
      " 484  3562X_Viento_pred                    17544 non-null  float64\n",
      " 485  4096Y_Viento_pred                    17544 non-null  float64\n",
      " 486  4340_Viento_pred                     17544 non-null  float64\n",
      " 487  5390Y_Viento_pred                    17544 non-null  float64\n",
      " 488  5402_Viento_pred                     17544 non-null  float64\n",
      " 489  5582A_Viento_pred                    17544 non-null  float64\n",
      " 490  5598X_Viento_pred                    17544 non-null  float64\n",
      " 491  5612X_Viento_pred                    17544 non-null  float64\n",
      " 492  5906X_Viento_pred                    17544 non-null  float64\n",
      " 493  5972X_Viento_pred                    17544 non-null  float64\n",
      " 494  6045X_Viento_pred                    17544 non-null  float64\n",
      " 495  6172X_Viento_pred                    17544 non-null  float64\n",
      " 496  6268Y_Viento_pred                    17544 non-null  float64\n",
      " 497  6307X_Viento_pred                    17544 non-null  float64\n",
      " 498  6312E_Viento_pred                    17544 non-null  float64\n",
      " 499  7066Y_Viento_pred                    17544 non-null  float64\n",
      " 500  7195X_Viento_pred                    17544 non-null  float64\n",
      " 501  7275C_Viento_pred                    17544 non-null  float64\n",
      " 502  8025_Viento_pred                     17544 non-null  float64\n",
      " 503  8036Y_Viento_pred                    17544 non-null  float64\n",
      " 504  8177A_Viento_pred                    17544 non-null  float64\n",
      " 505  8270X_Viento_pred                    17544 non-null  float64\n",
      " 506  8486X_Viento_pred                    17544 non-null  float64\n",
      " 507  8500A_Viento_pred                    17544 non-null  float64\n",
      " 508  9016X_Viento_pred                    17544 non-null  float64\n",
      " 509  9257X_Viento_pred                    17544 non-null  float64\n",
      " 510  9301X_Viento_pred                    17544 non-null  float64\n",
      " 511  9352A_Viento_pred                    17544 non-null  float64\n",
      " 512  9377Y_Viento_pred                    17544 non-null  float64\n",
      " 513  9434_Viento_pred                     17544 non-null  float64\n",
      " 514  9573X_Viento_pred                    17544 non-null  float64\n",
      " 515  9677_Viento_pred                     17544 non-null  float64\n",
      " 516  9814X_Viento_pred                    17544 non-null  float64\n",
      " 517  9843A_Viento_pred                    17544 non-null  float64\n",
      " 518  9946X_Viento_pred                    17544 non-null  float64\n",
      " 519  B275E_Viento_pred                    17544 non-null  float64\n",
      " 520  B569X_Viento_pred                    17544 non-null  float64\n",
      " 521  B760X_Viento_pred                    17544 non-null  float64\n",
      " 522  B925_Viento_pred                     17544 non-null  float64\n",
      " 523  C148F_Viento_pred                    17544 non-null  float64\n",
      " 524  C249I_Viento_pred                    17544 non-null  float64\n",
      " 525  C619Y_Viento_pred                    17544 non-null  float64\n",
      " 526  C639M_Viento_pred                    17544 non-null  float64\n",
      " 527  C649R_Viento_pred                    17544 non-null  float64\n",
      " 528  C659H_Viento_pred                    17544 non-null  float64\n",
      " 529  C659M_Viento_pred                    17544 non-null  float64\n",
      " 530  Eolica_emi                           17544 non-null  int64  \n",
      " 531  Nuclear_emi                          17544 non-null  int64  \n",
      " 532  Carbon_emi                           17544 non-null  float64\n",
      " 533  Ciclo_combinado_emi                  17544 non-null  float64\n",
      " 534  Hidraulica_emi                       17544 non-null  int64  \n",
      " 535  Intercambios_int_emi                 17544 non-null  int64  \n",
      " 536  Solar_fotovoltaica_emi               17544 non-null  int64  \n",
      " 537  Solar_termica_emi                    17544 non-null  int64  \n",
      " 538  Termica_renovable_emi                17544 non-null  int64  \n",
      " 539  Motores_diesel_emi                   17544 non-null  float64\n",
      " 540  Turbina_de_gas_emi                   17544 non-null  float64\n",
      " 541  Turbina_de_vapor_emi                 17544 non-null  float64\n",
      " 542  Generacion_auxiliar_emi              17544 non-null  float64\n",
      " 543  Cogeneracion_y_residuos_emi          17544 non-null  float64\n",
      " 544  Eolica_gen                           17544 non-null  float64\n",
      " 545  Nuclear_gen                          17544 non-null  int64  \n",
      " 546  Carbon_gen                           17544 non-null  int64  \n",
      " 547  Ciclo_combinado_gen                  17544 non-null  int64  \n",
      " 548  Hidraulica_gen                       17544 non-null  float64\n",
      " 549  Intercambios_int_gen                 17544 non-null  int64  \n",
      " 550  Solar_fotovoltaica_gen               17544 non-null  float64\n",
      " 551  Solar_termica_gen                    17544 non-null  float64\n",
      " 552  Termica_renovable_gen                17544 non-null  int64  \n",
      " 553  Motores_diesel_gen                   17544 non-null  int64  \n",
      " 554  Turbina_de_gas_gen                   17544 non-null  int64  \n",
      " 555  Turbina_de_vapor_gen                 17544 non-null  int64  \n",
      " 556  Generacion_auxiliar_gen              17544 non-null  int64  \n",
      " 557  Cogeneracion_y_residuos_gen          17544 non-null  int64  \n",
      " 558  Real                                 17544 non-null  float64\n",
      " 559  Prevista                             17544 non-null  float64\n",
      " 560  Programada                           17544 non-null  float64\n",
      " 561  file                                 17544 non-null  object \n",
      " 562  Asturias                             17544 non-null  float64\n",
      " 563  Cantabria                            17544 non-null  float64\n",
      " 564  Navarra                              17544 non-null  float64\n",
      " 565  País Vasco                           17544 non-null  float64\n",
      " 566  Cataluña                             17544 non-null  float64\n",
      " 567  Aragón                               17544 non-null  float64\n",
      " 568  Galicia                              17544 non-null  float64\n",
      " 569  Islas Baleares                       17544 non-null  float64\n",
      " 570  La Rioja                             17544 non-null  float64\n",
      " 571  Valencia                             17544 non-null  float64\n",
      " 572  Castilla y León                      17544 non-null  float64\n",
      " 573  Castilla La Mancha                   17544 non-null  float64\n",
      " 574  Extremadura                          17544 non-null  float64\n",
      " 575  Andalucía                            17544 non-null  float64\n",
      " 576  Murcia                               17544 non-null  float64\n",
      " 577  Madrid                               17544 non-null  float64\n",
      " 578  Solar_altitude                       17544 non-null  float64\n",
      " 579  is_weekend                           17544 non-null  int64  \n",
      " 580  Eolica_gen_1day_before               17544 non-null  float64\n",
      " 581  Eolica_gen_2days_before              17544 non-null  float64\n",
      " 582  Eolica_gen_3days_before              17544 non-null  float64\n",
      " 583  Hidraulica_gen_1day_before           17544 non-null  float64\n",
      " 584  Hidraulica_gen_2days_before          17544 non-null  float64\n",
      " 585  Hidraulica_gen_3days_before          17544 non-null  float64\n",
      " 586  Solar_fotovoltaica_gen_1day_before   17544 non-null  float64\n",
      " 587  Solar_fotovoltaica_gen_2days_before  17544 non-null  float64\n",
      " 588  Solar_fotovoltaica_gen_3days_before  17544 non-null  float64\n",
      " 589  Solar_termica_gen_1day_before        17544 non-null  float64\n",
      " 590  Solar_termica_gen_2days_before       17544 non-null  float64\n",
      " 591  Solar_termica_gen_3days_before       17544 non-null  float64\n",
      "dtypes: float64(568), int64(23), object(1)\n",
      "memory usage: 79.2+ MB\n",
      "None\n",
      "                Ano           Mes           Dia          Hora   Minuto  0016A_Altitud  0201D_Altitud  0244X_Altitud  0367_Altitud  1025X_Altitud  1056K_Altitud  1074C_Altitud  1111X_Altitud  1186P_Altitud  1279X_Altitud  1387E_Altitud  1390X_Altitud  1466A_Altitud  1475X_Altitud  1719_Altitud  2044B_Altitud  2048A_Altitud  2331_Altitud  2734D_Altitud  2777K_Altitud  2873X_Altitud  2891A_Altitud  2946X_Altitud  3104Y_Altitud  3140Y_Altitud  3266A_Altitud  3475X_Altitud  3504X_Altitud  3526X_Altitud  3562X_Altitud  4096Y_Altitud  4340_Altitud  5390Y_Altitud  5402_Altitud  5582A_Altitud  5598X_Altitud  5612X_Altitud  5906X_Altitud  5972X_Altitud  6045X_Altitud  6172X_Altitud  6268Y_Altitud  6307X_Altitud  6312E_Altitud  7066Y_Altitud  7195X_Altitud  7275C_Altitud  8025_Altitud  8036Y_Altitud  8177A_Altitud  8270X_Altitud  8486X_Altitud  8500A_Altitud  9016X_Altitud  9257X_Altitud  9301X_Altitud  9352A_Altitud  9377Y_Altitud  9434_Altitud  9573X_Altitud  9677_Altitud  9814X_Altitud  \\\n",
      "count  17544.000000  17544.000000  17544.000000  17544.000000  17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0       17544.0        17544.0   \n",
      "mean    2023.213406      6.519836     15.738714     11.500000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "std        0.674661      3.449649      8.804172      6.922384      0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0           0.0            0.0   \n",
      "min     2022.000000      1.000000      1.000000      0.000000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "25%     2023.000000      4.000000      8.000000      5.750000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "50%     2023.000000      7.000000     16.000000     11.500000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "75%     2024.000000     10.000000     23.000000     17.250000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "max     2024.000000     12.000000     31.000000     23.000000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "\n",
      "       9843A_Altitud  9946X_Altitud  B275E_Altitud  B569X_Altitud  B760X_Altitud  B925_Altitud  C148F_Altitud  C249I_Altitud  C619Y_Altitud  C639M_Altitud  C649R_Altitud  C659H_Altitud  C659M_Altitud  0016A_Humedad_relativa  0201D_Humedad_relativa  0244X_Humedad_relativa  0367_Humedad_relativa  1025X_Humedad_relativa  1056K_Humedad_relativa  1074C_Humedad_relativa  1111X_Humedad_relativa  1186P_Humedad_relativa  1279X_Humedad_relativa  1387E_Humedad_relativa  1390X_Humedad_relativa  1466A_Humedad_relativa  1475X_Humedad_relativa  1719_Humedad_relativa  2044B_Humedad_relativa  2048A_Humedad_relativa  2331_Humedad_relativa  2734D_Humedad_relativa  2777K_Humedad_relativa  2873X_Humedad_relativa  2891A_Humedad_relativa  2946X_Humedad_relativa  3104Y_Humedad_relativa  3140Y_Humedad_relativa  3266A_Humedad_relativa  3475X_Humedad_relativa  3504X_Humedad_relativa  3526X_Humedad_relativa  3562X_Humedad_relativa  4096Y_Humedad_relativa  4340_Humedad_relativa  5390Y_Humedad_relativa  \\\n",
      "count        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000   \n",
      "mean           825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               78.645505               85.298503               73.703971              79.549966               83.341061               87.932414               86.955535               84.639564               82.369211               88.507275               84.361469               90.605800               89.375963               88.018811              88.927185               88.934172               84.555380              85.852212               85.244499               81.782440               83.053693               82.640602               77.558665               84.977518               84.109440               94.236775               72.661909               79.014367               73.680327               72.998705               86.776954              73.741861               74.705176   \n",
      "std              0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0               12.982027                7.321991                9.220527              13.361466               12.949354               11.680500               11.048939                8.768136               15.194815                9.002921                9.570424                5.269272                7.560695               11.288062               9.367725               12.388408               12.526677               9.763116               13.444214               12.316739                7.415661                8.167666               10.775970               14.493382               15.170472                8.549972               12.758881               10.142724               15.405912               11.547168               12.327831              11.834436               10.694130   \n",
      "min            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               35.143417               44.376778               44.055698              35.257401               34.121571               45.781467               44.224327               41.570076               26.824883               51.351650               41.626255               69.196899               48.224895               31.320835              53.042210               35.862324               32.653690              43.500000               42.588963               33.633232               53.116501               48.782921               38.614082               23.211906               24.716419               51.223278               27.438637               41.801983               21.076496               36.332546               32.382313              34.467346               37.831699   \n",
      "25%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               69.355709               84.045591               67.481009              69.158333               74.194418               79.404572               79.047640               79.850397               72.173241               82.498598               78.167864               87.665756               86.605227               83.264822              83.348827               83.629280               77.947329              79.988995               77.839939               75.635609               78.815414               77.627405               72.039148               79.133202               76.291180               90.934404               64.325819               72.744003               63.933352               65.629507               80.770510              65.417509               68.761271   \n",
      "50%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               82.040009               88.000000               75.149952              80.952877               86.333858               91.402016               89.744781               86.704533               86.221016               90.301041               85.052002               91.740906               91.158131               91.158867              89.618397               93.283924               89.886299              88.417191               90.148373               86.548225               84.936806               83.539944               80.797291               89.664982               89.155544               99.345173               74.113888               81.075363               75.596615               75.931007               90.075855              75.838520               75.943535   \n",
      "75%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               89.243284               88.873730               80.633869              90.897900               94.273117               98.646008               96.268223               91.064487               95.250309               95.710987               91.675144               94.470640               94.286194               95.767588              97.387156               98.607418               93.393618              93.041420               94.334354               90.800747               88.641708               89.005104               85.457214               95.388365               95.807928              100.000000               81.967384               86.378958               85.048122               81.950157               96.159042              83.297071               82.492586   \n",
      "max            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0              100.000000               96.201492               92.850372             100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000             100.000000              100.000000              100.000000             100.000000              100.000000               99.131729               97.361641              100.000000               94.833328              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000               94.312561              100.000000              97.440346              100.000000   \n",
      "\n",
      "       5402_Humedad_relativa  5582A_Humedad_relativa  5598X_Humedad_relativa  5612X_Humedad_relativa  5906X_Humedad_relativa  5972X_Humedad_relativa  6045X_Humedad_relativa  6172X_Humedad_relativa  6268Y_Humedad_relativa  6307X_Humedad_relativa  6312E_Humedad_relativa  7066Y_Humedad_relativa  7195X_Humedad_relativa  7275C_Humedad_relativa  8025_Humedad_relativa  8036Y_Humedad_relativa  8177A_Humedad_relativa  8270X_Humedad_relativa  8486X_Humedad_relativa  8500A_Humedad_relativa  9016X_Humedad_relativa  9257X_Humedad_relativa  9301X_Humedad_relativa  9352A_Humedad_relativa  9377Y_Humedad_relativa  9434_Humedad_relativa  9573X_Humedad_relativa  9677_Humedad_relativa  9814X_Humedad_relativa  9843A_Humedad_relativa  9946X_Humedad_relativa  B275E_Humedad_relativa  B569X_Humedad_relativa  B760X_Humedad_relativa  B925_Humedad_relativa  C148F_Humedad_relativa  C249I_Humedad_relativa  C619Y_Humedad_relativa  C639M_Humedad_relativa  C649R_Humedad_relativa  C659H_Humedad_relativa  \\\n",
      "count           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000   \n",
      "mean               80.843474               65.984625               77.721553               71.278969               83.337645               78.539585               69.841095               66.752875               68.890195               64.526055               56.298102               62.965265               67.730889               60.391305              62.182325               68.963085               79.861424               77.134832               75.276632               74.595074               82.451906               90.247060               73.866613               85.167041               80.173777              77.837580               72.373922              83.534727               88.388428               90.161758               68.925591               71.004521               70.477186               77.031025              72.318358               78.359576               76.524213               66.051938               73.697290               68.512010               71.234412   \n",
      "std                11.637168               12.537599               11.789865               14.512291               12.052667                9.779350               10.656257               10.071838                9.992100               19.807887                8.720392               10.673023               19.723460               16.625849              13.979420               16.503389               15.759683               14.935848               14.700770               17.934932               13.347211               10.667925               12.116113                8.522143               14.041692              14.133208               18.927590               7.878008               14.102295               11.068081               13.155611                9.787736               12.391906               10.714328              12.576636                9.094445                8.243105                7.640214                6.874119                6.586608                6.279021   \n",
      "min                37.692486               29.544971               42.347481               25.950035               44.248131               40.709927               34.167091               26.718437               28.022259                7.479774               22.343262               32.434418               11.742886               10.707302              13.668671               15.541855               21.931377               30.822079               25.917404                7.757622               36.054359               39.345749               29.955261               55.516972               29.068771              32.500000                3.610710              43.236923               32.303753               37.843056               11.726532               38.816624               22.912579               42.907055              35.587482               50.042141               39.191170               37.095474               51.824158               46.707489               49.194000   \n",
      "25%                72.671116               56.236443               69.777998               61.495058               74.771177               72.316351               62.982457               61.163270               63.504913               49.027180               53.463772               55.594232               53.412779               47.153008              53.003728               57.764785               69.548813               66.428484               66.390749               63.616263               73.067299               85.759663               66.170622               79.680525               73.350519              67.926935               61.957980              79.889631               81.683283               87.750759               61.245316               64.272018               62.437084               69.073812              62.225524               73.113358               71.896402               61.387473               68.832514               63.859560               67.071508   \n",
      "50%                83.489407               69.057770               78.315510               73.324638               84.654812               80.083447               71.878860               68.868912               70.353279               62.858538               56.500000               62.780642               70.248062               61.238964              65.100990               70.229424               84.382259               77.008659               78.242172               78.870411               85.677258               94.445236               77.019798               87.481106               84.382023              79.793217               76.222572              85.039711               93.894150               94.401333               71.817127               72.540852               73.684387               78.043419              72.306442               79.324535               78.000000               66.713184               73.885296               69.311081               71.679039   \n",
      "75%                89.837851               75.929123               86.141176               81.759026               93.289244               85.824846               78.320145               74.197710               76.229778               80.094517               58.325874               70.866915               83.138556               74.187828              73.385374               81.347984               92.313303               88.737213               84.548050               88.864719               93.056423               97.988979               83.395292               91.725817               90.032566              88.891224               87.323256              88.854485              100.000000               97.144718               78.844570               78.428860               80.002470               85.017656              82.662029               84.603144               82.434813               71.021030               79.152464               73.741716               76.240509   \n",
      "max               100.000000               91.630592              100.000000              100.000000              100.000000              100.000000               92.108795               96.406479               87.178169              100.000000               88.901840               93.853462              100.000000               96.862877              91.209732              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000               93.607864              100.000000              100.000000             100.000000              100.000000             100.000000              100.000000              100.000000               92.716568               91.639984               93.311371              100.000000             100.000000              100.000000               93.166740               97.710999               92.280533               84.835785               85.018021   \n",
      "\n",
      "       C659M_Humedad_relativa  0016A_Precipitacion  0201D_Precipitacion  0244X_Precipitacion  0367_Precipitacion  1025X_Precipitacion  1056K_Precipitacion  1074C_Precipitacion  1111X_Precipitacion  1186P_Precipitacion  1279X_Precipitacion  1387E_Precipitacion  1390X_Precipitacion  1466A_Precipitacion  1475X_Precipitacion  1719_Precipitacion  2044B_Precipitacion  2048A_Precipitacion  2331_Precipitacion  2734D_Precipitacion  2777K_Precipitacion  2873X_Precipitacion  2891A_Precipitacion  2946X_Precipitacion  3104Y_Precipitacion  3140Y_Precipitacion  3266A_Precipitacion  3475X_Precipitacion  3504X_Precipitacion  3526X_Precipitacion  3562X_Precipitacion  4096Y_Precipitacion  4340_Precipitacion  5390Y_Precipitacion  5402_Precipitacion  5582A_Precipitacion  5598X_Precipitacion  5612X_Precipitacion  5906X_Precipitacion  5972X_Precipitacion  6045X_Precipitacion  6172X_Precipitacion  6268Y_Precipitacion  6307X_Precipitacion  6312E_Precipitacion  7066Y_Precipitacion  7195X_Precipitacion  \\\n",
      "count            17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000   \n",
      "mean                73.937804             0.086270             5.799117             0.084422            0.076727             0.109597             0.306239             0.148288             0.219429             0.107739             0.122511             0.294979             0.287854             0.258130             0.755983            0.578420             0.206820             0.111771            0.156214             0.144083             0.075956             0.129096             0.115862             0.093961             0.225793             0.085555             0.448395             0.142831             0.251492             0.227675             0.095650             0.079924            0.096416             0.113967            0.111405             0.096916             0.318046             0.189814             0.096850             0.270403             0.129004             0.155680             0.107539             0.069924            10.913621             0.089270             0.130954   \n",
      "std                  3.736788             1.374799             8.484172             1.363624            1.239648             1.058549             1.134688             1.035027             1.165866             1.094386             1.080889             1.351003             1.260762             1.540217             1.939839            1.799674             1.168006             1.189521            1.140424             1.612680             1.195590             1.233106             1.335515             1.317835             1.005618             1.290313             1.279893             1.590243             1.481956             1.656410             1.544702             1.290607            1.558440             1.492397            1.659046             1.547786             1.578015             1.571832             1.536314             1.828903             1.421918             1.515145             1.454879             1.129484            13.349852             1.442049             1.195240   \n",
      "min                 60.982677             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "25%                 71.405075             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.029266             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "50%                 74.044674             0.000000             0.000000             0.000000            0.000000             0.000000             0.006182             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.096921            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.101011             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "75%                 76.563118             0.000000            18.200000             0.000000            0.000000             0.000000             0.260014             0.038770             0.152167             0.000000             0.000000             0.223184             0.074588             0.051720             0.545405            0.301644             0.176452             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.259023             0.000000             0.392523             0.000000             0.055863             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.364491             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            27.250000             0.000000             0.000000   \n",
      "max                 84.846054            23.650000            19.900000            22.500000           20.700000            17.550000            17.450000            17.500000            18.700000            18.050000            17.450000            21.250000            18.850000            23.850000            22.850000           22.700000            20.050000            19.300000           19.650000            18.600000            20.500000            20.600000            22.400000            21.750000            17.150000            21.950000            16.850000            26.250000            23.550000            25.700000            25.550000            21.700000           26.400000            24.600000           27.150000            25.950000            25.600000            25.400000            25.600000            27.700000            24.800000            24.782608            24.500000            18.650000            27.250000            23.900000            19.850000   \n",
      "\n",
      "       7275C_Precipitacion  8025_Precipitacion  8036Y_Precipitacion  8177A_Precipitacion  8270X_Precipitacion  8486X_Precipitacion  8500A_Precipitacion  9016X_Precipitacion  9257X_Precipitacion  9301X_Precipitacion  9352A_Precipitacion  9377Y_Precipitacion  9434_Precipitacion  9573X_Precipitacion  9677_Precipitacion  9814X_Precipitacion  9843A_Precipitacion  9946X_Precipitacion  B275E_Precipitacion  B569X_Precipitacion  B760X_Precipitacion  B925_Precipitacion  C148F_Precipitacion  C249I_Precipitacion  C619Y_Precipitacion  C639M_Precipitacion  C649R_Precipitacion  C659H_Precipitacion  C659M_Precipitacion  0016A_Presion  0201D_Presion  0244X_Presion  0367_Presion  1025X_Presion  1056K_Presion  1074C_Presion  1111X_Presion  1186P_Presion  1279X_Presion  1387E_Presion  1390X_Presion  1466A_Presion  1475X_Presion  1719_Presion  2044B_Presion  2048A_Presion  2331_Presion  2734D_Presion  2777K_Presion  2873X_Presion  2891A_Presion  2946X_Presion  3104Y_Presion  3140Y_Presion  3266A_Presion  \\\n",
      "count         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   \n",
      "mean              0.089959            0.092795             0.117184             0.079202             0.215752             0.170503             0.090567             0.106948             0.275423             0.094790             0.071674             0.083917            0.102274             0.094026            0.201007             0.577843             0.344400             0.220856             0.088819             0.095017             0.105574            0.089201             0.084306             0.094933             0.095212             0.094453             0.091629             0.166037             0.094156    1006.614252     977.252804     985.597277    999.981778    1035.812160     993.382497    1001.733697    1010.459009     958.134798     942.912221    1001.429373     992.573671    1024.976641    1008.116474   1040.306780     895.236082     881.694108    915.033602     894.915049     915.742427     882.707738     868.261462     937.138042     896.920626     918.711744     847.784480   \n",
      "std               1.358939            1.499219             1.468069             1.279182             1.421547             0.987977             1.463988             1.006781             1.073314             1.175622             1.158436             1.116244            1.357365             1.333767            0.693020             1.539587             1.317198             2.119091             1.427753             1.535106             1.348240            1.439229             1.361748             1.535215             1.540097             1.525360             1.480200             2.044305             1.519918       5.476445       7.599955       6.609672      5.892336       7.229404       8.594393       6.886549       6.587984       7.254397       5.314445       8.553263       7.359677       6.838308       9.956167      8.763675       5.113925       5.093212      5.654577       5.668929       5.654209       6.627094       5.584496       5.884323       6.422975       4.977187       4.984431   \n",
      "min               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000     992.366089     949.485779     964.743591    983.063538     997.990000     958.150818     976.806641     986.516174     936.622559     930.074646     962.035034     955.824158     995.485779     970.484375    996.750000     883.023132     868.765564    894.983398     879.485291     890.274109     859.702454     850.983704     917.551514     876.032593     907.584656     833.643311   \n",
      "25%               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1002.686615     968.475000     981.283859    995.967575    1032.246307     988.083115     998.079941    1006.156403     953.482544     939.567642     997.939453     989.363266    1021.765793    1001.700000   1035.568878     891.322952     877.897263    911.431488     891.041199     912.623840     879.086426     865.239792     933.137497     893.129227     915.257111     844.435928   \n",
      "50%               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.007991             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1006.488434     978.150238     986.059235   1000.070221    1037.249878     994.859924    1003.100616    1010.734467     957.847473     942.041840    1004.164734     994.475311    1026.458130    1010.365326   1041.600952     895.172333     881.989471    915.850189     894.715790     916.239166     883.839813     868.553101     937.685974     897.582153     918.454773     848.212219   \n",
      "75%               0.000000            0.000000             0.000000             0.000000             0.076567             0.000000             0.000000             0.000000             0.259751             0.000000             0.000000             0.000000            0.000000             0.000000            0.119636             0.457875             0.135307             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1010.068298     983.446930     989.980331   1003.922028    1040.510040     999.399033    1006.367859    1015.289383     961.944427     945.551041    1007.079727     997.462631    1029.393127    1015.010147   1045.943237     898.912323     885.372894    919.091141     897.697845     919.564087     887.034073     871.075089     941.187515     901.554733     922.006622     851.416428   \n",
      "max              22.150000           25.050000            24.050000            21.200000            23.550000            16.050000            24.700000            16.650000            17.000000            20.050000            19.600000            19.150000           22.600000            22.100000           10.200000            19.450000            18.850000            21.600000            23.700000            25.650000            22.000000           24.100000            22.550000            26.500000            26.750000            25.200000            24.750000            25.600000            24.900000    1021.202148     995.585205    1002.250305   1017.098450    1050.263794    1010.408813    1015.991089    1026.792114     995.608032     986.618750    1016.074036    1007.719849    1044.007202    1036.501831   1062.736816     908.773560     897.100000    927.990601     933.289001     929.542603     907.490000     907.490000     950.734985     913.570000     932.370972     858.993896   \n",
      "\n",
      "       3475X_Presion  3504X_Presion  3526X_Presion  3562X_Presion  4096Y_Presion  4340_Presion  5390Y_Presion  5402_Presion  5582A_Presion  5598X_Presion  5612X_Presion  5906X_Presion  5972X_Presion  6045X_Presion  6172X_Presion  6268Y_Presion  6307X_Presion  6312E_Presion  7066Y_Presion  7195X_Presion  7275C_Presion  8025_Presion  8036Y_Presion  8177A_Presion  8270X_Presion  8486X_Presion  8500A_Presion  9016X_Presion  9257X_Presion  9301X_Presion  9352A_Presion  9377Y_Presion  9434_Presion  9573X_Presion  9677_Presion  9814X_Presion  9843A_Presion  9946X_Presion  B275E_Presion  B569X_Presion  B760X_Presion  B925_Presion  C148F_Presion  C249I_Presion  C619Y_Presion  C639M_Presion  C649R_Presion  C659H_Presion  C659M_Presion  0016A_Temperatura  0201D_Temperatura  0244X_Temperatura  0367_Temperatura  1025X_Temperatura  1056K_Temperatura  1074C_Temperatura  1111X_Temperatura  1186P_Temperatura  1279X_Temperatura  1387E_Temperatura  1390X_Temperatura  1466A_Temperatura  \\\n",
      "count   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean      978.182358    1022.088209     980.324093     971.959972     958.970244    968.920842     931.726001   1004.652934     776.135546     963.627151    1004.847004     962.037143    1012.914593    1082.939882     999.080664     681.213721    1080.510991     947.321480     931.512748    1079.891410     944.743914   1006.288915    1009.773076     916.244223     952.367380    1027.035862    1009.602701     905.604791    1002.642391     976.772294     884.050188     942.072987    986.699917     879.289106   1099.530471     930.624311     899.860563    1063.415144    1011.156408    1013.196395    1010.904770   1011.572907     941.384272    1014.843741    1016.350211    1019.665010    1014.381467    1020.355702    1015.674169          17.489967          18.770380          20.453208         18.530294          15.427593          16.435829          15.660039          16.364449          16.727039          16.015887          17.629651          15.882819          15.418910   \n",
      "std         5.253027       4.860617       5.855291       3.958558       4.216329      4.027742       3.475018      4.867036       9.398215       3.141394       4.086339       4.639425       3.165797       7.721168       5.561200      15.030891       7.394253       3.153458       3.022272       8.056099       3.959151      4.783542       4.547660       4.186292       6.095021       7.286145       7.498415       6.967444       5.720381       3.390610       3.986678       4.319986      5.180013       6.140727      7.585651       5.092917       5.083053       8.306629       3.431824       3.408402       3.525275      4.330479       3.597388       2.630717       1.762385       2.361539       2.874364       2.999345       2.719656           3.302484           1.620038           1.611769          3.105052           3.101791           3.158015           3.007023           1.846490           3.994400           3.461672           2.213679           2.240891           2.201555   \n",
      "min       959.423035     970.862500     955.227112     957.285767     934.575000    954.535583     922.320312    990.035156     765.530762     951.886047     989.008606     945.097412     980.242615    1002.850000     984.777893     671.704712     985.641667     939.561218     926.313232     989.881250     935.171814    993.696350     998.052856     906.491333     936.578857     930.983333     872.974243     887.746948     972.475000     965.304626     871.060059     914.475000    970.670471     866.347778    976.150000     915.358582     885.355347    1005.100000     999.310181    1003.111206     998.752502    998.169739     933.985535    1008.400000    1011.150000    1009.571429    1006.880188    1009.571429    1007.661194           9.209106          13.724069          15.392507          9.331562           8.075424           7.018330           9.550410          11.091537           6.235204           6.672863          10.656863           7.899129           8.772388   \n",
      "25%       974.632492    1019.830032     976.934433     969.752319     956.082428    966.798859     929.252747   1001.481491     773.595261     961.696198    1002.355347     959.291245    1011.198288    1077.952972     995.238068     678.269257    1077.994049     945.973740     929.190857    1075.890961     942.011215   1002.867050    1006.574997     913.244125     948.327881    1024.631958    1006.046295     902.177795     998.858521     974.912476     881.271774     939.340485    983.441452     875.379028   1100.000122     927.141281     896.366028    1058.921051    1008.934097    1011.085815    1008.539612   1008.740738     939.269470    1012.756836    1015.122742    1017.840347    1012.343079    1018.271484    1013.830933          14.992661          18.200000          19.113176         16.343008          13.017057          14.358105          13.118847          15.012233          13.771352          13.555547          16.187253          14.381362          13.779011   \n",
      "50%       978.435181    1021.785126     981.989288     972.106323     958.596863    969.106293     930.882233   1003.713745     775.752899     963.748627    1004.527863     962.489288    1012.973877    1082.939209     998.339539     680.731781    1081.056274     946.950000     930.728455    1079.659302     943.950165   1005.953583    1009.225159     915.791046     951.422394    1027.783264    1009.910522     905.141632    1002.764709     976.926056     883.793610     941.511749    986.664795     878.901764   1100.000122     931.027740     900.634003    1063.812073    1010.934357    1012.791504    1010.830597   1011.565765     940.958282    1014.492462    1016.039429    1019.106415    1013.835541    1019.902466    1015.338623          17.187369          18.200000          20.376690         18.308249          14.882962          16.114405          15.404482          16.225961          16.384774          15.826605          17.367743          16.110589          15.492554   \n",
      "75%       981.787674    1024.690216     984.354156     974.487991     961.721680    971.620285     933.675232   1008.151367     777.765137     965.898560    1007.570816     964.889557    1014.807434    1087.701538    1002.332230     682.326584    1084.336151     947.312393     933.250092    1084.523468     946.958954   1009.539078    1012.478287     918.691635     955.224838    1030.534729    1013.846512     907.897202    1006.775650     978.925629     886.630753     944.780624    989.808594     882.591721   1100.000122     934.494980     903.618088    1068.642059    1013.134659    1015.174881    1013.295547   1014.245544     942.886185    1016.809479    1017.349579    1021.254456    1016.187485    1022.326355    1017.391373          20.069508          19.784244          21.684522         20.708230          17.426626          18.631975          17.842211          17.542095          19.531332          18.537333          18.808368          17.559852          17.054851   \n",
      "max       990.219971    1033.520508     991.270874     982.035156     971.077942    977.858215     943.090820   1018.321228     921.175000     971.401001    1014.922058     996.007143    1022.048340    1100.000000    1016.390259     921.175000    1091.871216     959.018799     941.973206    1095.334106     958.357239   1019.943787    1022.909363     939.146240     982.516667    1036.435059    1024.199951     978.728572    1016.572693     987.387268     897.100000     956.076233   1001.355530     933.516667   1100.000122     942.693359     920.900000    1077.724365    1021.391663    1024.071045    1019.663147   1023.080688     975.747009    1022.594727    1022.710083    1027.051147    1022.991089    1028.691162    1023.201904          25.365870          23.720308          24.801941         27.454216          29.653635          26.357777          26.198933          22.144009          29.071087          26.330053          27.271729          22.133320          23.850000   \n",
      "\n",
      "       1475X_Temperatura  1719_Temperatura  2044B_Temperatura  2048A_Temperatura  2331_Temperatura  2734D_Temperatura  2777K_Temperatura  2873X_Temperatura  2891A_Temperatura  2946X_Temperatura  3104Y_Temperatura  3140Y_Temperatura  3266A_Temperatura  3475X_Temperatura  3504X_Temperatura  3526X_Temperatura  3562X_Temperatura  4096Y_Temperatura  4340_Temperatura  5390Y_Temperatura  5402_Temperatura  5582A_Temperatura  5598X_Temperatura  5612X_Temperatura  5906X_Temperatura  5972X_Temperatura  6045X_Temperatura  6172X_Temperatura  6268Y_Temperatura  6307X_Temperatura  6312E_Temperatura  7066Y_Temperatura  7195X_Temperatura  7275C_Temperatura  8025_Temperatura  8036Y_Temperatura  8177A_Temperatura  8270X_Temperatura  8486X_Temperatura  8500A_Temperatura  9016X_Temperatura  9257X_Temperatura  9301X_Temperatura  9352A_Temperatura  9377Y_Temperatura  9434_Temperatura  9573X_Temperatura  9677_Temperatura  9814X_Temperatura  9843A_Temperatura  9946X_Temperatura  B275E_Temperatura  \\\n",
      "count       17544.000000      17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean           17.604202         15.709500          12.152934          11.258528         12.424384          13.797902          13.693619          14.585602          14.073021          14.462330          10.236292          13.941308           9.673314          16.510689          15.162141          18.716862          18.115146          13.363093         18.323821          16.635097         19.237422          17.191880          17.880045          18.839378          20.520656          20.223832          18.087552          20.124534          20.968311          13.200191          22.977973          18.628024          14.742133          18.063653         21.764830          21.527819          15.330488          16.315153          12.304849          19.969096          12.382028          12.020784          16.251534          11.842602          11.803982         17.095796          16.129618          4.094196          11.730402          11.841330          16.500180          20.667096   \n",
      "std             2.012191          2.104158           2.855156           3.870807          3.894740           3.347185           3.403999           2.903663           2.386122           3.435158           3.464440           4.232740           2.190034           2.338979           2.692598           3.072061           2.860887           3.019844          3.420430           2.595066          2.697898           4.134224           3.454291           3.431958           1.804940           1.887249           3.645309           1.467471           1.444196           3.757836           3.763338           2.841842           4.254519           3.323264          2.795092           2.889968           3.977368           3.141722           3.298735           3.060675           4.471427           2.962623           3.004662           3.284912           3.712586          2.837490           3.937884          2.676851           3.277672           3.310015           3.319882           2.168583   \n",
      "min            10.800522          9.213299           5.528142           1.097467          1.238998           4.032483           3.276657           6.129852           6.669375           4.529089          -2.571681           3.833361           1.310746          10.209183           6.670433          11.093131          11.029390           3.581458          9.014250           6.408361         11.711831           8.770741           8.870099           9.871223          15.437985          12.654667           8.906227          15.487394          15.691759           3.845679          14.349721           9.966097           3.986917           8.902047         13.657481          14.803053           6.134442           6.581284           3.846155          11.195189           0.124064           5.566590           9.428516           3.859474           1.933386          9.993331           5.996670         -3.659091           2.881428           3.597418           9.786832          14.762064   \n",
      "25%            16.301046         14.254015          10.129621           8.511592          9.776810          11.749185          11.402154          12.488989          12.427768          12.086294           8.317264          10.931274           8.526004          14.877525          13.182480          16.500592          16.016516          11.367220         15.733006          14.902228         17.555050          13.950561          15.459084          16.358899          19.280191          19.202837          15.504602          19.122458          20.019773          10.391383          19.577219          16.606481          11.608628          15.694075         19.673180          19.243611          12.515400          14.072957           9.953700          17.636591           9.224771           9.808533          14.158523           9.485501           9.137678         14.987630          13.376353          2.429696           9.632200           9.716738          14.058077          18.993347   \n",
      "50%            17.494437         15.708643          11.750570          10.574811         12.007071          13.190019          12.962425          14.626769          14.261396          14.415085          10.160548          12.970313           9.788213          16.079656          14.994461          18.366067          17.721582          13.153453         18.212631          16.770646         19.039738          16.405367          17.302588          17.969643          20.402181          20.058752          17.413295          19.991214          21.059481          12.886318          22.068759          18.453574          13.973454          17.749334         21.682583          21.101799          14.256949          15.995227          11.742260          19.399300          12.204132          11.648264          15.714405          11.176358          11.146039         16.731733          15.659365          4.394750          11.331325          11.472409          15.758046          20.677589   \n",
      "75%            18.764968         17.281470          13.868133          13.440237         14.842039          15.518197          15.508738          16.782843          15.718676          16.565770          11.934982          16.407528          11.063738          17.794713          16.846859          20.625689          20.024064          15.160230         20.657561          17.865079         21.002017          19.963594          19.883599          21.071764          21.662644          21.179765          20.062195          20.968554          22.035738          15.904459          27.250000          20.522395          17.638625          20.406354         23.779818          23.709703          17.932578          18.272719          14.187555          22.186184          15.509917          13.896821          18.015180          13.832473          13.744866         18.841123          18.589514          6.188663          13.246682          13.685354          18.486175          22.456505   \n",
      "max            24.922523         22.700000          22.651524          26.387339         24.050709          25.494793          26.770939          22.092087          22.400000          24.363865          22.255838          28.357948          16.850000          26.250000          23.550000          29.267820          28.075588          24.471287         28.790947          25.220070         29.241638          28.805784          29.312561          29.956688          26.455339          27.700000          31.344837          26.799393          25.327328          24.299139          27.250000          28.008907          28.096182          28.659342         29.971210          28.957285          27.564781          28.460930          24.085773          30.013544          25.595163          22.743074          26.838495          22.942966          24.660479         27.190504          30.258717         10.200000          24.747490          23.148859          28.849724          25.698637   \n",
      "\n",
      "       B569X_Temperatura  B760X_Temperatura  B925_Temperatura  C148F_Temperatura  C249I_Temperatura  C619Y_Temperatura  C639M_Temperatura  C649R_Temperatura  C659H_Temperatura  C659M_Temperatura  0016A_Viento  0201D_Viento  0244X_Viento   0367_Viento  1025X_Viento  1056K_Viento  1074C_Viento  1111X_Viento  1186P_Viento  1279X_Viento  1387E_Viento  1390X_Viento  1466A_Viento  1475X_Viento   1719_Viento  2044B_Viento  2048A_Viento   2331_Viento  2734D_Viento  2777K_Viento  2873X_Viento  2891A_Viento  2946X_Viento  3104Y_Viento  3140Y_Viento  3266A_Viento  3475X_Viento  3504X_Viento  3526X_Viento  3562X_Viento  4096Y_Viento   4340_Viento  5390Y_Viento   5402_Viento  5582A_Viento  5598X_Viento  5612X_Viento  5906X_Viento  5972X_Viento  6045X_Viento  6172X_Viento  6268Y_Viento  6307X_Viento  6312E_Viento  7066Y_Viento  7195X_Viento  7275C_Viento   8025_Viento  8036Y_Viento  8177A_Viento  8270X_Viento  8486X_Viento  8500A_Viento  9016X_Viento  9257X_Viento  9301X_Viento  9352A_Viento  \\\n",
      "count       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000   \n",
      "mean           22.175810          19.457712         21.104257          19.859160          22.777946          23.088667          23.471840          23.229189          22.320892          23.295468      3.566689      3.083995      2.060858      3.082791      1.378386      2.237893      1.670337      4.692886      1.543998      1.961286      3.858413      4.068246      2.090287      1.250848      2.335673      3.331115      3.622886      4.601094      2.624350      2.567130      2.979754      3.311218      2.775559      1.190698      2.287510      4.532285      3.459781      2.017870      2.699864      2.480564      1.758413      2.617510      2.608071      2.609713      2.039537      3.056088      2.400275      3.151792      3.214833      2.046058      2.533365      2.551456      3.418905      3.060055      2.501297      2.714915      2.983721      2.168673      1.969083      3.698632      1.976334      4.247606      2.260876      2.393335      2.549918      2.549918      4.657127   \n",
      "std             1.187085           2.793852          2.621041           2.023586           1.386558           1.760407           1.649422           1.394975           1.005794           1.065554      1.788271      1.221325      0.937617      1.474555      0.834112      1.044251      0.954031      2.252141      1.366792      1.183998      1.676486      1.707074      1.067278      0.680950      0.984947      1.529467      1.948656      1.977438      1.429239      1.583025      1.559272      1.716609      1.232713      0.871661      0.976504      2.429797      1.653960      0.979043      1.316941      1.292564      0.807034      1.333638      1.008313      1.307442      0.807340      1.307723      0.941489      1.358722      1.460060      0.860881      1.073682      1.549198      1.876561      1.025727      1.118278      0.855564      1.452967      0.751247      0.842957      1.645469      0.996617      2.458352      0.755160      1.224393      1.090900      1.090900      2.395900   \n",
      "min            18.977245          10.938687         13.592285          15.553852          18.225531          17.152431          20.034756          20.064423          19.554756          20.974348      0.800000      0.800000      0.300000      0.000000      0.000000      0.300000      0.000000      1.100000      0.000000      0.000000      0.600000      1.170000      0.300000      0.000000      0.700000      0.600000      0.000000      0.800000      0.600000      0.000000      0.300000      0.300000      0.600000      0.000000      0.750000      0.000000      0.000000      0.300000      0.600000      0.000000      0.000000      0.300000      0.800000      0.000000      0.000000      0.600000      0.821429      0.300000      0.300000      0.000000      0.300000      0.300000      0.600000      0.800000      0.528571      0.923810      0.800000      0.600000      0.600000      0.600000      0.000000      0.300000      0.800000      0.000000      0.547059      0.547059      0.300000   \n",
      "25%            21.290448          17.564327         19.028690          18.358079          21.731564          21.791207          22.069849          22.084247          21.599735          22.462121      2.500000      2.200000      1.400000      1.900000      0.800000      1.700000      1.100000      3.100000      0.800000      1.100000      2.800000      2.772727      1.400000      0.800000      1.688889      2.200000      2.200000      3.100000      1.700000      1.400000      1.700000      2.200000      1.900000      0.600000      1.600000      2.800000      2.200000      1.400000      1.700000      1.400000      1.100000      1.700000      1.900000      1.700000      1.400000      2.200000      1.740000      2.200000      2.200000      1.400000      1.700000      1.400000      2.200000      2.200000      1.750000      2.133333      1.900000      1.700000      1.400000      2.500000      1.400000      2.500000      1.700000      1.700000      1.658824      1.658824      2.800000   \n",
      "50%            22.038592          19.243238         21.210130          19.282922          22.650744          22.852086          23.188914          22.885611          22.276049          23.162720      3.100000      2.500000      1.900000      2.800000      1.100000      1.900000      1.400000      4.200000      1.100000      1.700000      3.600000      3.710000      1.900000      1.100000      2.088889      3.100000      3.300000      4.400000      2.500000      2.200000      2.800000      3.100000      2.500000      1.100000      2.133333      3.900000      3.300000      1.900000      2.500000      2.200000      1.700000      2.500000      2.500000      2.500000      1.900000      2.800000      2.226667      3.100000      3.100000      1.900000      2.200000      1.900000      3.100000      3.600000      2.325000      2.609524      2.500000      1.900000      1.700000      3.600000      1.900000      3.600000      2.200000      2.200000      2.482353      2.482353      4.200000   \n",
      "75%            22.869579          21.500885         22.936416          21.026951          23.743445          24.403316          24.786349          24.491677          22.949311          24.080912      3.900000      3.900000      2.500000      3.900000      1.700000      2.500000      2.200000      5.800000      1.700000      2.200000      4.700000      4.927273      2.500000      1.700000      2.688889      4.200000      4.700000      5.800000      3.300000      3.600000      3.900000      4.200000      3.300000      1.400000      2.783333      5.800000      4.400000      2.500000      3.300000      3.300000      2.200000      3.300000      3.300000      3.300000      2.500000      3.900000      2.921429      3.900000      3.900000      2.500000      3.100000      3.300000      4.200000      3.600000      3.012500      3.128571      3.600000      2.500000      2.200000      4.700000      2.500000      5.300000      2.500000      3.100000      3.276471      3.276471      6.100000   \n",
      "max            26.307381          29.159519         29.609585          27.030048          28.227129          27.728361          28.512505          26.828087          25.985081          26.754694     13.100000     11.400000      6.900000      8.600000      6.700000      6.400000      5.800000     16.100000     10.800000      7.500000     10.800000     11.563636      6.700000      4.890000      6.888889     10.300000     12.800000     12.500000      8.300000      8.900000      9.700000     10.300000      8.100000      5.300000      6.616667     16.400000     10.600000      8.300000      9.700000      9.200000      5.300000      8.900000      6.900000     10.600000      7.438462      8.900000      7.385714      8.100000      9.200000      6.700000      6.400000      9.200000     13.900000      8.600000      8.375000      7.414286     10.000000      6.400000      6.700000     10.600000      8.300000     14.700000      7.500000      8.100000      6.341176      6.341176     14.400000   \n",
      "\n",
      "       9377Y_Viento   9434_Viento  9573X_Viento   9677_Viento  9814X_Viento  9843A_Viento  9946X_Viento  B275E_Viento  B569X_Viento  B760X_Viento   B925_Viento  C148F_Viento  C249I_Viento  C619Y_Viento  C639M_Viento  C649R_Viento  C659H_Viento  C659M_Viento  0016A_Viento_pred  0201D_Viento_pred  0244X_Viento_pred  0367_Viento_pred  1025X_Viento_pred  1056K_Viento_pred  1074C_Viento_pred  1111X_Viento_pred  1186P_Viento_pred  1279X_Viento_pred  1387E_Viento_pred  1390X_Viento_pred  1466A_Viento_pred  1475X_Viento_pred  1719_Viento_pred  2044B_Viento_pred  2048A_Viento_pred  2331_Viento_pred  2734D_Viento_pred  2777K_Viento_pred  2873X_Viento_pred  2891A_Viento_pred  2946X_Viento_pred  3104Y_Viento_pred  3140Y_Viento_pred  3266A_Viento_pred  3475X_Viento_pred  3504X_Viento_pred  3526X_Viento_pred  3562X_Viento_pred  4096Y_Viento_pred  4340_Viento_pred  5390Y_Viento_pred  5402_Viento_pred  5582A_Viento_pred  5598X_Viento_pred  5612X_Viento_pred  5906X_Viento_pred  5972X_Viento_pred  \\\n",
      "count  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000       17544.000000       1.754400e+04       1.754400e+04      17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04       17544.000000      17544.000000       17544.000000       1.754400e+04      1.754400e+04       1.754400e+04       17544.000000       1.754400e+04       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       1.754400e+04      17544.000000       17544.000000      17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean       3.121012      4.441040      2.622982      5.154408      1.708892      0.937483      3.054909      3.074419      4.120703      1.700649      1.823556      2.839261      6.014727      5.543107      2.702736      3.959371      3.830369      2.082763           3.502574       3.054826e+00       2.093478e+00          2.863463       1.031352e+00           1.947906       1.150054e+00           4.654116       1.329484e+00           1.216716           4.068267           3.403831       1.678753e+00           1.519296          2.198826           3.432234       2.924124e+00      3.798754e+00       1.702220e+00           1.616963       2.679557e+00       2.796130e+00           2.397041           0.680294           1.508194           4.750925       4.087664e+00           1.673326       2.751048e+00           3.152891       1.360146e+00          2.693929           2.101242          2.395552       1.455887e+00           2.858989           2.199925           3.690791           3.308808   \n",
      "std        1.545910      2.550068      1.654951      2.781921      1.351560      0.592922      1.269931      1.080546      2.612561      1.030439      1.008613      0.851002      2.136947      2.465146      0.729031      1.510392      1.793071      1.014482           1.695044       1.493670e+00       1.106617e+00          1.273009       8.529574e-01           1.099124       1.121743e+00           1.841026       1.124715e+00           0.773667           1.821747           0.985485       1.100548e+00           0.652917          1.366796           1.412604       1.562717e+00      1.840021e+00       9.494523e-01           1.133712       1.908050e+00       1.630094e+00           1.200222           0.569684           0.698808           1.851237       1.682830e+00           0.939994       1.801133e+00           1.542633       5.819541e-01          1.265801           0.652193          1.080223       5.182822e-01           1.468373           0.983901           1.807052           1.223006   \n",
      "min        0.000000      0.300000      0.300000      0.000000      0.000000      0.000000      1.000000      0.300000      0.000000      0.000000      0.300000      1.100000      1.900000      1.100000      0.800000      0.600000      0.000000      0.000000           0.930373      -4.768372e-08      -7.152558e-08          0.872286      -2.384186e-08           0.393672      -3.576279e-08           0.618887      -1.192093e-08           0.071303           0.685538           1.405635       1.192093e-07           0.000000          0.029825           1.034376      -1.907349e-07     -9.536743e-08      -7.152558e-08           0.000000       2.384186e-07      -1.430512e-07           0.461356           0.000000           0.011601           0.111854      -1.430512e-07           0.463061      -9.536743e-08           0.007112       4.768372e-08          0.553799           0.618831          0.259464      -1.430512e-07           0.248019           0.247877           0.136652           0.615769   \n",
      "25%        1.900000      2.500000      1.400000      3.300000      0.800000      0.600000      2.157143      2.200000      2.500000      1.100000      1.100000      2.200000      4.200000      3.600000      2.200000      2.800000      2.500000      1.400000           2.405411       2.368129e+00       1.243448e+00          1.872667       4.505958e-01           1.246473       4.666421e-01           3.346554       5.983505e-01           0.624921           2.791798           2.727972       9.729265e-01           1.068194          1.314782           2.296774       1.915791e+00      2.469829e+00       9.161426e-01           0.888215       1.281017e+00       1.683555e+00           1.453040           0.288449           1.035524           3.574698       2.832839e+00           1.220018       1.523649e+00           2.026030       9.669124e-01          1.908180           1.707514          1.748925       1.116567e+00           1.741931           1.456883           2.225953           2.354108   \n",
      "50%        2.800000      3.900000      2.200000      4.400000      1.400000      0.800000      2.800000      3.100000      3.600000      1.700000      1.700000      2.800000      5.800000      5.000000      2.800000      4.200000      3.900000      1.900000           2.781387       2.737892e+00       1.924190e+00          2.575836       7.719551e-01           1.549044       7.707570e-01           4.129161       9.159085e-01           0.973346           3.551844           3.169767       1.406674e+00           1.439278          1.883941           3.198754       2.710014e+00      3.652136e+00       1.407724e+00           1.316244       2.184665e+00       2.514146e+00           2.066940           0.567969           1.456435           4.341561       3.938899e+00           1.437954       2.226022e+00           2.881435       1.221724e+00          2.378489           2.075264          2.219876       1.449691e+00           2.515260           2.007789           3.313184           3.170051   \n",
      "75%        3.900000      5.800000      3.300000      6.700000      2.200000      1.400000      3.528571      3.600000      5.000000      2.200000      2.200000      3.300000      7.500000      7.200000      3.100000      5.300000      5.000000      2.800000           4.146969       3.182052e+00       2.793903e+00          3.545115       1.386682e+00           2.299429       1.309654e+00           5.511336       1.702399e+00           1.620648           4.791794           3.857039       2.107288e+00           1.908223          2.564327           4.366620       3.613290e+00      4.851503e+00       2.292380e+00           1.969712       3.567029e+00       3.648388e+00           3.107151           0.911896           1.893628           5.522279       5.187990e+00           1.741781       3.467566e+00           3.971207       1.652332e+00          3.099040           2.300103          2.768104       1.791480e+00           3.701739           2.783813           4.985096           4.161756   \n",
      "max       10.300000     13.900000      9.700000     17.500000     10.300000      3.600000      8.057143      8.600000     21.700000      6.700000      7.200000      7.200000     13.100000     13.900000      6.900000      7.500000      9.200000      6.100000          12.013194       1.182693e+01       6.061497e+00          8.793547       6.915824e+00           8.135352       7.100425e+00          13.919512       8.171537e+00           4.751741          12.210758           8.745016       8.746185e+00           4.445849         11.506269           9.003029       1.116309e+01      1.325397e+01       6.073560e+00           9.335615       1.200705e+01       9.755122e+00           7.052167           4.059801           5.163090          12.833286       9.753407e+00          10.730083       1.459449e+01          10.061859       4.454509e+00          9.215698           5.481841          8.783508       3.435004e+00           9.332878           6.114094           9.133139           7.414166   \n",
      "\n",
      "       6045X_Viento_pred  6172X_Viento_pred  6268Y_Viento_pred  6307X_Viento_pred  6312E_Viento_pred  7066Y_Viento_pred  7195X_Viento_pred  7275C_Viento_pred  8025_Viento_pred  8036Y_Viento_pred  8177A_Viento_pred  8270X_Viento_pred  8486X_Viento_pred  8500A_Viento_pred  9016X_Viento_pred  9257X_Viento_pred  9301X_Viento_pred  9352A_Viento_pred  9377Y_Viento_pred  9434_Viento_pred  9573X_Viento_pred  9677_Viento_pred  9814X_Viento_pred  9843A_Viento_pred  9946X_Viento_pred  B275E_Viento_pred  B569X_Viento_pred  B760X_Viento_pred  B925_Viento_pred  C148F_Viento_pred  C249I_Viento_pred  C619Y_Viento_pred  C639M_Viento_pred  C649R_Viento_pred  C659H_Viento_pred  C659M_Viento_pred  Eolica_emi  Nuclear_emi    Carbon_emi  Ciclo_combinado_emi  Hidraulica_emi  Intercambios_int_emi  Solar_fotovoltaica_emi  Solar_termica_emi  Termica_renovable_emi  Motores_diesel_emi  Turbina_de_gas_emi  Turbina_de_vapor_emi  Generacion_auxiliar_emi  Cogeneracion_y_residuos_emi    Eolica_gen   Nuclear_gen  \\\n",
      "count       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       1.754400e+04       1.754400e+04       17544.000000       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000      1.754400e+04       1.754400e+04      1.754400e+04       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04      1.754400e+04       17544.000000       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04     17544.0      17544.0  17544.000000         17544.000000         17544.0               17544.0                 17544.0            17544.0                17544.0        17544.000000        17544.000000          17544.000000             17544.000000                 17544.000000  17544.000000  17544.000000   \n",
      "mean            1.865158           2.709366           2.700732           3.124711           2.082592           2.394795           2.359891           2.875419          1.823194           2.372697       2.661456e+00       1.454021e+00           4.561255           2.352710       1.669170e+00           2.366235           2.211951           3.988125           2.755274      2.581999e+00       1.889652e+00      5.608468e+00           0.998021       5.037560e-01           2.322657           2.528423           4.950884       1.108113e+00      1.501856e+00           2.504380           6.561965       5.255149e+00           2.306585           3.848910           3.826168       5.093732e-01         0.0          0.0    406.556498          1951.771719             0.0                   0.0                     0.0                0.0                    0.0          197.824544           84.262332            129.414878                -0.481487                   522.167362   7090.423424   6131.148199   \n",
      "std             0.658790           1.206750           1.581191           1.412589           0.965062           0.716391           1.203238           1.405209          0.932994           0.963338       1.129467e+00       1.092955e+00           2.559706           0.856766       8.571942e-01           0.986332           0.721111           1.506682           1.103817      1.837516e+00       1.382891e+00      1.963084e+00           0.900788       4.543699e-01           1.237326           0.989330           1.867884       8.823155e-01      7.857791e-01           0.693882           1.257182       1.751829e+00           0.910522           1.123061           0.925837       5.921536e-01         0.0          0.0    186.870420          1092.248812             0.0                   0.0                     0.0                0.0                    0.0           42.098668           53.934862             37.745711                 5.084623                   108.430299   4070.266947    967.099452   \n",
      "min             0.092406           0.035823           0.204197           0.389800           0.930947           1.114078           0.302807           0.480837          0.008742           0.560222       1.430512e-07      -1.192093e-07           0.519294           0.000000       2.384186e-08           0.448436           0.865277           0.226453           0.082034     -4.768372e-08       4.768372e-08     -1.907349e-07           0.103416      -5.960465e-09           0.297869           0.985805           0.042060      -1.430512e-07     -1.430512e-07           0.300860           2.192507      -5.722046e-07           0.524536           0.519669           1.024795      -2.980232e-09         0.0          0.0      0.000000           420.000000             0.0                   0.0                     0.0                0.0                    0.0           97.000000            0.000000             50.000000               -10.200000                   248.000000    230.000000   3182.000000   \n",
      "25%             1.366765           1.847467           1.416246           2.015932           1.463399           1.868325           1.426366           1.848651          1.092009           1.531584       1.870265e+00       7.085955e-01           2.800054           1.724072       9.915155e-01           1.600827           1.665384           2.985022           1.904739      1.374174e+00       9.178240e-01      4.067207e+00           0.459281       2.687879e-01           1.455889           1.813106           3.851011       3.747150e-01      9.619623e-01           2.060631           5.673308       3.950123e+00           1.532702           3.081089           3.189215       1.034051e-02         0.0          0.0    248.000000          1087.000000             0.0                   0.0                     0.0                0.0                    0.0          166.000000           40.000000            109.000000                -2.000000                   443.000000   3825.750000   5206.000000   \n",
      "50%             1.774779           2.439348           2.363294           2.847945           1.606271           2.244938           2.075258           2.512853          1.578446           2.233920       2.620764e+00       1.198556e+00           3.677251           2.166882       1.422052e+00           2.190168           2.030777           3.765626           2.596174      2.136026e+00       1.377830e+00      5.329531e+00           0.672981       3.911455e-01           1.853972           2.094728           4.630023       1.009905e+00      1.387929e+00           2.473274           6.509245       5.252019e+00           2.083751           3.902415           3.735010       3.078863e-01         0.0          0.0    339.000000          1643.000000             0.0                   0.0                     0.0                0.0                    0.0          199.000000           71.000000            117.000000                 0.000000                   541.500000   6394.000000   6470.000000   \n",
      "75%             2.330174           3.299323           3.647673           3.954103           2.421060           2.796731           3.105172           3.603674          2.447649           3.056704       3.338524e+00       1.948196e+00           5.403150           2.775839       2.222895e+00           2.959257           2.598284           4.713784           3.447564      3.253609e+00       2.525415e+00      7.118515e+00           1.114335       5.253567e-01           2.841559           3.121076           5.718204       1.731261e+00      1.972326e+00           2.899246           7.370386       6.477822e+00           3.090322           4.676681           4.352696       7.671019e-01         0.0          0.0    500.000000          2612.250000             0.0                   0.0                     0.0                0.0                    0.0          228.000000          118.000000            151.000000                 0.000000                   606.000000   9766.000000   6979.000000   \n",
      "max             4.292424           9.071002           8.903175           8.937109           8.299777           5.431123           7.718726           9.267033          6.522239           6.503942       7.043380e+00       7.540772e+00          15.620208           7.392799       6.813485e+00           6.996884           5.639403          16.023735           7.899948      1.191945e+01       8.143102e+00      1.232651e+01           6.648502       4.145511e+00           7.476842           6.823880          13.377789       7.241610e+00      4.769161e+00           6.410732          11.299067       1.041230e+01           5.309681           6.897284           7.968153       3.296067e+00         0.0          0.0    878.000000          4886.000000             0.0                   0.0                     0.0                0.0                    0.0          321.000000          230.000000            216.000000               156.000000                   754.000000  18649.500000   7119.000000   \n",
      "\n",
      "         Carbon_gen  Ciclo_combinado_gen  Hidraulica_gen  Intercambios_int_gen  Solar_fotovoltaica_gen  Solar_termica_gen  Termica_renovable_gen  Motores_diesel_gen  Turbina_de_gas_gen  Turbina_de_vapor_gen  Generacion_auxiliar_gen  Cogeneracion_y_residuos_gen          Real      Prevista    Programada      Asturias     Cantabria       Navarra    País Vasco      Cataluña        Aragón       Galicia  Islas Baleares      La Rioja      Valencia  Castilla y León  Castilla La Mancha   Extremadura     Andalucía        Murcia        Madrid  Solar_altitude    is_weekend  Eolica_gen_1day_before  Eolica_gen_2days_before  Eolica_gen_3days_before  Hidraulica_gen_1day_before  Hidraulica_gen_2days_before  Hidraulica_gen_3days_before  Solar_fotovoltaica_gen_1day_before  Solar_fotovoltaica_gen_2days_before  Solar_fotovoltaica_gen_3days_before  Solar_termica_gen_1day_before  Solar_termica_gen_2days_before  Solar_termica_gen_3days_before  \n",
      "count  17544.000000         17544.000000    17544.000000          17544.000000            17544.000000       17544.000000           17544.000000        17544.000000        17544.000000          17544.000000             17544.000000                 17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000    17544.000000  17544.000000  17544.000000     17544.000000        17544.000000  17544.000000  17544.000000  17544.000000  17544.000000    17544.000000  17544.000000            17544.000000             17544.000000             17544.000000                17544.000000                 17544.000000                 17544.000000                        17544.000000                         17544.000000                         17544.000000                   17544.000000                    17544.000000                    17544.000000  \n",
      "mean     442.173906          5022.660454     2833.230186          -1608.621751             4404.033915         493.703575             435.113657          290.902189           84.615310            144.657832                -0.711069                  1868.015105  27876.522344  27900.049191  27933.161423      0.547439      0.584148      0.539761      0.619689      0.497620      0.451877      0.556311        0.443983      0.517853      0.425188         0.485263            0.405453      0.392776      0.350409      0.378957      0.407795       15.710192      0.285910             7082.355252              7072.459448              7068.130560                 2834.659962                  2837.824805                  2840.338371                         4400.622321                          4396.464432                          4394.217282                     493.665671                      493.088607                      492.780525  \n",
      "std      244.423468          3056.857537     3010.507817           2155.902834             5678.263321         576.136772              91.264443           61.953186           75.847646             44.425835                 7.476221                   387.460523   4438.707024   4423.429476   4456.988054      0.370360      0.379620      0.382336      0.381871      0.325386      0.347191      0.358586        0.341983      0.395463      0.332800         0.343812            0.348163      0.378472      0.323767      0.369518      0.403726       20.564777      0.451859             4067.469921              4066.923253              4067.296149                 3008.952485                  3006.210678                  3003.309842                         5674.449976                          5669.242506                          5667.008439                     576.268385                      576.042017                      576.000678  \n",
      "min        0.000000           958.000000    -3732.000000          -8088.000000                0.000000           0.000000             188.000000           71.000000           -4.000000              0.000000               -15.000000                    33.000000  17180.000000  17236.000000  17065.000000      0.000000      0.002832      0.000000      0.000000      0.000439      0.000000      0.001197        0.000000      0.000000      0.000000         0.000000            0.000000      0.000000      0.001261      0.000000      0.000000        0.000000      0.000000              230.000000               230.000000               230.000000                -3732.000000                 -3732.000000                 -3732.000000                            0.000000                             0.000000                             0.000000                       0.000000                        0.000000                        0.000000  \n",
      "25%      261.000000          2669.000000      673.750000          -3192.000000               24.000000          15.000000             394.000000          244.000000           41.000000            121.000000                -3.000000                  1586.000000  24149.750000  24204.750000  24191.750000      0.173597      0.186881      0.139870      0.222861      0.191865      0.118682      0.195149        0.125383      0.077836      0.117411         0.148319            0.064437      0.018908      0.057680      0.039104      0.004422        0.000000      0.000000             3822.750000              3814.750000              3808.750000                  676.000000                   682.750000                   688.000000                           24.000000                            24.000000                            24.000000                      15.000000                       15.000000                       15.000000  \n",
      "50%      357.000000          4147.000000     2579.000000          -1516.000000              203.000000         239.000000             442.000000          293.000000           71.000000            130.000000                 0.000000                  1937.000000  27946.500000  27970.500000  28028.000000      0.586003      0.685937      0.587515      0.769590      0.459378      0.394526      0.607348        0.380752      0.557221      0.352902         0.458889            0.329503      0.269328      0.238653      0.231769      0.266267        1.721577      0.000000             6384.500000              6365.000000              6356.000000                 2578.000000                  2580.500000                  2582.000000                          203.000000                           203.000000                           203.000000                     239.000000                      238.000000                      238.000000  \n",
      "75%      526.000000          6748.250000     4885.250000            -13.750000             9150.000000         746.000000             490.000000          336.000000          115.000000            168.000000                 0.000000                  2167.000000  31099.000000  31118.000000  31178.250000      0.932515      0.966022      0.941814      0.982746      0.810274      0.790150      0.916627        0.763804      0.941529      0.726136         0.826517            0.735617      0.777061      0.620561      0.734781      0.861734       28.918652      1.000000             9751.250000              9738.000000              9735.000000                 4884.250000                  4881.250000                  4877.750000                         9146.250000                          9143.250000                          9140.750000                     746.000000                      746.000000                      746.000000  \n",
      "max     4820.000000         17969.000000    11363.500000           5240.000000            20278.000000        1855.000000            5418.000000          475.000000         5512.000000            279.000000               229.000000                  2697.000000  41281.000000  41358.000000  41108.000000      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000        1.000000      1.000000      1.000000         1.000000            1.000000      1.000000      1.000000      1.000000      1.000000       72.814595      1.000000            18649.500000             18649.500000             18649.500000                11363.500000                 11363.500000                 11363.500000                        20278.000000                         20278.000000                         20278.000000                    1855.000000                     1855.000000                     1855.000000  \n",
      "Index(['Ano', 'Mes', 'Dia', 'Hora', 'Minuto', '0016A_Altitud', '0201D_Altitud', '0244X_Altitud', '0367_Altitud', '1025X_Altitud',\n",
      "       ...\n",
      "       'Eolica_gen_3days_before', 'Hidraulica_gen_1day_before', 'Hidraulica_gen_2days_before', 'Hidraulica_gen_3days_before', 'Solar_fotovoltaica_gen_1day_before', 'Solar_fotovoltaica_gen_2days_before', 'Solar_fotovoltaica_gen_3days_before', 'Solar_termica_gen_1day_before', 'Solar_termica_gen_2days_before', 'Solar_termica_gen_3days_before'], dtype='object', length=592)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735055947.836982   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.892591   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.905551   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.906371   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.906696   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.906966   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.999497   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735055947.999909   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 15:59:08.000106: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1735055948.000262   18764 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 15:59:08.000459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ multi_head_attention      │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │      \u001B[32m6,703,919\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],     │\n",
      "│ (\u001B[94mMultiHeadAttention\u001B[0m)      │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],     │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_1 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │              \u001B[32m0\u001B[0m │ multi_head_attention[\u001B[32m…\u001B[0m │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ add (\u001B[94mAdd\u001B[0m)                 │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │              \u001B[32m0\u001B[0m │ dropout_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],       │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ layer_normalization       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │            \u001B[32m818\u001B[0m │ add[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]              │\n",
      "│ (\u001B[94mLayerNormalization\u001B[0m)      │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m209,920\u001B[0m │ layer_normalization[\u001B[32m0\u001B[0m… │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_2 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │              \u001B[32m0\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │        \u001B[32m209,817\u001B[0m │ dropout_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ add_1 (\u001B[94mAdd\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │              \u001B[32m0\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ layer_normalization_1     │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)      │            \u001B[32m818\u001B[0m │ add_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "│ (\u001B[94mLayerNormalization\u001B[0m)      │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ global_average_pooling1d  │ (\u001B[96mNone\u001B[0m, \u001B[32m409\u001B[0m)            │              \u001B[32m0\u001B[0m │ layer_normalization_1… │\n",
      "│ (\u001B[94mGlobalAveragePooling1D\u001B[0m)  │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)            │        \u001B[32m209,920\u001B[0m │ global_average_poolin… │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_3 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)            │              \u001B[32m0\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)            │         \u001B[32m65,664\u001B[0m │ dropout_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_4 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)            │              \u001B[32m0\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m32\u001B[0m)             │          \u001B[32m4,128\u001B[0m │ dropout_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_5 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m32\u001B[0m)             │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[32m4\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m7,405,136\u001B[0m (28.25 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m7,405,136\u001B[0m (28.25 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "x_batch shape: (60, 60, 409)\n",
      "y_batch shape: (60, 4)\n",
      "x_batch shape: (60, 60, 409)\n",
      "y_batch shape: (60, 4)\n",
      "Epoch 1/10\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735055954.129011   18818 service.cc:146] XLA service 0x7c92800fb850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735055954.129073   18818 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-24 15:59:14.237339: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-24 15:59:14.888540: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1735055964.300032   18818 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "    145/Unknown \u001B[1m24s\u001B[0m 66ms/step - loss: 0.6694 - mae: 0.59382024-12-24 15:59:33.862227: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-24 15:59:33.862297: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 15:59:33.862324: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 15:59:33.862348: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-24 15:59:41.100572: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 15:59:41.100637: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 15:59:41.100664: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 116ms/step - loss: 0.6684 - mae: 0.5936 - val_loss: 0.3660 - val_mae: 0.4761\n",
      "Epoch 2/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - loss: 0.3787 - mae: 0.46982024-12-24 16:00:04.765123: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:00:04.765181: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:00:07.764058: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:00:07.764116: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:00:07.764140: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 88ms/step - loss: 0.3788 - mae: 0.4698 - val_loss: 0.3552 - val_mae: 0.4635\n",
      "Epoch 3/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - loss: 0.3446 - mae: 0.45092024-12-24 16:00:25.173263: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:00:25.173324: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:00:28.800678: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:00:28.800748: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 102ms/step - loss: 0.3446 - mae: 0.4509 - val_loss: 0.3388 - val_mae: 0.4473\n",
      "Epoch 4/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - loss: 0.3145 - mae: 0.43052024-12-24 16:00:45.699135: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:00:45.699200: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:00:48.672130: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:00:48.672188: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:00:48.672229: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 87ms/step - loss: 0.3145 - mae: 0.4305 - val_loss: 0.3272 - val_mae: 0.4471\n",
      "Epoch 5/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - loss: 0.2924 - mae: 0.41282024-12-24 16:01:06.002721: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:06.002810: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:01:09.826402: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:09.826469: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 101ms/step - loss: 0.2924 - mae: 0.4128 - val_loss: 0.3398 - val_mae: 0.4537\n",
      "Epoch 6/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - loss: 0.2704 - mae: 0.39612024-12-24 16:01:21.009666: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:21.009732: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:01:24.887773: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:24.887840: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 94ms/step - loss: 0.2704 - mae: 0.3961 - val_loss: 0.4106 - val_mae: 0.4678\n",
      "Epoch 7/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - loss: 0.2567 - mae: 0.38222024-12-24 16:01:34.771617: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:34.771681: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:01:38.826864: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:38.826939: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 94ms/step - loss: 0.2567 - mae: 0.3822 - val_loss: 0.3642 - val_mae: 0.4569\n",
      "Epoch 8/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - loss: 0.2445 - mae: 0.37322024-12-24 16:01:55.128828: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:55.128886: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:01:58.160323: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:01:58.160374: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:01:58.160402: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 87ms/step - loss: 0.2445 - mae: 0.3732 - val_loss: 0.3260 - val_mae: 0.4352\n",
      "Epoch 9/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - loss: 0.2339 - mae: 0.36672024-12-24 16:02:15.494134: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:02:15.494191: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:02:19.762177: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:02:19.762236: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 95ms/step - loss: 0.2339 - mae: 0.3667 - val_loss: 0.3631 - val_mae: 0.4606\n",
      "Epoch 10/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - loss: 0.2243 - mae: 0.35902024-12-24 16:02:29.577413: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:02:29.577475: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "2024-12-24 16:02:33.956339: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 6483299506403389951\n",
      "2024-12-24 16:02:33.956403: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 3787784948554193947\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 97ms/step - loss: 0.2243 - mae: 0.3590 - val_loss: 0.3695 - val_mae: 0.4610\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 28ms/step\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Mean Absolute Percentage Error (MAPE):\n",
      "   Eolica_gen_MAPE  Hidraulica_gen_MAPE  Solar_fotovoltaica_gen_MAPE  Solar_termica_gen_MAPE\n",
      "0        82.479206           354.500514                 6.862516e+08            2.169356e+08\n"
     ]
    }
   ],
   "source": [
    "!python \"${BASE_PATH_TFM}/energy_gen_predictor.py\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python \"${BASE_PATH_TFM}/energy_emission_predictor.py\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WopYD6216Im",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735058891015,
     "user_tz": -60,
     "elapsed": 236025,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     }
    },
    "outputId": "57c7e7b7-6bdf-4402-f244-9e9eff227c2d"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2024-12-24 16:44:17.271995: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-24 16:44:17.291810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-24 16:44:17.297722: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-24 16:44:17.312652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-24 16:44:18.349003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "    Ano  Mes  Dia  Hora  Minuto  0016A_Altitud  0201D_Altitud  0244X_Altitud  0367_Altitud  1025X_Altitud  1056K_Altitud  1074C_Altitud  1111X_Altitud  1186P_Altitud  1279X_Altitud  1387E_Altitud  1390X_Altitud  1466A_Altitud  1475X_Altitud  1719_Altitud  2044B_Altitud  2048A_Altitud  2331_Altitud  2734D_Altitud  2777K_Altitud  2873X_Altitud  2891A_Altitud  2946X_Altitud  3104Y_Altitud  3140Y_Altitud  3266A_Altitud  3475X_Altitud  3504X_Altitud  3526X_Altitud  3562X_Altitud  4096Y_Altitud  4340_Altitud  5390Y_Altitud  5402_Altitud  5582A_Altitud  5598X_Altitud  5612X_Altitud  5906X_Altitud  5972X_Altitud  6045X_Altitud  6172X_Altitud  6268Y_Altitud  6307X_Altitud  6312E_Altitud  7066Y_Altitud  7195X_Altitud  7275C_Altitud  8025_Altitud  8036Y_Altitud  8177A_Altitud  8270X_Altitud  8486X_Altitud  8500A_Altitud  9016X_Altitud  9257X_Altitud  9301X_Altitud  9352A_Altitud  9377Y_Altitud  9434_Altitud  9573X_Altitud  9677_Altitud  9814X_Altitud  9843A_Altitud  9946X_Altitud  \\\n",
      "0  2022    9   18     0       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "1  2022    9   18     1       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "2  2022    9   18     2       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "3  2022    9   18     3       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "4  2022    9   18     4       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "\n",
      "   B275E_Altitud  B569X_Altitud  B760X_Altitud  B925_Altitud  C148F_Altitud  C249I_Altitud  C619Y_Altitud  C639M_Altitud  C649R_Altitud  C659H_Altitud  C659M_Altitud  0016A_Humedad_relativa  0201D_Humedad_relativa  0244X_Humedad_relativa  0367_Humedad_relativa  1025X_Humedad_relativa  1056K_Humedad_relativa  1074C_Humedad_relativa  1111X_Humedad_relativa  1186P_Humedad_relativa  1279X_Humedad_relativa  1387E_Humedad_relativa  1390X_Humedad_relativa  1466A_Humedad_relativa  1475X_Humedad_relativa  1719_Humedad_relativa  2044B_Humedad_relativa  2048A_Humedad_relativa  2331_Humedad_relativa  2734D_Humedad_relativa  2777K_Humedad_relativa  2873X_Humedad_relativa  2891A_Humedad_relativa  2946X_Humedad_relativa  3104Y_Humedad_relativa  3140Y_Humedad_relativa  3266A_Humedad_relativa  3475X_Humedad_relativa  3504X_Humedad_relativa  3526X_Humedad_relativa  3562X_Humedad_relativa  4096Y_Humedad_relativa  4340_Humedad_relativa  5390Y_Humedad_relativa  5402_Humedad_relativa  \\\n",
      "0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "1           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "2           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "3           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "4           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "\n",
      "   5582A_Humedad_relativa  5598X_Humedad_relativa  5612X_Humedad_relativa  5906X_Humedad_relativa  5972X_Humedad_relativa  6045X_Humedad_relativa  6172X_Humedad_relativa  6268Y_Humedad_relativa  6307X_Humedad_relativa  6312E_Humedad_relativa  7066Y_Humedad_relativa  7195X_Humedad_relativa  7275C_Humedad_relativa  8025_Humedad_relativa  8036Y_Humedad_relativa  8177A_Humedad_relativa  8270X_Humedad_relativa  8486X_Humedad_relativa  8500A_Humedad_relativa  9016X_Humedad_relativa  9257X_Humedad_relativa  9301X_Humedad_relativa  9352A_Humedad_relativa  9377Y_Humedad_relativa  9434_Humedad_relativa  9573X_Humedad_relativa  9677_Humedad_relativa  9814X_Humedad_relativa  9843A_Humedad_relativa  9946X_Humedad_relativa  B275E_Humedad_relativa  B569X_Humedad_relativa  B760X_Humedad_relativa  B925_Humedad_relativa  C148F_Humedad_relativa  C249I_Humedad_relativa  C619Y_Humedad_relativa  C639M_Humedad_relativa  C649R_Humedad_relativa  C659H_Humedad_relativa  C659M_Humedad_relativa  \\\n",
      "0                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "1                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "2                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "3                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "4                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "\n",
      "   0016A_Precipitacion  0201D_Precipitacion  0244X_Precipitacion  0367_Precipitacion  1025X_Precipitacion  1056K_Precipitacion  1074C_Precipitacion  1111X_Precipitacion  1186P_Precipitacion  1279X_Precipitacion  1387E_Precipitacion  1390X_Precipitacion  1466A_Precipitacion  1475X_Precipitacion  1719_Precipitacion  2044B_Precipitacion  2048A_Precipitacion  2331_Precipitacion  2734D_Precipitacion  2777K_Precipitacion  2873X_Precipitacion  2891A_Precipitacion  2946X_Precipitacion  3104Y_Precipitacion  3140Y_Precipitacion  3266A_Precipitacion  3475X_Precipitacion  3504X_Precipitacion  3526X_Precipitacion  3562X_Precipitacion  4096Y_Precipitacion  4340_Precipitacion  5390Y_Precipitacion  5402_Precipitacion  5582A_Precipitacion  5598X_Precipitacion  5612X_Precipitacion  5906X_Precipitacion  5972X_Precipitacion  6045X_Precipitacion  6172X_Precipitacion  6268Y_Precipitacion  6307X_Precipitacion  6312E_Precipitacion  7066Y_Precipitacion  7195X_Precipitacion  7275C_Precipitacion  \\\n",
      "0                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "1                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "2                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "3                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "4                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "\n",
      "   8025_Precipitacion  8036Y_Precipitacion  8177A_Precipitacion  8270X_Precipitacion  8486X_Precipitacion  8500A_Precipitacion  9016X_Precipitacion  9257X_Precipitacion  9301X_Precipitacion  9352A_Precipitacion  9377Y_Precipitacion  9434_Precipitacion  9573X_Precipitacion  9677_Precipitacion  9814X_Precipitacion  9843A_Precipitacion  9946X_Precipitacion  B275E_Precipitacion  B569X_Precipitacion  B760X_Precipitacion  B925_Precipitacion  C148F_Precipitacion  C249I_Precipitacion  C619Y_Precipitacion  C639M_Precipitacion  C649R_Precipitacion  C659H_Precipitacion  C659M_Precipitacion  0016A_Presion  0201D_Presion  0244X_Presion  0367_Presion  1025X_Presion  1056K_Presion  1074C_Presion  1111X_Presion  1186P_Presion  1279X_Presion  1387E_Presion  1390X_Presion  1466A_Presion  1475X_Presion  1719_Presion  2044B_Presion  2048A_Presion  2331_Presion  2734D_Presion  2777K_Presion  2873X_Presion  2891A_Presion  2946X_Presion  3104Y_Presion  3140Y_Presion  3266A_Presion  3475X_Presion  \\\n",
      "0               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "1               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "2               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "3               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "4               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "\n",
      "   3504X_Presion  3526X_Presion  3562X_Presion  4096Y_Presion  4340_Presion  5390Y_Presion  5402_Presion  5582A_Presion  5598X_Presion  5612X_Presion  5906X_Presion  5972X_Presion  6045X_Presion  6172X_Presion  6268Y_Presion  6307X_Presion  6312E_Presion  7066Y_Presion  7195X_Presion  7275C_Presion  8025_Presion  8036Y_Presion  8177A_Presion  8270X_Presion  8486X_Presion  8500A_Presion  9016X_Presion  9257X_Presion  9301X_Presion  9352A_Presion  9377Y_Presion  9434_Presion  9573X_Presion  9677_Presion  9814X_Presion  9843A_Presion  9946X_Presion  B275E_Presion  B569X_Presion  B760X_Presion  B925_Presion  C148F_Presion  C249I_Presion  C619Y_Presion  C639M_Presion  C649R_Presion  C659H_Presion  C659M_Presion  0016A_Temperatura  0201D_Temperatura  0244X_Temperatura  0367_Temperatura  1025X_Temperatura  1056K_Temperatura  1074C_Temperatura  1111X_Temperatura  1186P_Temperatura  1279X_Temperatura  1387E_Temperatura  1390X_Temperatura  1466A_Temperatura  1475X_Temperatura  \\\n",
      "0       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "1       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "2       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "3       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "4       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "\n",
      "   1719_Temperatura  2044B_Temperatura  2048A_Temperatura  2331_Temperatura  2734D_Temperatura  2777K_Temperatura  2873X_Temperatura  2891A_Temperatura  2946X_Temperatura  3104Y_Temperatura  3140Y_Temperatura  3266A_Temperatura  3475X_Temperatura  3504X_Temperatura  3526X_Temperatura  3562X_Temperatura  4096Y_Temperatura  4340_Temperatura  5390Y_Temperatura  5402_Temperatura  5582A_Temperatura  5598X_Temperatura  5612X_Temperatura  5906X_Temperatura  5972X_Temperatura  6045X_Temperatura  6172X_Temperatura  6268Y_Temperatura  6307X_Temperatura  6312E_Temperatura  7066Y_Temperatura  7195X_Temperatura  7275C_Temperatura  8025_Temperatura  8036Y_Temperatura  8177A_Temperatura  8270X_Temperatura  8486X_Temperatura  8500A_Temperatura  9016X_Temperatura  9257X_Temperatura  9301X_Temperatura  9352A_Temperatura  9377Y_Temperatura  9434_Temperatura  9573X_Temperatura  9677_Temperatura  9814X_Temperatura  9843A_Temperatura  9946X_Temperatura  B275E_Temperatura  B569X_Temperatura  \\\n",
      "0              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "1              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "2              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "3              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "4              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "\n",
      "   B760X_Temperatura  B925_Temperatura  C148F_Temperatura  C249I_Temperatura  C619Y_Temperatura  C639M_Temperatura  C649R_Temperatura  C659H_Temperatura  C659M_Temperatura  0016A_Viento  0201D_Viento  0244X_Viento  0367_Viento  1025X_Viento  1056K_Viento  1074C_Viento  1111X_Viento  1186P_Viento  1279X_Viento  1387E_Viento  1390X_Viento  1466A_Viento  1475X_Viento  1719_Viento  2044B_Viento  2048A_Viento  2331_Viento  2734D_Viento  2777K_Viento  2873X_Viento  2891A_Viento  2946X_Viento  3104Y_Viento  3140Y_Viento  3266A_Viento  3475X_Viento  3504X_Viento  3526X_Viento  3562X_Viento  4096Y_Viento  4340_Viento  5390Y_Viento  5402_Viento  5582A_Viento  5598X_Viento  5612X_Viento  5906X_Viento  5972X_Viento  6045X_Viento  6172X_Viento  6268Y_Viento  6307X_Viento  6312E_Viento  7066Y_Viento  7195X_Viento  7275C_Viento  8025_Viento  8036Y_Viento  8177A_Viento  8270X_Viento  8486X_Viento  8500A_Viento  9016X_Viento  9257X_Viento  9301X_Viento  9352A_Viento  9377Y_Viento  9434_Viento  \\\n",
      "0               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "1               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "2               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "3               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "4               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "\n",
      "   9573X_Viento  9677_Viento  9814X_Viento  9843A_Viento  9946X_Viento  B275E_Viento  B569X_Viento  B760X_Viento  B925_Viento  C148F_Viento  C249I_Viento  C619Y_Viento  C639M_Viento  C649R_Viento  C659H_Viento  C659M_Viento  0016A_Viento_pred  0201D_Viento_pred  0244X_Viento_pred  0367_Viento_pred  1025X_Viento_pred  1056K_Viento_pred  1074C_Viento_pred  1111X_Viento_pred  1186P_Viento_pred  1279X_Viento_pred  1387E_Viento_pred  1390X_Viento_pred  1466A_Viento_pred  1475X_Viento_pred  1719_Viento_pred  2044B_Viento_pred  2048A_Viento_pred  2331_Viento_pred  2734D_Viento_pred  2777K_Viento_pred  2873X_Viento_pred  2891A_Viento_pred  2946X_Viento_pred  3104Y_Viento_pred  3140Y_Viento_pred  3266A_Viento_pred  3475X_Viento_pred  3504X_Viento_pred  3526X_Viento_pred  3562X_Viento_pred  4096Y_Viento_pred  4340_Viento_pred  5390Y_Viento_pred  5402_Viento_pred  5582A_Viento_pred  5598X_Viento_pred  5612X_Viento_pred  5906X_Viento_pred  5972X_Viento_pred  6045X_Viento_pred  6172X_Viento_pred  \\\n",
      "0           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           1.943829          1.479449           1.717177           0.506113           1.437103           0.699526           3.077921           0.797038           1.062248           3.079559           3.527321           1.770954          1.337379           1.186921           2.935063          1.764040           2.938147           1.502103           0.730523           1.471103           3.309237           3.144737           0.259190           0.981486           4.000695           3.736689           1.493466           1.996737           1.195477          1.024277           2.434672          1.944605           2.109376           1.610348           1.629929           1.736365           3.704096           2.812637           1.707109   \n",
      "1           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.025627          1.457594           1.667195           0.492925           1.464666           0.664485           3.110943           0.811082           1.106938           3.229418           3.642670           1.949584          1.315120           1.224410           2.888891          1.706343           2.938147           1.464919           0.729428           1.427311           3.227292           3.150652           0.264778           0.989055           3.962834           3.664406           1.347394           2.030380           1.172130          1.019138           2.420578          1.943563           2.091232           1.623601           1.689690           1.710809           3.710280           2.743318           1.758798   \n",
      "2           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.107308          1.434844           1.613085           0.485157           1.472447           0.618887           3.161249           0.799005           1.142866           3.380415           3.731186           2.081025          1.288763           1.264261           2.847514          1.644860           2.938147           1.396322           0.749744           1.403989           3.169053           3.222362           0.267762           0.999338           3.968915           3.658546           1.350777           2.057055           1.172484          1.027750           2.358795          1.932282           2.047971           1.625315           1.725357           1.686483           3.724195           2.714513           1.833021   \n",
      "3           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.025588          1.457296           1.665819           0.494732           1.458072           0.660966           3.116704           0.802375           1.104017           3.229798           3.633726           1.933855          1.313754           1.225197           2.890489          1.705081           2.938147           1.454448           0.736565           1.434134           3.235194           3.172584           0.263910           0.989960           3.977481           3.686547           1.397212           2.028057           1.180030          1.023721           2.404682          1.940150           2.082860           1.619754           1.681658           1.711219           3.712857           2.756823           1.766309   \n",
      "4           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.066467          1.446219           1.640140           0.489041           1.468556           0.641686           3.136096           0.805043           1.124902           3.304917           3.686928           2.015305          1.301941           1.244335           2.868203          1.675602           2.938147           1.430620           0.739586           1.415650           3.198173           3.186507           0.266270           0.994196           3.965875           3.661476           1.349085           2.043717           1.172307          1.023444           2.389687          1.937923           2.069601           1.624458           1.707523           1.698646           3.717237           2.728915           1.795909   \n",
      "\n",
      "   6268Y_Viento_pred  6307X_Viento_pred  6312E_Viento_pred  7066Y_Viento_pred  7195X_Viento_pred  7275C_Viento_pred  8025_Viento_pred  8036Y_Viento_pred  8177A_Viento_pred  8270X_Viento_pred  8486X_Viento_pred  8500A_Viento_pred  9016X_Viento_pred  9257X_Viento_pred  9301X_Viento_pred  9352A_Viento_pred  9377Y_Viento_pred  9434_Viento_pred  9573X_Viento_pred  9677_Viento_pred  9814X_Viento_pred  9843A_Viento_pred  9946X_Viento_pred  B275E_Viento_pred  B569X_Viento_pred  B760X_Viento_pred  B925_Viento_pred  C148F_Viento_pred  C249I_Viento_pred  C619Y_Viento_pred  C639M_Viento_pred  C649R_Viento_pred  C659H_Viento_pred  C659M_Viento_pred  Eolica_emi  Nuclear_emi  Carbon_emi  Ciclo_combinado_emi  Hidraulica_emi  Intercambios_int_emi  Solar_fotovoltaica_emi  Solar_termica_emi  Termica_renovable_emi  Motores_diesel_emi  Turbina_de_gas_emi  Turbina_de_vapor_emi  Generacion_auxiliar_emi  Cogeneracion_y_residuos_emi  Eolica_gen  Nuclear_gen  Carbon_gen  Ciclo_combinado_gen  Hidraulica_gen  \\\n",
      "0           2.288238           1.668124           1.463399           1.543373           1.609731           1.681400          1.123778           1.092416           1.326636           1.744443           0.665541           2.803017           2.650606           1.352547           1.823641           1.945526           3.260815          1.681861           3.027253          1.064673           6.580015           0.725655           0.297869           1.420418           1.862333           6.593983      9.762467e-02           0.437168           2.352216           4.554829           3.253805           1.457402           2.993989           3.296067           0            0       838.0               3559.0               0                     0                       0                  0                      0               220.0                38.0                 201.0                     0.68                        332.0      7998.0         6919         882                 9275          1927.0   \n",
      "1           2.149992           1.555193           1.463399           1.490385           1.627858           1.668701          1.062609           1.090597           1.331954           1.874320           0.591695           2.808985           2.783953           1.333456           1.842270           1.968959           3.128641          1.678815           2.942154          1.082016           6.583877           0.634895           0.297869           1.496873           1.890221           6.922064      4.126525e-03           0.365818           2.262426           4.531088           3.111320           1.455245           2.964689           3.282041           0            0       720.0               2858.0               0                     0                       0                  0                      0               194.0                43.0                 185.0                     1.40                        331.0      7488.0         6937         758                 7389          2040.0   \n",
      "2           2.008414           1.488367           1.463399           1.447117           1.645798           1.657706          0.999261           1.097296           1.339877           1.978168           0.519294           2.841664           2.904712           1.301297           1.900480           1.991143           3.010926          1.683544           2.827603          1.100459           6.648502           0.582916           0.297869           1.558116           1.909944           7.241610     -1.430512e-07           0.300860           2.192507           4.476672           3.063415           1.471645           2.924891           3.265723           0            0       672.0               3027.0               0                     0                       0                  0                      0               150.0                42.0                 124.0                     0.00                        331.0      6948.0         6939         707                 7809          1525.0   \n",
      "3           2.148881           1.570561           1.463399           1.493625           1.627796           1.669269          1.061883           1.093437           1.332822           1.865644           0.592177           2.817889           2.779757           1.329100           1.855464           1.968543           3.133461          1.681406           2.932337          1.082383           6.604131           0.647822           0.297869           1.491802           1.887499           6.919219      3.391702e-02           0.367949           2.269049           4.520863           3.142847           1.461431           2.961189           3.281277           0            0       674.0               2866.0               0                     0                       0                  0                      0               151.0                43.0                 114.0                     0.00                        333.0      6405.0         6939         709                 7391          1638.0   \n",
      "4           2.079203           1.521780           1.463399           1.468751           1.636828           1.663203          1.030935           1.093947           1.335915           1.926244           0.555495           2.825325           2.844333           1.317377           1.871375           1.980051           3.069784          1.681179           2.884878          1.091238           6.616189           0.608906           0.297869           1.527494           1.900083           7.081837      2.063191e-03           0.333339           2.227466           4.503880           3.087368           1.463445           2.944790           3.273882           0            0       674.0               2858.0               0                     0                       0                  0                      0               150.0                43.0                 114.0                     0.00                        333.0      5926.0         6938         709                 7387          1780.0   \n",
      "\n",
      "   Intercambios_int_gen  Solar_fotovoltaica_gen  Solar_termica_gen  Termica_renovable_gen  Motores_diesel_gen  Turbina_de_gas_gen  Turbina_de_vapor_gen  Generacion_auxiliar_gen  Cogeneracion_y_residuos_gen     Real  Prevista  Programada                                file  Asturias  Cantabria   Navarra  País Vasco  Cataluña    Aragón   Galicia  Islas Baleares  La Rioja  Valencia  Castilla y León  Castilla La Mancha  Extremadura  Andalucía    Murcia    Madrid  Solar_altitude  is_weekend  Carbon_emi_1day_before  Carbon_emi_2days_before  Carbon_emi_3days_before  Ciclo_combinado_emi_1day_before  Ciclo_combinado_emi_2days_before  Ciclo_combinado_emi_3days_before  Motores_diesel_emi_1day_before  Motores_diesel_emi_2days_before  Motores_diesel_emi_3days_before  Turbina_de_vapor_emi_1day_before  Turbina_de_vapor_emi_2days_before  Turbina_de_vapor_emi_3days_before  Turbina_de_gas_emi_1day_before  Turbina_de_gas_emi_2days_before  Turbina_de_gas_emi_3days_before  \\\n",
      "0                 -4994                    34.0              376.0                    458                 323                  39                   223                        1                         1191  24602.0   24581.0     24568.0  image_2022-09-18T00-00-00.000Z.png  1.000000   1.000000  1.000000    1.000000  0.882925  0.829349  0.822483        0.789877  0.657171  0.622616         0.400481            0.171011     0.121783   0.100546  0.052420  0.001263             0.0           1                   838.0                    838.0                    838.0                           3559.0                            3559.0                            3559.0                           220.0                            220.0                            220.0                             201.0                              201.0                              201.0                            38.0                             38.0                             38.0   \n",
      "1                 -4272                    33.0              339.0                    506                 286                  44                   205                        2                         1190  22860.0   23275.0     22934.0  image_2022-09-18T01-00-00.000Z.png  1.000000   0.987258  0.999529    0.925593  0.876782  0.704849  0.716930        0.855061  0.431284  0.579425         0.380731            0.171980     0.112889   0.092299  0.135067  0.219204             0.0           1                   720.0                    720.0                    720.0                           2858.0                            2858.0                            2858.0                           194.0                            194.0                            194.0                             185.0                              185.0                              185.0                            43.0                             43.0                             43.0   \n",
      "2                 -4183                    17.0              234.0                    520                 220                  43                   138                        0                         1189  22023.0   22126.0     21911.0  image_2022-09-18T02-00-00.000Z.png  1.000000   0.954224  0.964664    0.811646  0.904278  0.623915  0.674565        0.957055  0.130935  0.628286         0.314095            0.179288     0.113952   0.090697  0.318326  0.680354             0.0           1                   672.0                    672.0                    672.0                           3027.0                            3027.0                            3027.0                           150.0                            150.0                            150.0                             124.0                              124.0                              124.0                            42.0                             42.0                             42.0   \n",
      "3                 -3933                    16.0              151.0                    512                 222                  44                   127                        0                         1195  21324.0   21277.0     21384.0  image_2022-09-18T03-00-00.000Z.png  0.964781   0.693723  0.841932    0.854781  0.928629  0.563372  0.551460        0.837040  0.288856  0.720544         0.202483            0.222614     0.150145   0.127495  0.381526  0.551169             0.0           1                   674.0                    674.0                    674.0                           2866.0                            2866.0                            2866.0                           151.0                            151.0                            151.0                             114.0                              114.0                              114.0                            43.0                             43.0                             43.0   \n",
      "4                 -3959                    16.0               24.0                    518                 220                  44                   127                        0                         1195  20834.0   20803.0     20853.0  image_2022-09-18T04-00-00.000Z.png  0.453761   0.220387  0.733569    0.924515  0.938867  0.536491  0.395724        0.849310  0.033483  0.718586         0.107176            0.187683     0.190255   0.103147  0.363560  0.110865             0.0           1                   674.0                    674.0                    674.0                           2858.0                            2858.0                            2858.0                           150.0                            150.0                            150.0                             114.0                              114.0                              114.0                            43.0                             43.0                             43.0   \n",
      "\n",
      "   Cogeneracion_y_residuos_emi_1day_before  Cogeneracion_y_residuos_emi_2days_before  Cogeneracion_y_residuos_emi_3days_before  \n",
      "0                                    332.0                                     332.0                                     332.0  \n",
      "1                                    331.0                                     331.0                                     331.0  \n",
      "2                                    331.0                                     331.0                                     331.0  \n",
      "3                                    333.0                                     333.0                                     333.0  \n",
      "4                                    333.0                                     333.0                                     333.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17544 entries, 0 to 17543\n",
      "Data columns (total 598 columns):\n",
      " #    Column                                    Non-Null Count  Dtype  \n",
      "---   ------                                    --------------  -----  \n",
      " 0    Ano                                       17544 non-null  int64  \n",
      " 1    Mes                                       17544 non-null  int64  \n",
      " 2    Dia                                       17544 non-null  int64  \n",
      " 3    Hora                                      17544 non-null  int64  \n",
      " 4    Minuto                                    17544 non-null  int64  \n",
      " 5    0016A_Altitud                             17544 non-null  float64\n",
      " 6    0201D_Altitud                             17544 non-null  float64\n",
      " 7    0244X_Altitud                             17544 non-null  float64\n",
      " 8    0367_Altitud                              17544 non-null  float64\n",
      " 9    1025X_Altitud                             17544 non-null  float64\n",
      " 10   1056K_Altitud                             17544 non-null  float64\n",
      " 11   1074C_Altitud                             17544 non-null  float64\n",
      " 12   1111X_Altitud                             17544 non-null  float64\n",
      " 13   1186P_Altitud                             17544 non-null  float64\n",
      " 14   1279X_Altitud                             17544 non-null  float64\n",
      " 15   1387E_Altitud                             17544 non-null  float64\n",
      " 16   1390X_Altitud                             17544 non-null  float64\n",
      " 17   1466A_Altitud                             17544 non-null  float64\n",
      " 18   1475X_Altitud                             17544 non-null  float64\n",
      " 19   1719_Altitud                              17544 non-null  float64\n",
      " 20   2044B_Altitud                             17544 non-null  float64\n",
      " 21   2048A_Altitud                             17544 non-null  float64\n",
      " 22   2331_Altitud                              17544 non-null  float64\n",
      " 23   2734D_Altitud                             17544 non-null  float64\n",
      " 24   2777K_Altitud                             17544 non-null  float64\n",
      " 25   2873X_Altitud                             17544 non-null  float64\n",
      " 26   2891A_Altitud                             17544 non-null  float64\n",
      " 27   2946X_Altitud                             17544 non-null  float64\n",
      " 28   3104Y_Altitud                             17544 non-null  float64\n",
      " 29   3140Y_Altitud                             17544 non-null  float64\n",
      " 30   3266A_Altitud                             17544 non-null  float64\n",
      " 31   3475X_Altitud                             17544 non-null  float64\n",
      " 32   3504X_Altitud                             17544 non-null  float64\n",
      " 33   3526X_Altitud                             17544 non-null  float64\n",
      " 34   3562X_Altitud                             17544 non-null  float64\n",
      " 35   4096Y_Altitud                             17544 non-null  float64\n",
      " 36   4340_Altitud                              17544 non-null  float64\n",
      " 37   5390Y_Altitud                             17544 non-null  float64\n",
      " 38   5402_Altitud                              17544 non-null  float64\n",
      " 39   5582A_Altitud                             17544 non-null  float64\n",
      " 40   5598X_Altitud                             17544 non-null  float64\n",
      " 41   5612X_Altitud                             17544 non-null  float64\n",
      " 42   5906X_Altitud                             17544 non-null  float64\n",
      " 43   5972X_Altitud                             17544 non-null  float64\n",
      " 44   6045X_Altitud                             17544 non-null  float64\n",
      " 45   6172X_Altitud                             17544 non-null  float64\n",
      " 46   6268Y_Altitud                             17544 non-null  float64\n",
      " 47   6307X_Altitud                             17544 non-null  float64\n",
      " 48   6312E_Altitud                             17544 non-null  float64\n",
      " 49   7066Y_Altitud                             17544 non-null  float64\n",
      " 50   7195X_Altitud                             17544 non-null  float64\n",
      " 51   7275C_Altitud                             17544 non-null  float64\n",
      " 52   8025_Altitud                              17544 non-null  float64\n",
      " 53   8036Y_Altitud                             17544 non-null  float64\n",
      " 54   8177A_Altitud                             17544 non-null  float64\n",
      " 55   8270X_Altitud                             17544 non-null  float64\n",
      " 56   8486X_Altitud                             17544 non-null  float64\n",
      " 57   8500A_Altitud                             17544 non-null  float64\n",
      " 58   9016X_Altitud                             17544 non-null  float64\n",
      " 59   9257X_Altitud                             17544 non-null  float64\n",
      " 60   9301X_Altitud                             17544 non-null  float64\n",
      " 61   9352A_Altitud                             17544 non-null  float64\n",
      " 62   9377Y_Altitud                             17544 non-null  float64\n",
      " 63   9434_Altitud                              17544 non-null  float64\n",
      " 64   9573X_Altitud                             17544 non-null  float64\n",
      " 65   9677_Altitud                              17544 non-null  float64\n",
      " 66   9814X_Altitud                             17544 non-null  float64\n",
      " 67   9843A_Altitud                             17544 non-null  float64\n",
      " 68   9946X_Altitud                             17544 non-null  float64\n",
      " 69   B275E_Altitud                             17544 non-null  float64\n",
      " 70   B569X_Altitud                             17544 non-null  float64\n",
      " 71   B760X_Altitud                             17544 non-null  float64\n",
      " 72   B925_Altitud                              17544 non-null  float64\n",
      " 73   C148F_Altitud                             17544 non-null  float64\n",
      " 74   C249I_Altitud                             17544 non-null  float64\n",
      " 75   C619Y_Altitud                             17544 non-null  float64\n",
      " 76   C639M_Altitud                             17544 non-null  float64\n",
      " 77   C649R_Altitud                             17544 non-null  float64\n",
      " 78   C659H_Altitud                             17544 non-null  float64\n",
      " 79   C659M_Altitud                             17544 non-null  float64\n",
      " 80   0016A_Humedad_relativa                    17544 non-null  float64\n",
      " 81   0201D_Humedad_relativa                    17544 non-null  float64\n",
      " 82   0244X_Humedad_relativa                    17544 non-null  float64\n",
      " 83   0367_Humedad_relativa                     17544 non-null  float64\n",
      " 84   1025X_Humedad_relativa                    17544 non-null  float64\n",
      " 85   1056K_Humedad_relativa                    17544 non-null  float64\n",
      " 86   1074C_Humedad_relativa                    17544 non-null  float64\n",
      " 87   1111X_Humedad_relativa                    17544 non-null  float64\n",
      " 88   1186P_Humedad_relativa                    17544 non-null  float64\n",
      " 89   1279X_Humedad_relativa                    17544 non-null  float64\n",
      " 90   1387E_Humedad_relativa                    17544 non-null  float64\n",
      " 91   1390X_Humedad_relativa                    17544 non-null  float64\n",
      " 92   1466A_Humedad_relativa                    17544 non-null  float64\n",
      " 93   1475X_Humedad_relativa                    17544 non-null  float64\n",
      " 94   1719_Humedad_relativa                     17544 non-null  float64\n",
      " 95   2044B_Humedad_relativa                    17544 non-null  float64\n",
      " 96   2048A_Humedad_relativa                    17544 non-null  float64\n",
      " 97   2331_Humedad_relativa                     17544 non-null  float64\n",
      " 98   2734D_Humedad_relativa                    17544 non-null  float64\n",
      " 99   2777K_Humedad_relativa                    17544 non-null  float64\n",
      " 100  2873X_Humedad_relativa                    17544 non-null  float64\n",
      " 101  2891A_Humedad_relativa                    17544 non-null  float64\n",
      " 102  2946X_Humedad_relativa                    17544 non-null  float64\n",
      " 103  3104Y_Humedad_relativa                    17544 non-null  float64\n",
      " 104  3140Y_Humedad_relativa                    17544 non-null  float64\n",
      " 105  3266A_Humedad_relativa                    17544 non-null  float64\n",
      " 106  3475X_Humedad_relativa                    17544 non-null  float64\n",
      " 107  3504X_Humedad_relativa                    17544 non-null  float64\n",
      " 108  3526X_Humedad_relativa                    17544 non-null  float64\n",
      " 109  3562X_Humedad_relativa                    17544 non-null  float64\n",
      " 110  4096Y_Humedad_relativa                    17544 non-null  float64\n",
      " 111  4340_Humedad_relativa                     17544 non-null  float64\n",
      " 112  5390Y_Humedad_relativa                    17544 non-null  float64\n",
      " 113  5402_Humedad_relativa                     17544 non-null  float64\n",
      " 114  5582A_Humedad_relativa                    17544 non-null  float64\n",
      " 115  5598X_Humedad_relativa                    17544 non-null  float64\n",
      " 116  5612X_Humedad_relativa                    17544 non-null  float64\n",
      " 117  5906X_Humedad_relativa                    17544 non-null  float64\n",
      " 118  5972X_Humedad_relativa                    17544 non-null  float64\n",
      " 119  6045X_Humedad_relativa                    17544 non-null  float64\n",
      " 120  6172X_Humedad_relativa                    17544 non-null  float64\n",
      " 121  6268Y_Humedad_relativa                    17544 non-null  float64\n",
      " 122  6307X_Humedad_relativa                    17544 non-null  float64\n",
      " 123  6312E_Humedad_relativa                    17544 non-null  float64\n",
      " 124  7066Y_Humedad_relativa                    17544 non-null  float64\n",
      " 125  7195X_Humedad_relativa                    17544 non-null  float64\n",
      " 126  7275C_Humedad_relativa                    17544 non-null  float64\n",
      " 127  8025_Humedad_relativa                     17544 non-null  float64\n",
      " 128  8036Y_Humedad_relativa                    17544 non-null  float64\n",
      " 129  8177A_Humedad_relativa                    17544 non-null  float64\n",
      " 130  8270X_Humedad_relativa                    17544 non-null  float64\n",
      " 131  8486X_Humedad_relativa                    17544 non-null  float64\n",
      " 132  8500A_Humedad_relativa                    17544 non-null  float64\n",
      " 133  9016X_Humedad_relativa                    17544 non-null  float64\n",
      " 134  9257X_Humedad_relativa                    17544 non-null  float64\n",
      " 135  9301X_Humedad_relativa                    17544 non-null  float64\n",
      " 136  9352A_Humedad_relativa                    17544 non-null  float64\n",
      " 137  9377Y_Humedad_relativa                    17544 non-null  float64\n",
      " 138  9434_Humedad_relativa                     17544 non-null  float64\n",
      " 139  9573X_Humedad_relativa                    17544 non-null  float64\n",
      " 140  9677_Humedad_relativa                     17544 non-null  float64\n",
      " 141  9814X_Humedad_relativa                    17544 non-null  float64\n",
      " 142  9843A_Humedad_relativa                    17544 non-null  float64\n",
      " 143  9946X_Humedad_relativa                    17544 non-null  float64\n",
      " 144  B275E_Humedad_relativa                    17544 non-null  float64\n",
      " 145  B569X_Humedad_relativa                    17544 non-null  float64\n",
      " 146  B760X_Humedad_relativa                    17544 non-null  float64\n",
      " 147  B925_Humedad_relativa                     17544 non-null  float64\n",
      " 148  C148F_Humedad_relativa                    17544 non-null  float64\n",
      " 149  C249I_Humedad_relativa                    17544 non-null  float64\n",
      " 150  C619Y_Humedad_relativa                    17544 non-null  float64\n",
      " 151  C639M_Humedad_relativa                    17544 non-null  float64\n",
      " 152  C649R_Humedad_relativa                    17544 non-null  float64\n",
      " 153  C659H_Humedad_relativa                    17544 non-null  float64\n",
      " 154  C659M_Humedad_relativa                    17544 non-null  float64\n",
      " 155  0016A_Precipitacion                       17544 non-null  float64\n",
      " 156  0201D_Precipitacion                       17544 non-null  float64\n",
      " 157  0244X_Precipitacion                       17544 non-null  float64\n",
      " 158  0367_Precipitacion                        17544 non-null  float64\n",
      " 159  1025X_Precipitacion                       17544 non-null  float64\n",
      " 160  1056K_Precipitacion                       17544 non-null  float64\n",
      " 161  1074C_Precipitacion                       17544 non-null  float64\n",
      " 162  1111X_Precipitacion                       17544 non-null  float64\n",
      " 163  1186P_Precipitacion                       17544 non-null  float64\n",
      " 164  1279X_Precipitacion                       17544 non-null  float64\n",
      " 165  1387E_Precipitacion                       17544 non-null  float64\n",
      " 166  1390X_Precipitacion                       17544 non-null  float64\n",
      " 167  1466A_Precipitacion                       17544 non-null  float64\n",
      " 168  1475X_Precipitacion                       17544 non-null  float64\n",
      " 169  1719_Precipitacion                        17544 non-null  float64\n",
      " 170  2044B_Precipitacion                       17544 non-null  float64\n",
      " 171  2048A_Precipitacion                       17544 non-null  float64\n",
      " 172  2331_Precipitacion                        17544 non-null  float64\n",
      " 173  2734D_Precipitacion                       17544 non-null  float64\n",
      " 174  2777K_Precipitacion                       17544 non-null  float64\n",
      " 175  2873X_Precipitacion                       17544 non-null  float64\n",
      " 176  2891A_Precipitacion                       17544 non-null  float64\n",
      " 177  2946X_Precipitacion                       17544 non-null  float64\n",
      " 178  3104Y_Precipitacion                       17544 non-null  float64\n",
      " 179  3140Y_Precipitacion                       17544 non-null  float64\n",
      " 180  3266A_Precipitacion                       17544 non-null  float64\n",
      " 181  3475X_Precipitacion                       17544 non-null  float64\n",
      " 182  3504X_Precipitacion                       17544 non-null  float64\n",
      " 183  3526X_Precipitacion                       17544 non-null  float64\n",
      " 184  3562X_Precipitacion                       17544 non-null  float64\n",
      " 185  4096Y_Precipitacion                       17544 non-null  float64\n",
      " 186  4340_Precipitacion                        17544 non-null  float64\n",
      " 187  5390Y_Precipitacion                       17544 non-null  float64\n",
      " 188  5402_Precipitacion                        17544 non-null  float64\n",
      " 189  5582A_Precipitacion                       17544 non-null  float64\n",
      " 190  5598X_Precipitacion                       17544 non-null  float64\n",
      " 191  5612X_Precipitacion                       17544 non-null  float64\n",
      " 192  5906X_Precipitacion                       17544 non-null  float64\n",
      " 193  5972X_Precipitacion                       17544 non-null  float64\n",
      " 194  6045X_Precipitacion                       17544 non-null  float64\n",
      " 195  6172X_Precipitacion                       17544 non-null  float64\n",
      " 196  6268Y_Precipitacion                       17544 non-null  float64\n",
      " 197  6307X_Precipitacion                       17544 non-null  float64\n",
      " 198  6312E_Precipitacion                       17544 non-null  float64\n",
      " 199  7066Y_Precipitacion                       17544 non-null  float64\n",
      " 200  7195X_Precipitacion                       17544 non-null  float64\n",
      " 201  7275C_Precipitacion                       17544 non-null  float64\n",
      " 202  8025_Precipitacion                        17544 non-null  float64\n",
      " 203  8036Y_Precipitacion                       17544 non-null  float64\n",
      " 204  8177A_Precipitacion                       17544 non-null  float64\n",
      " 205  8270X_Precipitacion                       17544 non-null  float64\n",
      " 206  8486X_Precipitacion                       17544 non-null  float64\n",
      " 207  8500A_Precipitacion                       17544 non-null  float64\n",
      " 208  9016X_Precipitacion                       17544 non-null  float64\n",
      " 209  9257X_Precipitacion                       17544 non-null  float64\n",
      " 210  9301X_Precipitacion                       17544 non-null  float64\n",
      " 211  9352A_Precipitacion                       17544 non-null  float64\n",
      " 212  9377Y_Precipitacion                       17544 non-null  float64\n",
      " 213  9434_Precipitacion                        17544 non-null  float64\n",
      " 214  9573X_Precipitacion                       17544 non-null  float64\n",
      " 215  9677_Precipitacion                        17544 non-null  float64\n",
      " 216  9814X_Precipitacion                       17544 non-null  float64\n",
      " 217  9843A_Precipitacion                       17544 non-null  float64\n",
      " 218  9946X_Precipitacion                       17544 non-null  float64\n",
      " 219  B275E_Precipitacion                       17544 non-null  float64\n",
      " 220  B569X_Precipitacion                       17544 non-null  float64\n",
      " 221  B760X_Precipitacion                       17544 non-null  float64\n",
      " 222  B925_Precipitacion                        17544 non-null  float64\n",
      " 223  C148F_Precipitacion                       17544 non-null  float64\n",
      " 224  C249I_Precipitacion                       17544 non-null  float64\n",
      " 225  C619Y_Precipitacion                       17544 non-null  float64\n",
      " 226  C639M_Precipitacion                       17544 non-null  float64\n",
      " 227  C649R_Precipitacion                       17544 non-null  float64\n",
      " 228  C659H_Precipitacion                       17544 non-null  float64\n",
      " 229  C659M_Precipitacion                       17544 non-null  float64\n",
      " 230  0016A_Presion                             17544 non-null  float64\n",
      " 231  0201D_Presion                             17544 non-null  float64\n",
      " 232  0244X_Presion                             17544 non-null  float64\n",
      " 233  0367_Presion                              17544 non-null  float64\n",
      " 234  1025X_Presion                             17544 non-null  float64\n",
      " 235  1056K_Presion                             17544 non-null  float64\n",
      " 236  1074C_Presion                             17544 non-null  float64\n",
      " 237  1111X_Presion                             17544 non-null  float64\n",
      " 238  1186P_Presion                             17544 non-null  float64\n",
      " 239  1279X_Presion                             17544 non-null  float64\n",
      " 240  1387E_Presion                             17544 non-null  float64\n",
      " 241  1390X_Presion                             17544 non-null  float64\n",
      " 242  1466A_Presion                             17544 non-null  float64\n",
      " 243  1475X_Presion                             17544 non-null  float64\n",
      " 244  1719_Presion                              17544 non-null  float64\n",
      " 245  2044B_Presion                             17544 non-null  float64\n",
      " 246  2048A_Presion                             17544 non-null  float64\n",
      " 247  2331_Presion                              17544 non-null  float64\n",
      " 248  2734D_Presion                             17544 non-null  float64\n",
      " 249  2777K_Presion                             17544 non-null  float64\n",
      " 250  2873X_Presion                             17544 non-null  float64\n",
      " 251  2891A_Presion                             17544 non-null  float64\n",
      " 252  2946X_Presion                             17544 non-null  float64\n",
      " 253  3104Y_Presion                             17544 non-null  float64\n",
      " 254  3140Y_Presion                             17544 non-null  float64\n",
      " 255  3266A_Presion                             17544 non-null  float64\n",
      " 256  3475X_Presion                             17544 non-null  float64\n",
      " 257  3504X_Presion                             17544 non-null  float64\n",
      " 258  3526X_Presion                             17544 non-null  float64\n",
      " 259  3562X_Presion                             17544 non-null  float64\n",
      " 260  4096Y_Presion                             17544 non-null  float64\n",
      " 261  4340_Presion                              17544 non-null  float64\n",
      " 262  5390Y_Presion                             17544 non-null  float64\n",
      " 263  5402_Presion                              17544 non-null  float64\n",
      " 264  5582A_Presion                             17544 non-null  float64\n",
      " 265  5598X_Presion                             17544 non-null  float64\n",
      " 266  5612X_Presion                             17544 non-null  float64\n",
      " 267  5906X_Presion                             17544 non-null  float64\n",
      " 268  5972X_Presion                             17544 non-null  float64\n",
      " 269  6045X_Presion                             17544 non-null  float64\n",
      " 270  6172X_Presion                             17544 non-null  float64\n",
      " 271  6268Y_Presion                             17544 non-null  float64\n",
      " 272  6307X_Presion                             17544 non-null  float64\n",
      " 273  6312E_Presion                             17544 non-null  float64\n",
      " 274  7066Y_Presion                             17544 non-null  float64\n",
      " 275  7195X_Presion                             17544 non-null  float64\n",
      " 276  7275C_Presion                             17544 non-null  float64\n",
      " 277  8025_Presion                              17544 non-null  float64\n",
      " 278  8036Y_Presion                             17544 non-null  float64\n",
      " 279  8177A_Presion                             17544 non-null  float64\n",
      " 280  8270X_Presion                             17544 non-null  float64\n",
      " 281  8486X_Presion                             17544 non-null  float64\n",
      " 282  8500A_Presion                             17544 non-null  float64\n",
      " 283  9016X_Presion                             17544 non-null  float64\n",
      " 284  9257X_Presion                             17544 non-null  float64\n",
      " 285  9301X_Presion                             17544 non-null  float64\n",
      " 286  9352A_Presion                             17544 non-null  float64\n",
      " 287  9377Y_Presion                             17544 non-null  float64\n",
      " 288  9434_Presion                              17544 non-null  float64\n",
      " 289  9573X_Presion                             17544 non-null  float64\n",
      " 290  9677_Presion                              17544 non-null  float64\n",
      " 291  9814X_Presion                             17544 non-null  float64\n",
      " 292  9843A_Presion                             17544 non-null  float64\n",
      " 293  9946X_Presion                             17544 non-null  float64\n",
      " 294  B275E_Presion                             17544 non-null  float64\n",
      " 295  B569X_Presion                             17544 non-null  float64\n",
      " 296  B760X_Presion                             17544 non-null  float64\n",
      " 297  B925_Presion                              17544 non-null  float64\n",
      " 298  C148F_Presion                             17544 non-null  float64\n",
      " 299  C249I_Presion                             17544 non-null  float64\n",
      " 300  C619Y_Presion                             17544 non-null  float64\n",
      " 301  C639M_Presion                             17544 non-null  float64\n",
      " 302  C649R_Presion                             17544 non-null  float64\n",
      " 303  C659H_Presion                             17544 non-null  float64\n",
      " 304  C659M_Presion                             17544 non-null  float64\n",
      " 305  0016A_Temperatura                         17544 non-null  float64\n",
      " 306  0201D_Temperatura                         17544 non-null  float64\n",
      " 307  0244X_Temperatura                         17544 non-null  float64\n",
      " 308  0367_Temperatura                          17544 non-null  float64\n",
      " 309  1025X_Temperatura                         17544 non-null  float64\n",
      " 310  1056K_Temperatura                         17544 non-null  float64\n",
      " 311  1074C_Temperatura                         17544 non-null  float64\n",
      " 312  1111X_Temperatura                         17544 non-null  float64\n",
      " 313  1186P_Temperatura                         17544 non-null  float64\n",
      " 314  1279X_Temperatura                         17544 non-null  float64\n",
      " 315  1387E_Temperatura                         17544 non-null  float64\n",
      " 316  1390X_Temperatura                         17544 non-null  float64\n",
      " 317  1466A_Temperatura                         17544 non-null  float64\n",
      " 318  1475X_Temperatura                         17544 non-null  float64\n",
      " 319  1719_Temperatura                          17544 non-null  float64\n",
      " 320  2044B_Temperatura                         17544 non-null  float64\n",
      " 321  2048A_Temperatura                         17544 non-null  float64\n",
      " 322  2331_Temperatura                          17544 non-null  float64\n",
      " 323  2734D_Temperatura                         17544 non-null  float64\n",
      " 324  2777K_Temperatura                         17544 non-null  float64\n",
      " 325  2873X_Temperatura                         17544 non-null  float64\n",
      " 326  2891A_Temperatura                         17544 non-null  float64\n",
      " 327  2946X_Temperatura                         17544 non-null  float64\n",
      " 328  3104Y_Temperatura                         17544 non-null  float64\n",
      " 329  3140Y_Temperatura                         17544 non-null  float64\n",
      " 330  3266A_Temperatura                         17544 non-null  float64\n",
      " 331  3475X_Temperatura                         17544 non-null  float64\n",
      " 332  3504X_Temperatura                         17544 non-null  float64\n",
      " 333  3526X_Temperatura                         17544 non-null  float64\n",
      " 334  3562X_Temperatura                         17544 non-null  float64\n",
      " 335  4096Y_Temperatura                         17544 non-null  float64\n",
      " 336  4340_Temperatura                          17544 non-null  float64\n",
      " 337  5390Y_Temperatura                         17544 non-null  float64\n",
      " 338  5402_Temperatura                          17544 non-null  float64\n",
      " 339  5582A_Temperatura                         17544 non-null  float64\n",
      " 340  5598X_Temperatura                         17544 non-null  float64\n",
      " 341  5612X_Temperatura                         17544 non-null  float64\n",
      " 342  5906X_Temperatura                         17544 non-null  float64\n",
      " 343  5972X_Temperatura                         17544 non-null  float64\n",
      " 344  6045X_Temperatura                         17544 non-null  float64\n",
      " 345  6172X_Temperatura                         17544 non-null  float64\n",
      " 346  6268Y_Temperatura                         17544 non-null  float64\n",
      " 347  6307X_Temperatura                         17544 non-null  float64\n",
      " 348  6312E_Temperatura                         17544 non-null  float64\n",
      " 349  7066Y_Temperatura                         17544 non-null  float64\n",
      " 350  7195X_Temperatura                         17544 non-null  float64\n",
      " 351  7275C_Temperatura                         17544 non-null  float64\n",
      " 352  8025_Temperatura                          17544 non-null  float64\n",
      " 353  8036Y_Temperatura                         17544 non-null  float64\n",
      " 354  8177A_Temperatura                         17544 non-null  float64\n",
      " 355  8270X_Temperatura                         17544 non-null  float64\n",
      " 356  8486X_Temperatura                         17544 non-null  float64\n",
      " 357  8500A_Temperatura                         17544 non-null  float64\n",
      " 358  9016X_Temperatura                         17544 non-null  float64\n",
      " 359  9257X_Temperatura                         17544 non-null  float64\n",
      " 360  9301X_Temperatura                         17544 non-null  float64\n",
      " 361  9352A_Temperatura                         17544 non-null  float64\n",
      " 362  9377Y_Temperatura                         17544 non-null  float64\n",
      " 363  9434_Temperatura                          17544 non-null  float64\n",
      " 364  9573X_Temperatura                         17544 non-null  float64\n",
      " 365  9677_Temperatura                          17544 non-null  float64\n",
      " 366  9814X_Temperatura                         17544 non-null  float64\n",
      " 367  9843A_Temperatura                         17544 non-null  float64\n",
      " 368  9946X_Temperatura                         17544 non-null  float64\n",
      " 369  B275E_Temperatura                         17544 non-null  float64\n",
      " 370  B569X_Temperatura                         17544 non-null  float64\n",
      " 371  B760X_Temperatura                         17544 non-null  float64\n",
      " 372  B925_Temperatura                          17544 non-null  float64\n",
      " 373  C148F_Temperatura                         17544 non-null  float64\n",
      " 374  C249I_Temperatura                         17544 non-null  float64\n",
      " 375  C619Y_Temperatura                         17544 non-null  float64\n",
      " 376  C639M_Temperatura                         17544 non-null  float64\n",
      " 377  C649R_Temperatura                         17544 non-null  float64\n",
      " 378  C659H_Temperatura                         17544 non-null  float64\n",
      " 379  C659M_Temperatura                         17544 non-null  float64\n",
      " 380  0016A_Viento                              17544 non-null  float64\n",
      " 381  0201D_Viento                              17544 non-null  float64\n",
      " 382  0244X_Viento                              17544 non-null  float64\n",
      " 383  0367_Viento                               17544 non-null  float64\n",
      " 384  1025X_Viento                              17544 non-null  float64\n",
      " 385  1056K_Viento                              17544 non-null  float64\n",
      " 386  1074C_Viento                              17544 non-null  float64\n",
      " 387  1111X_Viento                              17544 non-null  float64\n",
      " 388  1186P_Viento                              17544 non-null  float64\n",
      " 389  1279X_Viento                              17544 non-null  float64\n",
      " 390  1387E_Viento                              17544 non-null  float64\n",
      " 391  1390X_Viento                              17544 non-null  float64\n",
      " 392  1466A_Viento                              17544 non-null  float64\n",
      " 393  1475X_Viento                              17544 non-null  float64\n",
      " 394  1719_Viento                               17544 non-null  float64\n",
      " 395  2044B_Viento                              17544 non-null  float64\n",
      " 396  2048A_Viento                              17544 non-null  float64\n",
      " 397  2331_Viento                               17544 non-null  float64\n",
      " 398  2734D_Viento                              17544 non-null  float64\n",
      " 399  2777K_Viento                              17544 non-null  float64\n",
      " 400  2873X_Viento                              17544 non-null  float64\n",
      " 401  2891A_Viento                              17544 non-null  float64\n",
      " 402  2946X_Viento                              17544 non-null  float64\n",
      " 403  3104Y_Viento                              17544 non-null  float64\n",
      " 404  3140Y_Viento                              17544 non-null  float64\n",
      " 405  3266A_Viento                              17544 non-null  float64\n",
      " 406  3475X_Viento                              17544 non-null  float64\n",
      " 407  3504X_Viento                              17544 non-null  float64\n",
      " 408  3526X_Viento                              17544 non-null  float64\n",
      " 409  3562X_Viento                              17544 non-null  float64\n",
      " 410  4096Y_Viento                              17544 non-null  float64\n",
      " 411  4340_Viento                               17544 non-null  float64\n",
      " 412  5390Y_Viento                              17544 non-null  float64\n",
      " 413  5402_Viento                               17544 non-null  float64\n",
      " 414  5582A_Viento                              17544 non-null  float64\n",
      " 415  5598X_Viento                              17544 non-null  float64\n",
      " 416  5612X_Viento                              17544 non-null  float64\n",
      " 417  5906X_Viento                              17544 non-null  float64\n",
      " 418  5972X_Viento                              17544 non-null  float64\n",
      " 419  6045X_Viento                              17544 non-null  float64\n",
      " 420  6172X_Viento                              17544 non-null  float64\n",
      " 421  6268Y_Viento                              17544 non-null  float64\n",
      " 422  6307X_Viento                              17544 non-null  float64\n",
      " 423  6312E_Viento                              17544 non-null  float64\n",
      " 424  7066Y_Viento                              17544 non-null  float64\n",
      " 425  7195X_Viento                              17544 non-null  float64\n",
      " 426  7275C_Viento                              17544 non-null  float64\n",
      " 427  8025_Viento                               17544 non-null  float64\n",
      " 428  8036Y_Viento                              17544 non-null  float64\n",
      " 429  8177A_Viento                              17544 non-null  float64\n",
      " 430  8270X_Viento                              17544 non-null  float64\n",
      " 431  8486X_Viento                              17544 non-null  float64\n",
      " 432  8500A_Viento                              17544 non-null  float64\n",
      " 433  9016X_Viento                              17544 non-null  float64\n",
      " 434  9257X_Viento                              17544 non-null  float64\n",
      " 435  9301X_Viento                              17544 non-null  float64\n",
      " 436  9352A_Viento                              17544 non-null  float64\n",
      " 437  9377Y_Viento                              17544 non-null  float64\n",
      " 438  9434_Viento                               17544 non-null  float64\n",
      " 439  9573X_Viento                              17544 non-null  float64\n",
      " 440  9677_Viento                               17544 non-null  float64\n",
      " 441  9814X_Viento                              17544 non-null  float64\n",
      " 442  9843A_Viento                              17544 non-null  float64\n",
      " 443  9946X_Viento                              17544 non-null  float64\n",
      " 444  B275E_Viento                              17544 non-null  float64\n",
      " 445  B569X_Viento                              17544 non-null  float64\n",
      " 446  B760X_Viento                              17544 non-null  float64\n",
      " 447  B925_Viento                               17544 non-null  float64\n",
      " 448  C148F_Viento                              17544 non-null  float64\n",
      " 449  C249I_Viento                              17544 non-null  float64\n",
      " 450  C619Y_Viento                              17544 non-null  float64\n",
      " 451  C639M_Viento                              17544 non-null  float64\n",
      " 452  C649R_Viento                              17544 non-null  float64\n",
      " 453  C659H_Viento                              17544 non-null  float64\n",
      " 454  C659M_Viento                              17544 non-null  float64\n",
      " 455  0016A_Viento_pred                         17544 non-null  float64\n",
      " 456  0201D_Viento_pred                         17544 non-null  float64\n",
      " 457  0244X_Viento_pred                         17544 non-null  float64\n",
      " 458  0367_Viento_pred                          17544 non-null  float64\n",
      " 459  1025X_Viento_pred                         17544 non-null  float64\n",
      " 460  1056K_Viento_pred                         17544 non-null  float64\n",
      " 461  1074C_Viento_pred                         17544 non-null  float64\n",
      " 462  1111X_Viento_pred                         17544 non-null  float64\n",
      " 463  1186P_Viento_pred                         17544 non-null  float64\n",
      " 464  1279X_Viento_pred                         17544 non-null  float64\n",
      " 465  1387E_Viento_pred                         17544 non-null  float64\n",
      " 466  1390X_Viento_pred                         17544 non-null  float64\n",
      " 467  1466A_Viento_pred                         17544 non-null  float64\n",
      " 468  1475X_Viento_pred                         17544 non-null  float64\n",
      " 469  1719_Viento_pred                          17544 non-null  float64\n",
      " 470  2044B_Viento_pred                         17544 non-null  float64\n",
      " 471  2048A_Viento_pred                         17544 non-null  float64\n",
      " 472  2331_Viento_pred                          17544 non-null  float64\n",
      " 473  2734D_Viento_pred                         17544 non-null  float64\n",
      " 474  2777K_Viento_pred                         17544 non-null  float64\n",
      " 475  2873X_Viento_pred                         17544 non-null  float64\n",
      " 476  2891A_Viento_pred                         17544 non-null  float64\n",
      " 477  2946X_Viento_pred                         17544 non-null  float64\n",
      " 478  3104Y_Viento_pred                         17544 non-null  float64\n",
      " 479  3140Y_Viento_pred                         17544 non-null  float64\n",
      " 480  3266A_Viento_pred                         17544 non-null  float64\n",
      " 481  3475X_Viento_pred                         17544 non-null  float64\n",
      " 482  3504X_Viento_pred                         17544 non-null  float64\n",
      " 483  3526X_Viento_pred                         17544 non-null  float64\n",
      " 484  3562X_Viento_pred                         17544 non-null  float64\n",
      " 485  4096Y_Viento_pred                         17544 non-null  float64\n",
      " 486  4340_Viento_pred                          17544 non-null  float64\n",
      " 487  5390Y_Viento_pred                         17544 non-null  float64\n",
      " 488  5402_Viento_pred                          17544 non-null  float64\n",
      " 489  5582A_Viento_pred                         17544 non-null  float64\n",
      " 490  5598X_Viento_pred                         17544 non-null  float64\n",
      " 491  5612X_Viento_pred                         17544 non-null  float64\n",
      " 492  5906X_Viento_pred                         17544 non-null  float64\n",
      " 493  5972X_Viento_pred                         17544 non-null  float64\n",
      " 494  6045X_Viento_pred                         17544 non-null  float64\n",
      " 495  6172X_Viento_pred                         17544 non-null  float64\n",
      " 496  6268Y_Viento_pred                         17544 non-null  float64\n",
      " 497  6307X_Viento_pred                         17544 non-null  float64\n",
      " 498  6312E_Viento_pred                         17544 non-null  float64\n",
      " 499  7066Y_Viento_pred                         17544 non-null  float64\n",
      " 500  7195X_Viento_pred                         17544 non-null  float64\n",
      " 501  7275C_Viento_pred                         17544 non-null  float64\n",
      " 502  8025_Viento_pred                          17544 non-null  float64\n",
      " 503  8036Y_Viento_pred                         17544 non-null  float64\n",
      " 504  8177A_Viento_pred                         17544 non-null  float64\n",
      " 505  8270X_Viento_pred                         17544 non-null  float64\n",
      " 506  8486X_Viento_pred                         17544 non-null  float64\n",
      " 507  8500A_Viento_pred                         17544 non-null  float64\n",
      " 508  9016X_Viento_pred                         17544 non-null  float64\n",
      " 509  9257X_Viento_pred                         17544 non-null  float64\n",
      " 510  9301X_Viento_pred                         17544 non-null  float64\n",
      " 511  9352A_Viento_pred                         17544 non-null  float64\n",
      " 512  9377Y_Viento_pred                         17544 non-null  float64\n",
      " 513  9434_Viento_pred                          17544 non-null  float64\n",
      " 514  9573X_Viento_pred                         17544 non-null  float64\n",
      " 515  9677_Viento_pred                          17544 non-null  float64\n",
      " 516  9814X_Viento_pred                         17544 non-null  float64\n",
      " 517  9843A_Viento_pred                         17544 non-null  float64\n",
      " 518  9946X_Viento_pred                         17544 non-null  float64\n",
      " 519  B275E_Viento_pred                         17544 non-null  float64\n",
      " 520  B569X_Viento_pred                         17544 non-null  float64\n",
      " 521  B760X_Viento_pred                         17544 non-null  float64\n",
      " 522  B925_Viento_pred                          17544 non-null  float64\n",
      " 523  C148F_Viento_pred                         17544 non-null  float64\n",
      " 524  C249I_Viento_pred                         17544 non-null  float64\n",
      " 525  C619Y_Viento_pred                         17544 non-null  float64\n",
      " 526  C639M_Viento_pred                         17544 non-null  float64\n",
      " 527  C649R_Viento_pred                         17544 non-null  float64\n",
      " 528  C659H_Viento_pred                         17544 non-null  float64\n",
      " 529  C659M_Viento_pred                         17544 non-null  float64\n",
      " 530  Eolica_emi                                17544 non-null  int64  \n",
      " 531  Nuclear_emi                               17544 non-null  int64  \n",
      " 532  Carbon_emi                                17544 non-null  float64\n",
      " 533  Ciclo_combinado_emi                       17544 non-null  float64\n",
      " 534  Hidraulica_emi                            17544 non-null  int64  \n",
      " 535  Intercambios_int_emi                      17544 non-null  int64  \n",
      " 536  Solar_fotovoltaica_emi                    17544 non-null  int64  \n",
      " 537  Solar_termica_emi                         17544 non-null  int64  \n",
      " 538  Termica_renovable_emi                     17544 non-null  int64  \n",
      " 539  Motores_diesel_emi                        17544 non-null  float64\n",
      " 540  Turbina_de_gas_emi                        17544 non-null  float64\n",
      " 541  Turbina_de_vapor_emi                      17544 non-null  float64\n",
      " 542  Generacion_auxiliar_emi                   17544 non-null  float64\n",
      " 543  Cogeneracion_y_residuos_emi               17544 non-null  float64\n",
      " 544  Eolica_gen                                17544 non-null  float64\n",
      " 545  Nuclear_gen                               17544 non-null  int64  \n",
      " 546  Carbon_gen                                17544 non-null  int64  \n",
      " 547  Ciclo_combinado_gen                       17544 non-null  int64  \n",
      " 548  Hidraulica_gen                            17544 non-null  float64\n",
      " 549  Intercambios_int_gen                      17544 non-null  int64  \n",
      " 550  Solar_fotovoltaica_gen                    17544 non-null  float64\n",
      " 551  Solar_termica_gen                         17544 non-null  float64\n",
      " 552  Termica_renovable_gen                     17544 non-null  int64  \n",
      " 553  Motores_diesel_gen                        17544 non-null  int64  \n",
      " 554  Turbina_de_gas_gen                        17544 non-null  int64  \n",
      " 555  Turbina_de_vapor_gen                      17544 non-null  int64  \n",
      " 556  Generacion_auxiliar_gen                   17544 non-null  int64  \n",
      " 557  Cogeneracion_y_residuos_gen               17544 non-null  int64  \n",
      " 558  Real                                      17544 non-null  float64\n",
      " 559  Prevista                                  17544 non-null  float64\n",
      " 560  Programada                                17544 non-null  float64\n",
      " 561  file                                      17544 non-null  object \n",
      " 562  Asturias                                  17544 non-null  float64\n",
      " 563  Cantabria                                 17544 non-null  float64\n",
      " 564  Navarra                                   17544 non-null  float64\n",
      " 565  País Vasco                                17544 non-null  float64\n",
      " 566  Cataluña                                  17544 non-null  float64\n",
      " 567  Aragón                                    17544 non-null  float64\n",
      " 568  Galicia                                   17544 non-null  float64\n",
      " 569  Islas Baleares                            17544 non-null  float64\n",
      " 570  La Rioja                                  17544 non-null  float64\n",
      " 571  Valencia                                  17544 non-null  float64\n",
      " 572  Castilla y León                           17544 non-null  float64\n",
      " 573  Castilla La Mancha                        17544 non-null  float64\n",
      " 574  Extremadura                               17544 non-null  float64\n",
      " 575  Andalucía                                 17544 non-null  float64\n",
      " 576  Murcia                                    17544 non-null  float64\n",
      " 577  Madrid                                    17544 non-null  float64\n",
      " 578  Solar_altitude                            17544 non-null  float64\n",
      " 579  is_weekend                                17544 non-null  int64  \n",
      " 580  Carbon_emi_1day_before                    17544 non-null  float64\n",
      " 581  Carbon_emi_2days_before                   17544 non-null  float64\n",
      " 582  Carbon_emi_3days_before                   17544 non-null  float64\n",
      " 583  Ciclo_combinado_emi_1day_before           17544 non-null  float64\n",
      " 584  Ciclo_combinado_emi_2days_before          17544 non-null  float64\n",
      " 585  Ciclo_combinado_emi_3days_before          17544 non-null  float64\n",
      " 586  Motores_diesel_emi_1day_before            17544 non-null  float64\n",
      " 587  Motores_diesel_emi_2days_before           17544 non-null  float64\n",
      " 588  Motores_diesel_emi_3days_before           17544 non-null  float64\n",
      " 589  Turbina_de_vapor_emi_1day_before          17544 non-null  float64\n",
      " 590  Turbina_de_vapor_emi_2days_before         17544 non-null  float64\n",
      " 591  Turbina_de_vapor_emi_3days_before         17544 non-null  float64\n",
      " 592  Turbina_de_gas_emi_1day_before            17544 non-null  float64\n",
      " 593  Turbina_de_gas_emi_2days_before           17544 non-null  float64\n",
      " 594  Turbina_de_gas_emi_3days_before           17544 non-null  float64\n",
      " 595  Cogeneracion_y_residuos_emi_1day_before   17544 non-null  float64\n",
      " 596  Cogeneracion_y_residuos_emi_2days_before  17544 non-null  float64\n",
      " 597  Cogeneracion_y_residuos_emi_3days_before  17544 non-null  float64\n",
      "dtypes: float64(574), int64(23), object(1)\n",
      "memory usage: 80.0+ MB\n",
      "None\n",
      "                Ano           Mes           Dia          Hora   Minuto  0016A_Altitud  0201D_Altitud  0244X_Altitud  0367_Altitud  1025X_Altitud  1056K_Altitud  1074C_Altitud  1111X_Altitud  1186P_Altitud  1279X_Altitud  1387E_Altitud  1390X_Altitud  1466A_Altitud  1475X_Altitud  1719_Altitud  2044B_Altitud  2048A_Altitud  2331_Altitud  2734D_Altitud  2777K_Altitud  2873X_Altitud  2891A_Altitud  2946X_Altitud  3104Y_Altitud  3140Y_Altitud  3266A_Altitud  3475X_Altitud  3504X_Altitud  3526X_Altitud  3562X_Altitud  4096Y_Altitud  4340_Altitud  5390Y_Altitud  5402_Altitud  5582A_Altitud  5598X_Altitud  5612X_Altitud  5906X_Altitud  5972X_Altitud  6045X_Altitud  6172X_Altitud  6268Y_Altitud  6307X_Altitud  6312E_Altitud  7066Y_Altitud  7195X_Altitud  7275C_Altitud  8025_Altitud  8036Y_Altitud  8177A_Altitud  8270X_Altitud  8486X_Altitud  8500A_Altitud  9016X_Altitud  9257X_Altitud  9301X_Altitud  9352A_Altitud  9377Y_Altitud  9434_Altitud  9573X_Altitud  9677_Altitud  9814X_Altitud  \\\n",
      "count  17544.000000  17544.000000  17544.000000  17544.000000  17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0       17544.0        17544.0   \n",
      "mean    2023.213406      6.519836     15.738714     11.500000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "std        0.674661      3.449649      8.804172      6.922384      0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0           0.0            0.0   \n",
      "min     2022.000000      1.000000      1.000000      0.000000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "25%     2023.000000      4.000000      8.000000      5.750000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "50%     2023.000000      7.000000     16.000000     11.500000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "75%     2024.000000     10.000000     23.000000     17.250000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "max     2024.000000     12.000000     31.000000     23.000000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "\n",
      "       9843A_Altitud  9946X_Altitud  B275E_Altitud  B569X_Altitud  B760X_Altitud  B925_Altitud  C148F_Altitud  C249I_Altitud  C619Y_Altitud  C639M_Altitud  C649R_Altitud  C659H_Altitud  C659M_Altitud  0016A_Humedad_relativa  0201D_Humedad_relativa  0244X_Humedad_relativa  0367_Humedad_relativa  1025X_Humedad_relativa  1056K_Humedad_relativa  1074C_Humedad_relativa  1111X_Humedad_relativa  1186P_Humedad_relativa  1279X_Humedad_relativa  1387E_Humedad_relativa  1390X_Humedad_relativa  1466A_Humedad_relativa  1475X_Humedad_relativa  1719_Humedad_relativa  2044B_Humedad_relativa  2048A_Humedad_relativa  2331_Humedad_relativa  2734D_Humedad_relativa  2777K_Humedad_relativa  2873X_Humedad_relativa  2891A_Humedad_relativa  2946X_Humedad_relativa  3104Y_Humedad_relativa  3140Y_Humedad_relativa  3266A_Humedad_relativa  3475X_Humedad_relativa  3504X_Humedad_relativa  3526X_Humedad_relativa  3562X_Humedad_relativa  4096Y_Humedad_relativa  4340_Humedad_relativa  5390Y_Humedad_relativa  \\\n",
      "count        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000   \n",
      "mean           825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               78.645505               85.298503               73.703971              79.549966               83.341061               87.932414               86.955535               84.639564               82.369211               88.507275               84.361469               90.605800               89.375963               88.018811              88.927185               88.934172               84.555380              85.852212               85.244499               81.782440               83.053693               82.640602               77.558665               84.977518               84.109440               94.236775               72.661909               79.014367               73.680327               72.998705               86.776954              73.741861               74.705176   \n",
      "std              0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0               12.982027                7.321991                9.220527              13.361466               12.949354               11.680500               11.048939                8.768136               15.194815                9.002921                9.570424                5.269272                7.560695               11.288062               9.367725               12.388408               12.526677               9.763116               13.444214               12.316739                7.415661                8.167666               10.775970               14.493382               15.170472                8.549972               12.758881               10.142724               15.405912               11.547168               12.327831              11.834436               10.694130   \n",
      "min            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               35.143417               44.376778               44.055698              35.257401               34.121571               45.781467               44.224327               41.570076               26.824883               51.351650               41.626255               69.196899               48.224895               31.320835              53.042210               35.862324               32.653690              43.500000               42.588963               33.633232               53.116501               48.782921               38.614082               23.211906               24.716419               51.223278               27.438637               41.801983               21.076496               36.332546               32.382313              34.467346               37.831699   \n",
      "25%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               69.355709               84.045591               67.481009              69.158333               74.194418               79.404572               79.047640               79.850397               72.173241               82.498598               78.167864               87.665756               86.605227               83.264822              83.348827               83.629280               77.947329              79.988995               77.839939               75.635609               78.815414               77.627405               72.039148               79.133202               76.291180               90.934404               64.325819               72.744003               63.933352               65.629507               80.770510              65.417509               68.761271   \n",
      "50%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               82.040009               88.000000               75.149952              80.952877               86.333858               91.402016               89.744781               86.704533               86.221016               90.301041               85.052002               91.740906               91.158131               91.158867              89.618397               93.283924               89.886299              88.417191               90.148373               86.548225               84.936806               83.539944               80.797291               89.664982               89.155544               99.345173               74.113888               81.075363               75.596615               75.931007               90.075855              75.838520               75.943535   \n",
      "75%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               89.243284               88.873730               80.633869              90.897900               94.273117               98.646008               96.268223               91.064487               95.250309               95.710987               91.675144               94.470640               94.286194               95.767588              97.387156               98.607418               93.393618              93.041420               94.334354               90.800747               88.641708               89.005104               85.457214               95.388365               95.807928              100.000000               81.967384               86.378958               85.048122               81.950157               96.159042              83.297071               82.492586   \n",
      "max            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0              100.000000               96.201492               92.850372             100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000             100.000000              100.000000              100.000000             100.000000              100.000000               99.131729               97.361641              100.000000               94.833328              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000               94.312561              100.000000              97.440346              100.000000   \n",
      "\n",
      "       5402_Humedad_relativa  5582A_Humedad_relativa  5598X_Humedad_relativa  5612X_Humedad_relativa  5906X_Humedad_relativa  5972X_Humedad_relativa  6045X_Humedad_relativa  6172X_Humedad_relativa  6268Y_Humedad_relativa  6307X_Humedad_relativa  6312E_Humedad_relativa  7066Y_Humedad_relativa  7195X_Humedad_relativa  7275C_Humedad_relativa  8025_Humedad_relativa  8036Y_Humedad_relativa  8177A_Humedad_relativa  8270X_Humedad_relativa  8486X_Humedad_relativa  8500A_Humedad_relativa  9016X_Humedad_relativa  9257X_Humedad_relativa  9301X_Humedad_relativa  9352A_Humedad_relativa  9377Y_Humedad_relativa  9434_Humedad_relativa  9573X_Humedad_relativa  9677_Humedad_relativa  9814X_Humedad_relativa  9843A_Humedad_relativa  9946X_Humedad_relativa  B275E_Humedad_relativa  B569X_Humedad_relativa  B760X_Humedad_relativa  B925_Humedad_relativa  C148F_Humedad_relativa  C249I_Humedad_relativa  C619Y_Humedad_relativa  C639M_Humedad_relativa  C649R_Humedad_relativa  C659H_Humedad_relativa  \\\n",
      "count           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000   \n",
      "mean               80.843474               65.984625               77.721553               71.278969               83.337645               78.539585               69.841095               66.752875               68.890195               64.526055               56.298102               62.965265               67.730889               60.391305              62.182325               68.963085               79.861424               77.134832               75.276632               74.595074               82.451906               90.247060               73.866613               85.167041               80.173777              77.837580               72.373922              83.534727               88.388428               90.161758               68.925591               71.004521               70.477186               77.031025              72.318358               78.359576               76.524213               66.051938               73.697290               68.512010               71.234412   \n",
      "std                11.637168               12.537599               11.789865               14.512291               12.052667                9.779350               10.656257               10.071838                9.992100               19.807887                8.720392               10.673023               19.723460               16.625849              13.979420               16.503389               15.759683               14.935848               14.700770               17.934932               13.347211               10.667925               12.116113                8.522143               14.041692              14.133208               18.927590               7.878008               14.102295               11.068081               13.155611                9.787736               12.391906               10.714328              12.576636                9.094445                8.243105                7.640214                6.874119                6.586608                6.279021   \n",
      "min                37.692486               29.544971               42.347481               25.950035               44.248131               40.709927               34.167091               26.718437               28.022259                7.479774               22.343262               32.434418               11.742886               10.707302              13.668671               15.541855               21.931377               30.822079               25.917404                7.757622               36.054359               39.345749               29.955261               55.516972               29.068771              32.500000                3.610710              43.236923               32.303753               37.843056               11.726532               38.816624               22.912579               42.907055              35.587482               50.042141               39.191170               37.095474               51.824158               46.707489               49.194000   \n",
      "25%                72.671116               56.236443               69.777998               61.495058               74.771177               72.316351               62.982457               61.163270               63.504913               49.027180               53.463772               55.594232               53.412779               47.153008              53.003728               57.764785               69.548813               66.428484               66.390749               63.616263               73.067299               85.759663               66.170622               79.680525               73.350519              67.926935               61.957980              79.889631               81.683283               87.750759               61.245316               64.272018               62.437084               69.073812              62.225524               73.113358               71.896402               61.387473               68.832514               63.859560               67.071508   \n",
      "50%                83.489407               69.057770               78.315510               73.324638               84.654812               80.083447               71.878860               68.868912               70.353279               62.858538               56.500000               62.780642               70.248062               61.238964              65.100990               70.229424               84.382259               77.008659               78.242172               78.870411               85.677258               94.445236               77.019798               87.481106               84.382023              79.793217               76.222572              85.039711               93.894150               94.401333               71.817127               72.540852               73.684387               78.043419              72.306442               79.324535               78.000000               66.713184               73.885296               69.311081               71.679039   \n",
      "75%                89.837851               75.929123               86.141176               81.759026               93.289244               85.824846               78.320145               74.197710               76.229778               80.094517               58.325874               70.866915               83.138556               74.187828              73.385374               81.347984               92.313303               88.737213               84.548050               88.864719               93.056423               97.988979               83.395292               91.725817               90.032566              88.891224               87.323256              88.854485              100.000000               97.144718               78.844570               78.428860               80.002470               85.017656              82.662029               84.603144               82.434813               71.021030               79.152464               73.741716               76.240509   \n",
      "max               100.000000               91.630592              100.000000              100.000000              100.000000              100.000000               92.108795               96.406479               87.178169              100.000000               88.901840               93.853462              100.000000               96.862877              91.209732              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000               93.607864              100.000000              100.000000             100.000000              100.000000             100.000000              100.000000              100.000000               92.716568               91.639984               93.311371              100.000000             100.000000              100.000000               93.166740               97.710999               92.280533               84.835785               85.018021   \n",
      "\n",
      "       C659M_Humedad_relativa  0016A_Precipitacion  0201D_Precipitacion  0244X_Precipitacion  0367_Precipitacion  1025X_Precipitacion  1056K_Precipitacion  1074C_Precipitacion  1111X_Precipitacion  1186P_Precipitacion  1279X_Precipitacion  1387E_Precipitacion  1390X_Precipitacion  1466A_Precipitacion  1475X_Precipitacion  1719_Precipitacion  2044B_Precipitacion  2048A_Precipitacion  2331_Precipitacion  2734D_Precipitacion  2777K_Precipitacion  2873X_Precipitacion  2891A_Precipitacion  2946X_Precipitacion  3104Y_Precipitacion  3140Y_Precipitacion  3266A_Precipitacion  3475X_Precipitacion  3504X_Precipitacion  3526X_Precipitacion  3562X_Precipitacion  4096Y_Precipitacion  4340_Precipitacion  5390Y_Precipitacion  5402_Precipitacion  5582A_Precipitacion  5598X_Precipitacion  5612X_Precipitacion  5906X_Precipitacion  5972X_Precipitacion  6045X_Precipitacion  6172X_Precipitacion  6268Y_Precipitacion  6307X_Precipitacion  6312E_Precipitacion  7066Y_Precipitacion  7195X_Precipitacion  \\\n",
      "count            17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000   \n",
      "mean                73.937804             0.086270             5.799117             0.084422            0.076727             0.109597             0.306239             0.148288             0.219429             0.107739             0.122511             0.294979             0.287854             0.258130             0.755983            0.578420             0.206820             0.111771            0.156214             0.144083             0.075956             0.129096             0.115862             0.093961             0.225793             0.085555             0.448395             0.142831             0.251492             0.227675             0.095650             0.079924            0.096416             0.113967            0.111405             0.096916             0.318046             0.189814             0.096850             0.270403             0.129004             0.155680             0.107539             0.069924            10.913621             0.089270             0.130954   \n",
      "std                  3.736788             1.374799             8.484172             1.363624            1.239648             1.058549             1.134688             1.035027             1.165866             1.094386             1.080889             1.351003             1.260762             1.540217             1.939839            1.799674             1.168006             1.189521            1.140424             1.612680             1.195590             1.233106             1.335515             1.317835             1.005618             1.290313             1.279893             1.590243             1.481956             1.656410             1.544702             1.290607            1.558440             1.492397            1.659046             1.547786             1.578015             1.571832             1.536314             1.828903             1.421918             1.515145             1.454879             1.129484            13.349852             1.442049             1.195240   \n",
      "min                 60.982677             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "25%                 71.405075             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.029266             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "50%                 74.044674             0.000000             0.000000             0.000000            0.000000             0.000000             0.006182             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.096921            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.101011             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "75%                 76.563118             0.000000            18.200000             0.000000            0.000000             0.000000             0.260014             0.038770             0.152167             0.000000             0.000000             0.223184             0.074588             0.051720             0.545405            0.301644             0.176452             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.259023             0.000000             0.392523             0.000000             0.055863             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.364491             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            27.250000             0.000000             0.000000   \n",
      "max                 84.846054            23.650000            19.900000            22.500000           20.700000            17.550000            17.450000            17.500000            18.700000            18.050000            17.450000            21.250000            18.850000            23.850000            22.850000           22.700000            20.050000            19.300000           19.650000            18.600000            20.500000            20.600000            22.400000            21.750000            17.150000            21.950000            16.850000            26.250000            23.550000            25.700000            25.550000            21.700000           26.400000            24.600000           27.150000            25.950000            25.600000            25.400000            25.600000            27.700000            24.800000            24.782608            24.500000            18.650000            27.250000            23.900000            19.850000   \n",
      "\n",
      "       7275C_Precipitacion  8025_Precipitacion  8036Y_Precipitacion  8177A_Precipitacion  8270X_Precipitacion  8486X_Precipitacion  8500A_Precipitacion  9016X_Precipitacion  9257X_Precipitacion  9301X_Precipitacion  9352A_Precipitacion  9377Y_Precipitacion  9434_Precipitacion  9573X_Precipitacion  9677_Precipitacion  9814X_Precipitacion  9843A_Precipitacion  9946X_Precipitacion  B275E_Precipitacion  B569X_Precipitacion  B760X_Precipitacion  B925_Precipitacion  C148F_Precipitacion  C249I_Precipitacion  C619Y_Precipitacion  C639M_Precipitacion  C649R_Precipitacion  C659H_Precipitacion  C659M_Precipitacion  0016A_Presion  0201D_Presion  0244X_Presion  0367_Presion  1025X_Presion  1056K_Presion  1074C_Presion  1111X_Presion  1186P_Presion  1279X_Presion  1387E_Presion  1390X_Presion  1466A_Presion  1475X_Presion  1719_Presion  2044B_Presion  2048A_Presion  2331_Presion  2734D_Presion  2777K_Presion  2873X_Presion  2891A_Presion  2946X_Presion  3104Y_Presion  3140Y_Presion  3266A_Presion  \\\n",
      "count         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   \n",
      "mean              0.089959            0.092795             0.117184             0.079202             0.215752             0.170503             0.090567             0.106948             0.275423             0.094790             0.071674             0.083917            0.102274             0.094026            0.201007             0.577843             0.344400             0.220856             0.088819             0.095017             0.105574            0.089201             0.084306             0.094933             0.095212             0.094453             0.091629             0.166037             0.094156    1006.614252     977.252804     985.597277    999.981778    1035.812160     993.382497    1001.733697    1010.459009     958.134798     942.912221    1001.429373     992.573671    1024.976641    1008.116474   1040.306780     895.236082     881.694108    915.033602     894.915049     915.742427     882.707738     868.261462     937.138042     896.920626     918.711744     847.784480   \n",
      "std               1.358939            1.499219             1.468069             1.279182             1.421547             0.987977             1.463988             1.006781             1.073314             1.175622             1.158436             1.116244            1.357365             1.333767            0.693020             1.539587             1.317198             2.119091             1.427753             1.535106             1.348240            1.439229             1.361748             1.535215             1.540097             1.525360             1.480200             2.044305             1.519918       5.476445       7.599955       6.609672      5.892336       7.229404       8.594393       6.886549       6.587984       7.254397       5.314445       8.553263       7.359677       6.838308       9.956167      8.763675       5.113925       5.093212      5.654577       5.668929       5.654209       6.627094       5.584496       5.884323       6.422975       4.977187       4.984431   \n",
      "min               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000     992.366089     949.485779     964.743591    983.063538     997.990000     958.150818     976.806641     986.516174     936.622559     930.074646     962.035034     955.824158     995.485779     970.484375    996.750000     883.023132     868.765564    894.983398     879.485291     890.274109     859.702454     850.983704     917.551514     876.032593     907.584656     833.643311   \n",
      "25%               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1002.686615     968.475000     981.283859    995.967575    1032.246307     988.083115     998.079941    1006.156403     953.482544     939.567642     997.939453     989.363266    1021.765793    1001.700000   1035.568878     891.322952     877.897263    911.431488     891.041199     912.623840     879.086426     865.239792     933.137497     893.129227     915.257111     844.435928   \n",
      "50%               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.007991             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1006.488434     978.150238     986.059235   1000.070221    1037.249878     994.859924    1003.100616    1010.734467     957.847473     942.041840    1004.164734     994.475311    1026.458130    1010.365326   1041.600952     895.172333     881.989471    915.850189     894.715790     916.239166     883.839813     868.553101     937.685974     897.582153     918.454773     848.212219   \n",
      "75%               0.000000            0.000000             0.000000             0.000000             0.076567             0.000000             0.000000             0.000000             0.259751             0.000000             0.000000             0.000000            0.000000             0.000000            0.119636             0.457875             0.135307             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1010.068298     983.446930     989.980331   1003.922028    1040.510040     999.399033    1006.367859    1015.289383     961.944427     945.551041    1007.079727     997.462631    1029.393127    1015.010147   1045.943237     898.912323     885.372894    919.091141     897.697845     919.564087     887.034073     871.075089     941.187515     901.554733     922.006622     851.416428   \n",
      "max              22.150000           25.050000            24.050000            21.200000            23.550000            16.050000            24.700000            16.650000            17.000000            20.050000            19.600000            19.150000           22.600000            22.100000           10.200000            19.450000            18.850000            21.600000            23.700000            25.650000            22.000000           24.100000            22.550000            26.500000            26.750000            25.200000            24.750000            25.600000            24.900000    1021.202148     995.585205    1002.250305   1017.098450    1050.263794    1010.408813    1015.991089    1026.792114     995.608032     986.618750    1016.074036    1007.719849    1044.007202    1036.501831   1062.736816     908.773560     897.100000    927.990601     933.289001     929.542603     907.490000     907.490000     950.734985     913.570000     932.370972     858.993896   \n",
      "\n",
      "       3475X_Presion  3504X_Presion  3526X_Presion  3562X_Presion  4096Y_Presion  4340_Presion  5390Y_Presion  5402_Presion  5582A_Presion  5598X_Presion  5612X_Presion  5906X_Presion  5972X_Presion  6045X_Presion  6172X_Presion  6268Y_Presion  6307X_Presion  6312E_Presion  7066Y_Presion  7195X_Presion  7275C_Presion  8025_Presion  8036Y_Presion  8177A_Presion  8270X_Presion  8486X_Presion  8500A_Presion  9016X_Presion  9257X_Presion  9301X_Presion  9352A_Presion  9377Y_Presion  9434_Presion  9573X_Presion  9677_Presion  9814X_Presion  9843A_Presion  9946X_Presion  B275E_Presion  B569X_Presion  B760X_Presion  B925_Presion  C148F_Presion  C249I_Presion  C619Y_Presion  C639M_Presion  C649R_Presion  C659H_Presion  C659M_Presion  0016A_Temperatura  0201D_Temperatura  0244X_Temperatura  0367_Temperatura  1025X_Temperatura  1056K_Temperatura  1074C_Temperatura  1111X_Temperatura  1186P_Temperatura  1279X_Temperatura  1387E_Temperatura  1390X_Temperatura  1466A_Temperatura  \\\n",
      "count   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean      978.182358    1022.088209     980.324093     971.959972     958.970244    968.920842     931.726001   1004.652934     776.135546     963.627151    1004.847004     962.037143    1012.914593    1082.939882     999.080664     681.213721    1080.510991     947.321480     931.512748    1079.891410     944.743914   1006.288915    1009.773076     916.244223     952.367380    1027.035862    1009.602701     905.604791    1002.642391     976.772294     884.050188     942.072987    986.699917     879.289106   1099.530471     930.624311     899.860563    1063.415144    1011.156408    1013.196395    1010.904770   1011.572907     941.384272    1014.843741    1016.350211    1019.665010    1014.381467    1020.355702    1015.674169          17.489967          18.770380          20.453208         18.530294          15.427593          16.435829          15.660039          16.364449          16.727039          16.015887          17.629651          15.882819          15.418910   \n",
      "std         5.253027       4.860617       5.855291       3.958558       4.216329      4.027742       3.475018      4.867036       9.398215       3.141394       4.086339       4.639425       3.165797       7.721168       5.561200      15.030891       7.394253       3.153458       3.022272       8.056099       3.959151      4.783542       4.547660       4.186292       6.095021       7.286145       7.498415       6.967444       5.720381       3.390610       3.986678       4.319986      5.180013       6.140727      7.585651       5.092917       5.083053       8.306629       3.431824       3.408402       3.525275      4.330479       3.597388       2.630717       1.762385       2.361539       2.874364       2.999345       2.719656           3.302484           1.620038           1.611769          3.105052           3.101791           3.158015           3.007023           1.846490           3.994400           3.461672           2.213679           2.240891           2.201555   \n",
      "min       959.423035     970.862500     955.227112     957.285767     934.575000    954.535583     922.320312    990.035156     765.530762     951.886047     989.008606     945.097412     980.242615    1002.850000     984.777893     671.704712     985.641667     939.561218     926.313232     989.881250     935.171814    993.696350     998.052856     906.491333     936.578857     930.983333     872.974243     887.746948     972.475000     965.304626     871.060059     914.475000    970.670471     866.347778    976.150000     915.358582     885.355347    1005.100000     999.310181    1003.111206     998.752502    998.169739     933.985535    1008.400000    1011.150000    1009.571429    1006.880188    1009.571429    1007.661194           9.209106          13.724069          15.392507          9.331562           8.075424           7.018330           9.550410          11.091537           6.235204           6.672863          10.656863           7.899129           8.772388   \n",
      "25%       974.632492    1019.830032     976.934433     969.752319     956.082428    966.798859     929.252747   1001.481491     773.595261     961.696198    1002.355347     959.291245    1011.198288    1077.952972     995.238068     678.269257    1077.994049     945.973740     929.190857    1075.890961     942.011215   1002.867050    1006.574997     913.244125     948.327881    1024.631958    1006.046295     902.177795     998.858521     974.912476     881.271774     939.340485    983.441452     875.379028   1100.000122     927.141281     896.366028    1058.921051    1008.934097    1011.085815    1008.539612   1008.740738     939.269470    1012.756836    1015.122742    1017.840347    1012.343079    1018.271484    1013.830933          14.992661          18.200000          19.113176         16.343008          13.017057          14.358105          13.118847          15.012233          13.771352          13.555547          16.187253          14.381362          13.779011   \n",
      "50%       978.435181    1021.785126     981.989288     972.106323     958.596863    969.106293     930.882233   1003.713745     775.752899     963.748627    1004.527863     962.489288    1012.973877    1082.939209     998.339539     680.731781    1081.056274     946.950000     930.728455    1079.659302     943.950165   1005.953583    1009.225159     915.791046     951.422394    1027.783264    1009.910522     905.141632    1002.764709     976.926056     883.793610     941.511749    986.664795     878.901764   1100.000122     931.027740     900.634003    1063.812073    1010.934357    1012.791504    1010.830597   1011.565765     940.958282    1014.492462    1016.039429    1019.106415    1013.835541    1019.902466    1015.338623          17.187369          18.200000          20.376690         18.308249          14.882962          16.114405          15.404482          16.225961          16.384774          15.826605          17.367743          16.110589          15.492554   \n",
      "75%       981.787674    1024.690216     984.354156     974.487991     961.721680    971.620285     933.675232   1008.151367     777.765137     965.898560    1007.570816     964.889557    1014.807434    1087.701538    1002.332230     682.326584    1084.336151     947.312393     933.250092    1084.523468     946.958954   1009.539078    1012.478287     918.691635     955.224838    1030.534729    1013.846512     907.897202    1006.775650     978.925629     886.630753     944.780624    989.808594     882.591721   1100.000122     934.494980     903.618088    1068.642059    1013.134659    1015.174881    1013.295547   1014.245544     942.886185    1016.809479    1017.349579    1021.254456    1016.187485    1022.326355    1017.391373          20.069508          19.784244          21.684522         20.708230          17.426626          18.631975          17.842211          17.542095          19.531332          18.537333          18.808368          17.559852          17.054851   \n",
      "max       990.219971    1033.520508     991.270874     982.035156     971.077942    977.858215     943.090820   1018.321228     921.175000     971.401001    1014.922058     996.007143    1022.048340    1100.000000    1016.390259     921.175000    1091.871216     959.018799     941.973206    1095.334106     958.357239   1019.943787    1022.909363     939.146240     982.516667    1036.435059    1024.199951     978.728572    1016.572693     987.387268     897.100000     956.076233   1001.355530     933.516667   1100.000122     942.693359     920.900000    1077.724365    1021.391663    1024.071045    1019.663147   1023.080688     975.747009    1022.594727    1022.710083    1027.051147    1022.991089    1028.691162    1023.201904          25.365870          23.720308          24.801941         27.454216          29.653635          26.357777          26.198933          22.144009          29.071087          26.330053          27.271729          22.133320          23.850000   \n",
      "\n",
      "       1475X_Temperatura  1719_Temperatura  2044B_Temperatura  2048A_Temperatura  2331_Temperatura  2734D_Temperatura  2777K_Temperatura  2873X_Temperatura  2891A_Temperatura  2946X_Temperatura  3104Y_Temperatura  3140Y_Temperatura  3266A_Temperatura  3475X_Temperatura  3504X_Temperatura  3526X_Temperatura  3562X_Temperatura  4096Y_Temperatura  4340_Temperatura  5390Y_Temperatura  5402_Temperatura  5582A_Temperatura  5598X_Temperatura  5612X_Temperatura  5906X_Temperatura  5972X_Temperatura  6045X_Temperatura  6172X_Temperatura  6268Y_Temperatura  6307X_Temperatura  6312E_Temperatura  7066Y_Temperatura  7195X_Temperatura  7275C_Temperatura  8025_Temperatura  8036Y_Temperatura  8177A_Temperatura  8270X_Temperatura  8486X_Temperatura  8500A_Temperatura  9016X_Temperatura  9257X_Temperatura  9301X_Temperatura  9352A_Temperatura  9377Y_Temperatura  9434_Temperatura  9573X_Temperatura  9677_Temperatura  9814X_Temperatura  9843A_Temperatura  9946X_Temperatura  B275E_Temperatura  \\\n",
      "count       17544.000000      17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean           17.604202         15.709500          12.152934          11.258528         12.424384          13.797902          13.693619          14.585602          14.073021          14.462330          10.236292          13.941308           9.673314          16.510689          15.162141          18.716862          18.115146          13.363093         18.323821          16.635097         19.237422          17.191880          17.880045          18.839378          20.520656          20.223832          18.087552          20.124534          20.968311          13.200191          22.977973          18.628024          14.742133          18.063653         21.764830          21.527819          15.330488          16.315153          12.304849          19.969096          12.382028          12.020784          16.251534          11.842602          11.803982         17.095796          16.129618          4.094196          11.730402          11.841330          16.500180          20.667096   \n",
      "std             2.012191          2.104158           2.855156           3.870807          3.894740           3.347185           3.403999           2.903663           2.386122           3.435158           3.464440           4.232740           2.190034           2.338979           2.692598           3.072061           2.860887           3.019844          3.420430           2.595066          2.697898           4.134224           3.454291           3.431958           1.804940           1.887249           3.645309           1.467471           1.444196           3.757836           3.763338           2.841842           4.254519           3.323264          2.795092           2.889968           3.977368           3.141722           3.298735           3.060675           4.471427           2.962623           3.004662           3.284912           3.712586          2.837490           3.937884          2.676851           3.277672           3.310015           3.319882           2.168583   \n",
      "min            10.800522          9.213299           5.528142           1.097467          1.238998           4.032483           3.276657           6.129852           6.669375           4.529089          -2.571681           3.833361           1.310746          10.209183           6.670433          11.093131          11.029390           3.581458          9.014250           6.408361         11.711831           8.770741           8.870099           9.871223          15.437985          12.654667           8.906227          15.487394          15.691759           3.845679          14.349721           9.966097           3.986917           8.902047         13.657481          14.803053           6.134442           6.581284           3.846155          11.195189           0.124064           5.566590           9.428516           3.859474           1.933386          9.993331           5.996670         -3.659091           2.881428           3.597418           9.786832          14.762064   \n",
      "25%            16.301046         14.254015          10.129621           8.511592          9.776810          11.749185          11.402154          12.488989          12.427768          12.086294           8.317264          10.931274           8.526004          14.877525          13.182480          16.500592          16.016516          11.367220         15.733006          14.902228         17.555050          13.950561          15.459084          16.358899          19.280191          19.202837          15.504602          19.122458          20.019773          10.391383          19.577219          16.606481          11.608628          15.694075         19.673180          19.243611          12.515400          14.072957           9.953700          17.636591           9.224771           9.808533          14.158523           9.485501           9.137678         14.987630          13.376353          2.429696           9.632200           9.716738          14.058077          18.993347   \n",
      "50%            17.494437         15.708643          11.750570          10.574811         12.007071          13.190019          12.962425          14.626769          14.261396          14.415085          10.160548          12.970313           9.788213          16.079656          14.994461          18.366067          17.721582          13.153453         18.212631          16.770646         19.039738          16.405367          17.302588          17.969643          20.402181          20.058752          17.413295          19.991214          21.059481          12.886318          22.068759          18.453574          13.973454          17.749334         21.682583          21.101799          14.256949          15.995227          11.742260          19.399300          12.204132          11.648264          15.714405          11.176358          11.146039         16.731733          15.659365          4.394750          11.331325          11.472409          15.758046          20.677589   \n",
      "75%            18.764968         17.281470          13.868133          13.440237         14.842039          15.518197          15.508738          16.782843          15.718676          16.565770          11.934982          16.407528          11.063738          17.794713          16.846859          20.625689          20.024064          15.160230         20.657561          17.865079         21.002017          19.963594          19.883599          21.071764          21.662644          21.179765          20.062195          20.968554          22.035738          15.904459          27.250000          20.522395          17.638625          20.406354         23.779818          23.709703          17.932578          18.272719          14.187555          22.186184          15.509917          13.896821          18.015180          13.832473          13.744866         18.841123          18.589514          6.188663          13.246682          13.685354          18.486175          22.456505   \n",
      "max            24.922523         22.700000          22.651524          26.387339         24.050709          25.494793          26.770939          22.092087          22.400000          24.363865          22.255838          28.357948          16.850000          26.250000          23.550000          29.267820          28.075588          24.471287         28.790947          25.220070         29.241638          28.805784          29.312561          29.956688          26.455339          27.700000          31.344837          26.799393          25.327328          24.299139          27.250000          28.008907          28.096182          28.659342         29.971210          28.957285          27.564781          28.460930          24.085773          30.013544          25.595163          22.743074          26.838495          22.942966          24.660479         27.190504          30.258717         10.200000          24.747490          23.148859          28.849724          25.698637   \n",
      "\n",
      "       B569X_Temperatura  B760X_Temperatura  B925_Temperatura  C148F_Temperatura  C249I_Temperatura  C619Y_Temperatura  C639M_Temperatura  C649R_Temperatura  C659H_Temperatura  C659M_Temperatura  0016A_Viento  0201D_Viento  0244X_Viento   0367_Viento  1025X_Viento  1056K_Viento  1074C_Viento  1111X_Viento  1186P_Viento  1279X_Viento  1387E_Viento  1390X_Viento  1466A_Viento  1475X_Viento   1719_Viento  2044B_Viento  2048A_Viento   2331_Viento  2734D_Viento  2777K_Viento  2873X_Viento  2891A_Viento  2946X_Viento  3104Y_Viento  3140Y_Viento  3266A_Viento  3475X_Viento  3504X_Viento  3526X_Viento  3562X_Viento  4096Y_Viento   4340_Viento  5390Y_Viento   5402_Viento  5582A_Viento  5598X_Viento  5612X_Viento  5906X_Viento  5972X_Viento  6045X_Viento  6172X_Viento  6268Y_Viento  6307X_Viento  6312E_Viento  7066Y_Viento  7195X_Viento  7275C_Viento   8025_Viento  8036Y_Viento  8177A_Viento  8270X_Viento  8486X_Viento  8500A_Viento  9016X_Viento  9257X_Viento  9301X_Viento  9352A_Viento  \\\n",
      "count       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000   \n",
      "mean           22.175810          19.457712         21.104257          19.859160          22.777946          23.088667          23.471840          23.229189          22.320892          23.295468      3.566689      3.083995      2.060858      3.082791      1.378386      2.237893      1.670337      4.692886      1.543998      1.961286      3.858413      4.068246      2.090287      1.250848      2.335673      3.331115      3.622886      4.601094      2.624350      2.567130      2.979754      3.311218      2.775559      1.190698      2.287510      4.532285      3.459781      2.017870      2.699864      2.480564      1.758413      2.617510      2.608071      2.609713      2.039537      3.056088      2.400275      3.151792      3.214833      2.046058      2.533365      2.551456      3.418905      3.060055      2.501297      2.714915      2.983721      2.168673      1.969083      3.698632      1.976334      4.247606      2.260876      2.393335      2.549918      2.549918      4.657127   \n",
      "std             1.187085           2.793852          2.621041           2.023586           1.386558           1.760407           1.649422           1.394975           1.005794           1.065554      1.788271      1.221325      0.937617      1.474555      0.834112      1.044251      0.954031      2.252141      1.366792      1.183998      1.676486      1.707074      1.067278      0.680950      0.984947      1.529467      1.948656      1.977438      1.429239      1.583025      1.559272      1.716609      1.232713      0.871661      0.976504      2.429797      1.653960      0.979043      1.316941      1.292564      0.807034      1.333638      1.008313      1.307442      0.807340      1.307723      0.941489      1.358722      1.460060      0.860881      1.073682      1.549198      1.876561      1.025727      1.118278      0.855564      1.452967      0.751247      0.842957      1.645469      0.996617      2.458352      0.755160      1.224393      1.090900      1.090900      2.395900   \n",
      "min            18.977245          10.938687         13.592285          15.553852          18.225531          17.152431          20.034756          20.064423          19.554756          20.974348      0.800000      0.800000      0.300000      0.000000      0.000000      0.300000      0.000000      1.100000      0.000000      0.000000      0.600000      1.170000      0.300000      0.000000      0.700000      0.600000      0.000000      0.800000      0.600000      0.000000      0.300000      0.300000      0.600000      0.000000      0.750000      0.000000      0.000000      0.300000      0.600000      0.000000      0.000000      0.300000      0.800000      0.000000      0.000000      0.600000      0.821429      0.300000      0.300000      0.000000      0.300000      0.300000      0.600000      0.800000      0.528571      0.923810      0.800000      0.600000      0.600000      0.600000      0.000000      0.300000      0.800000      0.000000      0.547059      0.547059      0.300000   \n",
      "25%            21.290448          17.564327         19.028690          18.358079          21.731564          21.791207          22.069849          22.084247          21.599735          22.462121      2.500000      2.200000      1.400000      1.900000      0.800000      1.700000      1.100000      3.100000      0.800000      1.100000      2.800000      2.772727      1.400000      0.800000      1.688889      2.200000      2.200000      3.100000      1.700000      1.400000      1.700000      2.200000      1.900000      0.600000      1.600000      2.800000      2.200000      1.400000      1.700000      1.400000      1.100000      1.700000      1.900000      1.700000      1.400000      2.200000      1.740000      2.200000      2.200000      1.400000      1.700000      1.400000      2.200000      2.200000      1.750000      2.133333      1.900000      1.700000      1.400000      2.500000      1.400000      2.500000      1.700000      1.700000      1.658824      1.658824      2.800000   \n",
      "50%            22.038592          19.243238         21.210130          19.282922          22.650744          22.852086          23.188914          22.885611          22.276049          23.162720      3.100000      2.500000      1.900000      2.800000      1.100000      1.900000      1.400000      4.200000      1.100000      1.700000      3.600000      3.710000      1.900000      1.100000      2.088889      3.100000      3.300000      4.400000      2.500000      2.200000      2.800000      3.100000      2.500000      1.100000      2.133333      3.900000      3.300000      1.900000      2.500000      2.200000      1.700000      2.500000      2.500000      2.500000      1.900000      2.800000      2.226667      3.100000      3.100000      1.900000      2.200000      1.900000      3.100000      3.600000      2.325000      2.609524      2.500000      1.900000      1.700000      3.600000      1.900000      3.600000      2.200000      2.200000      2.482353      2.482353      4.200000   \n",
      "75%            22.869579          21.500885         22.936416          21.026951          23.743445          24.403316          24.786349          24.491677          22.949311          24.080912      3.900000      3.900000      2.500000      3.900000      1.700000      2.500000      2.200000      5.800000      1.700000      2.200000      4.700000      4.927273      2.500000      1.700000      2.688889      4.200000      4.700000      5.800000      3.300000      3.600000      3.900000      4.200000      3.300000      1.400000      2.783333      5.800000      4.400000      2.500000      3.300000      3.300000      2.200000      3.300000      3.300000      3.300000      2.500000      3.900000      2.921429      3.900000      3.900000      2.500000      3.100000      3.300000      4.200000      3.600000      3.012500      3.128571      3.600000      2.500000      2.200000      4.700000      2.500000      5.300000      2.500000      3.100000      3.276471      3.276471      6.100000   \n",
      "max            26.307381          29.159519         29.609585          27.030048          28.227129          27.728361          28.512505          26.828087          25.985081          26.754694     13.100000     11.400000      6.900000      8.600000      6.700000      6.400000      5.800000     16.100000     10.800000      7.500000     10.800000     11.563636      6.700000      4.890000      6.888889     10.300000     12.800000     12.500000      8.300000      8.900000      9.700000     10.300000      8.100000      5.300000      6.616667     16.400000     10.600000      8.300000      9.700000      9.200000      5.300000      8.900000      6.900000     10.600000      7.438462      8.900000      7.385714      8.100000      9.200000      6.700000      6.400000      9.200000     13.900000      8.600000      8.375000      7.414286     10.000000      6.400000      6.700000     10.600000      8.300000     14.700000      7.500000      8.100000      6.341176      6.341176     14.400000   \n",
      "\n",
      "       9377Y_Viento   9434_Viento  9573X_Viento   9677_Viento  9814X_Viento  9843A_Viento  9946X_Viento  B275E_Viento  B569X_Viento  B760X_Viento   B925_Viento  C148F_Viento  C249I_Viento  C619Y_Viento  C639M_Viento  C649R_Viento  C659H_Viento  C659M_Viento  0016A_Viento_pred  0201D_Viento_pred  0244X_Viento_pred  0367_Viento_pred  1025X_Viento_pred  1056K_Viento_pred  1074C_Viento_pred  1111X_Viento_pred  1186P_Viento_pred  1279X_Viento_pred  1387E_Viento_pred  1390X_Viento_pred  1466A_Viento_pred  1475X_Viento_pred  1719_Viento_pred  2044B_Viento_pred  2048A_Viento_pred  2331_Viento_pred  2734D_Viento_pred  2777K_Viento_pred  2873X_Viento_pred  2891A_Viento_pred  2946X_Viento_pred  3104Y_Viento_pred  3140Y_Viento_pred  3266A_Viento_pred  3475X_Viento_pred  3504X_Viento_pred  3526X_Viento_pred  3562X_Viento_pred  4096Y_Viento_pred  4340_Viento_pred  5390Y_Viento_pred  5402_Viento_pred  5582A_Viento_pred  5598X_Viento_pred  5612X_Viento_pred  5906X_Viento_pred  5972X_Viento_pred  \\\n",
      "count  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000       17544.000000       1.754400e+04       1.754400e+04      17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04       17544.000000      17544.000000       17544.000000       1.754400e+04      1.754400e+04       1.754400e+04       17544.000000       1.754400e+04       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       1.754400e+04      17544.000000       17544.000000      17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean       3.121012      4.441040      2.622982      5.154408      1.708892      0.937483      3.054909      3.074419      4.120703      1.700649      1.823556      2.839261      6.014727      5.543107      2.702736      3.959371      3.830369      2.082763           3.502574       3.054826e+00       2.093478e+00          2.863463       1.031352e+00           1.947906       1.150054e+00           4.654116       1.329484e+00           1.216716           4.068267           3.403831       1.678753e+00           1.519296          2.198826           3.432234       2.924124e+00      3.798754e+00       1.702220e+00           1.616963       2.679557e+00       2.796130e+00           2.397041           0.680294           1.508194           4.750925       4.087664e+00           1.673326       2.751048e+00           3.152891       1.360146e+00          2.693929           2.101242          2.395552       1.455887e+00           2.858989           2.199925           3.690791           3.308808   \n",
      "std        1.545910      2.550068      1.654951      2.781921      1.351560      0.592922      1.269931      1.080546      2.612561      1.030439      1.008613      0.851002      2.136947      2.465146      0.729031      1.510392      1.793071      1.014482           1.695044       1.493670e+00       1.106617e+00          1.273009       8.529574e-01           1.099124       1.121743e+00           1.841026       1.124715e+00           0.773667           1.821747           0.985485       1.100548e+00           0.652917          1.366796           1.412604       1.562717e+00      1.840021e+00       9.494523e-01           1.133712       1.908050e+00       1.630094e+00           1.200222           0.569684           0.698808           1.851237       1.682830e+00           0.939994       1.801133e+00           1.542633       5.819541e-01          1.265801           0.652193          1.080223       5.182822e-01           1.468373           0.983901           1.807052           1.223006   \n",
      "min        0.000000      0.300000      0.300000      0.000000      0.000000      0.000000      1.000000      0.300000      0.000000      0.000000      0.300000      1.100000      1.900000      1.100000      0.800000      0.600000      0.000000      0.000000           0.930373      -4.768372e-08      -7.152558e-08          0.872286      -2.384186e-08           0.393672      -3.576279e-08           0.618887      -1.192093e-08           0.071303           0.685538           1.405635       1.192093e-07           0.000000          0.029825           1.034376      -1.907349e-07     -9.536743e-08      -7.152558e-08           0.000000       2.384186e-07      -1.430512e-07           0.461356           0.000000           0.011601           0.111854      -1.430512e-07           0.463061      -9.536743e-08           0.007112       4.768372e-08          0.553799           0.618831          0.259464      -1.430512e-07           0.248019           0.247877           0.136652           0.615769   \n",
      "25%        1.900000      2.500000      1.400000      3.300000      0.800000      0.600000      2.157143      2.200000      2.500000      1.100000      1.100000      2.200000      4.200000      3.600000      2.200000      2.800000      2.500000      1.400000           2.405411       2.368129e+00       1.243448e+00          1.872667       4.505958e-01           1.246473       4.666421e-01           3.346554       5.983505e-01           0.624921           2.791798           2.727972       9.729265e-01           1.068194          1.314782           2.296774       1.915791e+00      2.469829e+00       9.161426e-01           0.888215       1.281017e+00       1.683555e+00           1.453040           0.288449           1.035524           3.574698       2.832839e+00           1.220018       1.523649e+00           2.026030       9.669124e-01          1.908180           1.707514          1.748925       1.116567e+00           1.741931           1.456883           2.225953           2.354108   \n",
      "50%        2.800000      3.900000      2.200000      4.400000      1.400000      0.800000      2.800000      3.100000      3.600000      1.700000      1.700000      2.800000      5.800000      5.000000      2.800000      4.200000      3.900000      1.900000           2.781387       2.737892e+00       1.924190e+00          2.575836       7.719551e-01           1.549044       7.707570e-01           4.129161       9.159085e-01           0.973346           3.551844           3.169767       1.406674e+00           1.439278          1.883941           3.198754       2.710014e+00      3.652136e+00       1.407724e+00           1.316244       2.184665e+00       2.514146e+00           2.066940           0.567969           1.456435           4.341561       3.938899e+00           1.437954       2.226022e+00           2.881435       1.221724e+00          2.378489           2.075264          2.219876       1.449691e+00           2.515260           2.007789           3.313184           3.170051   \n",
      "75%        3.900000      5.800000      3.300000      6.700000      2.200000      1.400000      3.528571      3.600000      5.000000      2.200000      2.200000      3.300000      7.500000      7.200000      3.100000      5.300000      5.000000      2.800000           4.146969       3.182052e+00       2.793903e+00          3.545115       1.386682e+00           2.299429       1.309654e+00           5.511336       1.702399e+00           1.620648           4.791794           3.857039       2.107288e+00           1.908223          2.564327           4.366620       3.613290e+00      4.851503e+00       2.292380e+00           1.969712       3.567029e+00       3.648388e+00           3.107151           0.911896           1.893628           5.522279       5.187990e+00           1.741781       3.467566e+00           3.971207       1.652332e+00          3.099040           2.300103          2.768104       1.791480e+00           3.701739           2.783813           4.985096           4.161756   \n",
      "max       10.300000     13.900000      9.700000     17.500000     10.300000      3.600000      8.057143      8.600000     21.700000      6.700000      7.200000      7.200000     13.100000     13.900000      6.900000      7.500000      9.200000      6.100000          12.013194       1.182693e+01       6.061497e+00          8.793547       6.915824e+00           8.135352       7.100425e+00          13.919512       8.171537e+00           4.751741          12.210758           8.745016       8.746185e+00           4.445849         11.506269           9.003029       1.116309e+01      1.325397e+01       6.073560e+00           9.335615       1.200705e+01       9.755122e+00           7.052167           4.059801           5.163090          12.833286       9.753407e+00          10.730083       1.459449e+01          10.061859       4.454509e+00          9.215698           5.481841          8.783508       3.435004e+00           9.332878           6.114094           9.133139           7.414166   \n",
      "\n",
      "       6045X_Viento_pred  6172X_Viento_pred  6268Y_Viento_pred  6307X_Viento_pred  6312E_Viento_pred  7066Y_Viento_pred  7195X_Viento_pred  7275C_Viento_pred  8025_Viento_pred  8036Y_Viento_pred  8177A_Viento_pred  8270X_Viento_pred  8486X_Viento_pred  8500A_Viento_pred  9016X_Viento_pred  9257X_Viento_pred  9301X_Viento_pred  9352A_Viento_pred  9377Y_Viento_pred  9434_Viento_pred  9573X_Viento_pred  9677_Viento_pred  9814X_Viento_pred  9843A_Viento_pred  9946X_Viento_pred  B275E_Viento_pred  B569X_Viento_pred  B760X_Viento_pred  B925_Viento_pred  C148F_Viento_pred  C249I_Viento_pred  C619Y_Viento_pred  C639M_Viento_pred  C649R_Viento_pred  C659H_Viento_pred  C659M_Viento_pred  Eolica_emi  Nuclear_emi    Carbon_emi  Ciclo_combinado_emi  Hidraulica_emi  Intercambios_int_emi  Solar_fotovoltaica_emi  Solar_termica_emi  Termica_renovable_emi  Motores_diesel_emi  Turbina_de_gas_emi  Turbina_de_vapor_emi  Generacion_auxiliar_emi  Cogeneracion_y_residuos_emi    Eolica_gen   Nuclear_gen  \\\n",
      "count       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       1.754400e+04       1.754400e+04       17544.000000       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000      1.754400e+04       1.754400e+04      1.754400e+04       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04      1.754400e+04       17544.000000       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04     17544.0      17544.0  17544.000000         17544.000000         17544.0               17544.0                 17544.0            17544.0                17544.0        17544.000000        17544.000000          17544.000000             17544.000000                 17544.000000  17544.000000  17544.000000   \n",
      "mean            1.865158           2.709366           2.700732           3.124711           2.082592           2.394795           2.359891           2.875419          1.823194           2.372697       2.661456e+00       1.454021e+00           4.561255           2.352710       1.669170e+00           2.366235           2.211951           3.988125           2.755274      2.581999e+00       1.889652e+00      5.608468e+00           0.998021       5.037560e-01           2.322657           2.528423           4.950884       1.108113e+00      1.501856e+00           2.504380           6.561965       5.255149e+00           2.306585           3.848910           3.826168       5.093732e-01         0.0          0.0    406.556498          1951.771719             0.0                   0.0                     0.0                0.0                    0.0          197.824544           84.262332            129.414878                -0.481487                   522.167362   7090.423424   6131.148199   \n",
      "std             0.658790           1.206750           1.581191           1.412589           0.965062           0.716391           1.203238           1.405209          0.932994           0.963338       1.129467e+00       1.092955e+00           2.559706           0.856766       8.571942e-01           0.986332           0.721111           1.506682           1.103817      1.837516e+00       1.382891e+00      1.963084e+00           0.900788       4.543699e-01           1.237326           0.989330           1.867884       8.823155e-01      7.857791e-01           0.693882           1.257182       1.751829e+00           0.910522           1.123061           0.925837       5.921536e-01         0.0          0.0    186.870420          1092.248812             0.0                   0.0                     0.0                0.0                    0.0           42.098668           53.934862             37.745711                 5.084623                   108.430299   4070.266947    967.099452   \n",
      "min             0.092406           0.035823           0.204197           0.389800           0.930947           1.114078           0.302807           0.480837          0.008742           0.560222       1.430512e-07      -1.192093e-07           0.519294           0.000000       2.384186e-08           0.448436           0.865277           0.226453           0.082034     -4.768372e-08       4.768372e-08     -1.907349e-07           0.103416      -5.960465e-09           0.297869           0.985805           0.042060      -1.430512e-07     -1.430512e-07           0.300860           2.192507      -5.722046e-07           0.524536           0.519669           1.024795      -2.980232e-09         0.0          0.0      0.000000           420.000000             0.0                   0.0                     0.0                0.0                    0.0           97.000000            0.000000             50.000000               -10.200000                   248.000000    230.000000   3182.000000   \n",
      "25%             1.366765           1.847467           1.416246           2.015932           1.463399           1.868325           1.426366           1.848651          1.092009           1.531584       1.870265e+00       7.085955e-01           2.800054           1.724072       9.915155e-01           1.600827           1.665384           2.985022           1.904739      1.374174e+00       9.178240e-01      4.067207e+00           0.459281       2.687879e-01           1.455889           1.813106           3.851011       3.747150e-01      9.619623e-01           2.060631           5.673308       3.950123e+00           1.532702           3.081089           3.189215       1.034051e-02         0.0          0.0    248.000000          1087.000000             0.0                   0.0                     0.0                0.0                    0.0          166.000000           40.000000            109.000000                -2.000000                   443.000000   3825.750000   5206.000000   \n",
      "50%             1.774779           2.439348           2.363294           2.847945           1.606271           2.244938           2.075258           2.512853          1.578446           2.233920       2.620764e+00       1.198556e+00           3.677251           2.166882       1.422052e+00           2.190168           2.030777           3.765626           2.596174      2.136026e+00       1.377830e+00      5.329531e+00           0.672981       3.911455e-01           1.853972           2.094728           4.630023       1.009905e+00      1.387929e+00           2.473274           6.509245       5.252019e+00           2.083751           3.902415           3.735010       3.078863e-01         0.0          0.0    339.000000          1643.000000             0.0                   0.0                     0.0                0.0                    0.0          199.000000           71.000000            117.000000                 0.000000                   541.500000   6394.000000   6470.000000   \n",
      "75%             2.330174           3.299323           3.647673           3.954103           2.421060           2.796731           3.105172           3.603674          2.447649           3.056704       3.338524e+00       1.948196e+00           5.403150           2.775839       2.222895e+00           2.959257           2.598284           4.713784           3.447564      3.253609e+00       2.525415e+00      7.118515e+00           1.114335       5.253567e-01           2.841559           3.121076           5.718204       1.731261e+00      1.972326e+00           2.899246           7.370386       6.477822e+00           3.090322           4.676681           4.352696       7.671019e-01         0.0          0.0    500.000000          2612.250000             0.0                   0.0                     0.0                0.0                    0.0          228.000000          118.000000            151.000000                 0.000000                   606.000000   9766.000000   6979.000000   \n",
      "max             4.292424           9.071002           8.903175           8.937109           8.299777           5.431123           7.718726           9.267033          6.522239           6.503942       7.043380e+00       7.540772e+00          15.620208           7.392799       6.813485e+00           6.996884           5.639403          16.023735           7.899948      1.191945e+01       8.143102e+00      1.232651e+01           6.648502       4.145511e+00           7.476842           6.823880          13.377789       7.241610e+00      4.769161e+00           6.410732          11.299067       1.041230e+01           5.309681           6.897284           7.968153       3.296067e+00         0.0          0.0    878.000000          4886.000000             0.0                   0.0                     0.0                0.0                    0.0          321.000000          230.000000            216.000000               156.000000                   754.000000  18649.500000   7119.000000   \n",
      "\n",
      "         Carbon_gen  Ciclo_combinado_gen  Hidraulica_gen  Intercambios_int_gen  Solar_fotovoltaica_gen  Solar_termica_gen  Termica_renovable_gen  Motores_diesel_gen  Turbina_de_gas_gen  Turbina_de_vapor_gen  Generacion_auxiliar_gen  Cogeneracion_y_residuos_gen          Real      Prevista    Programada      Asturias     Cantabria       Navarra    País Vasco      Cataluña        Aragón       Galicia  Islas Baleares      La Rioja      Valencia  Castilla y León  Castilla La Mancha   Extremadura     Andalucía        Murcia        Madrid  Solar_altitude    is_weekend  Carbon_emi_1day_before  Carbon_emi_2days_before  Carbon_emi_3days_before  Ciclo_combinado_emi_1day_before  Ciclo_combinado_emi_2days_before  Ciclo_combinado_emi_3days_before  Motores_diesel_emi_1day_before  Motores_diesel_emi_2days_before  Motores_diesel_emi_3days_before  Turbina_de_vapor_emi_1day_before  Turbina_de_vapor_emi_2days_before  Turbina_de_vapor_emi_3days_before  Turbina_de_gas_emi_1day_before  \\\n",
      "count  17544.000000         17544.000000    17544.000000          17544.000000            17544.000000       17544.000000           17544.000000        17544.000000        17544.000000          17544.000000             17544.000000                 17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000    17544.000000  17544.000000  17544.000000     17544.000000        17544.000000  17544.000000  17544.000000  17544.000000  17544.000000    17544.000000  17544.000000            17544.000000             17544.000000             17544.000000                     17544.000000                      17544.000000                      17544.000000                    17544.000000                     17544.000000                     17544.000000                      17544.000000                       17544.000000                       17544.000000                    17544.000000   \n",
      "mean     442.173906          5022.660454     2833.230186          -1608.621751             4404.033915         493.703575             435.113657          290.902189           84.615310            144.657832                -0.711069                  1868.015105  27876.522344  27900.049191  27933.161423      0.547439      0.584148      0.539761      0.619689      0.497620      0.451877      0.556311        0.443983      0.517853      0.425188         0.485263            0.405453      0.392776      0.350409      0.378957      0.407795       15.710192      0.285910              407.001095               407.699453               408.181555                      1954.096673                       1958.210315                       1963.027119                      197.789490                       197.777805                       197.789547                        129.506519                         129.659327                         129.828730                       84.193163   \n",
      "std      244.423468          3056.857537     3010.507817           2155.902834             5678.263321         576.136772              91.264443           61.953186           75.847646             44.425835                 7.476221                   387.460523   4438.707024   4423.429476   4456.988054      0.370360      0.379620      0.382336      0.381871      0.325386      0.347191      0.358586        0.341983      0.395463      0.332800         0.343812            0.348163      0.378472      0.323767      0.369518      0.403726       20.564777      0.451859              187.155101               187.760717               187.795612                      1092.796835                       1096.017364                       1100.148687                       42.082048                        42.068593                        42.075517                         37.721199                          37.717921                          37.676794                       53.868467   \n",
      "min        0.000000           958.000000    -3732.000000          -8088.000000                0.000000           0.000000             188.000000           71.000000           -4.000000              0.000000               -15.000000                    33.000000  17180.000000  17236.000000  17065.000000      0.000000      0.002832      0.000000      0.000000      0.000439      0.000000      0.001197        0.000000      0.000000      0.000000         0.000000            0.000000      0.000000      0.001261      0.000000      0.000000        0.000000      0.000000                0.000000                 0.000000                 0.000000                       420.000000                        420.000000                        420.000000                       97.000000                        97.000000                        97.000000                         50.000000                          50.000000                          50.000000                        0.000000   \n",
      "25%      261.000000          2669.000000      673.750000          -3192.000000               24.000000          15.000000             394.000000          244.000000           41.000000            121.000000                -3.000000                  1586.000000  24149.750000  24204.750000  24191.750000      0.173597      0.186881      0.139870      0.222861      0.191865      0.118682      0.195149        0.125383      0.077836      0.117411         0.148319            0.064437      0.018908      0.057680      0.039104      0.004422        0.000000      0.000000              248.000000               248.000000               249.000000                      1089.000000                       1089.000000                       1090.000000                      166.000000                       166.000000                       166.000000                        109.000000                         109.000000                         109.000000                       40.000000   \n",
      "50%      357.000000          4147.000000     2579.000000          -1516.000000              203.000000         239.000000             442.000000          293.000000           71.000000            130.000000                 0.000000                  1937.000000  27946.500000  27970.500000  28028.000000      0.586003      0.685937      0.587515      0.769590      0.459378      0.394526      0.607348        0.380752      0.557221      0.352902         0.458889            0.329503      0.269328      0.238653      0.231769      0.266267        1.721577      0.000000              339.000000               339.000000               340.000000                      1647.000000                       1649.000000                       1653.000000                      199.000000                       199.000000                       199.000000                        117.000000                         117.000000                         117.000000                       71.000000   \n",
      "75%      526.000000          6748.250000     4885.250000            -13.750000             9150.000000         746.000000             490.000000          336.000000          115.000000            168.000000                 0.000000                  2167.000000  31099.000000  31118.000000  31178.250000      0.932515      0.966022      0.941814      0.982746      0.810274      0.790150      0.916627        0.763804      0.941529      0.726136         0.826517            0.735617      0.777061      0.620561      0.734781      0.861734       28.918652      1.000000              501.000000               501.250000               502.000000                      2616.000000                       2624.000000                       2627.000000                      228.000000                       228.000000                       228.000000                        151.000000                         152.000000                         152.000000                      117.000000   \n",
      "max     4820.000000         17969.000000    11363.500000           5240.000000            20278.000000        1855.000000            5418.000000          475.000000         5512.000000            279.000000               229.000000                  2697.000000  41281.000000  41358.000000  41108.000000      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000        1.000000      1.000000      1.000000         1.000000            1.000000      1.000000      1.000000      1.000000      1.000000       72.814595      1.000000              878.000000               878.000000               878.000000                      4886.000000                       4886.000000                       4886.000000                      321.000000                       321.000000                       321.000000                        216.000000                         216.000000                         216.000000                      230.000000   \n",
      "\n",
      "       Turbina_de_gas_emi_2days_before  Turbina_de_gas_emi_3days_before  Cogeneracion_y_residuos_emi_1day_before  Cogeneracion_y_residuos_emi_2days_before  Cogeneracion_y_residuos_emi_3days_before  \n",
      "count                     17544.000000                     17544.000000                             17544.000000                              17544.000000                              17544.000000  \n",
      "mean                         84.219065                        84.317674                               522.158299                                522.214273                                522.250980  \n",
      "std                          53.887206                        53.910631                               108.428703                                108.348269                                108.287797  \n",
      "min                           0.000000                         0.000000                               248.000000                                248.000000                                248.000000  \n",
      "25%                          40.000000                        40.000000                               443.000000                                443.000000                                443.000000  \n",
      "50%                          71.000000                        71.000000                               541.500000                                541.500000                                541.500000  \n",
      "75%                         117.000000                       118.000000                               606.000000                                606.000000                                606.000000  \n",
      "max                         230.000000                       230.000000                               754.000000                                754.000000                                754.000000  \n",
      "Index(['Ano', 'Mes', 'Dia', 'Hora', 'Minuto', '0016A_Altitud', '0201D_Altitud', '0244X_Altitud', '0367_Altitud', '1025X_Altitud',\n",
      "       ...\n",
      "       'Motores_diesel_emi_3days_before', 'Turbina_de_vapor_emi_1day_before', 'Turbina_de_vapor_emi_2days_before', 'Turbina_de_vapor_emi_3days_before', 'Turbina_de_gas_emi_1day_before', 'Turbina_de_gas_emi_2days_before', 'Turbina_de_gas_emi_3days_before', 'Cogeneracion_y_residuos_emi_1day_before', 'Cogeneracion_y_residuos_emi_2days_before', 'Cogeneracion_y_residuos_emi_3days_before'], dtype='object', length=598)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735058664.084487   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.164607   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.164968   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.167029   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.167358   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.167643   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.306130   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735058664.306557   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 16:44:24.306776: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1735058664.306930   31188 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 16:44:24.307133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ multi_head_attention      │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │      \u001B[32m6,901,865\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],     │\n",
      "│ (\u001B[94mMultiHeadAttention\u001B[0m)      │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],     │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_1 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │              \u001B[32m0\u001B[0m │ multi_head_attention[\u001B[32m…\u001B[0m │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ add (\u001B[94mAdd\u001B[0m)                 │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │              \u001B[32m0\u001B[0m │ dropout_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],       │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ layer_normalization       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │            \u001B[32m830\u001B[0m │ add[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]              │\n",
      "│ (\u001B[94mLayerNormalization\u001B[0m)      │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │        \u001B[32m106,496\u001B[0m │ layer_normalization[\u001B[32m0\u001B[0m… │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_2 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)      │              \u001B[32m0\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │        \u001B[32m106,655\u001B[0m │ dropout_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ add_1 (\u001B[94mAdd\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │              \u001B[32m0\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ layer_normalization_1     │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)      │            \u001B[32m830\u001B[0m │ add_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "│ (\u001B[94mLayerNormalization\u001B[0m)      │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ global_average_pooling1d  │ (\u001B[96mNone\u001B[0m, \u001B[32m415\u001B[0m)            │              \u001B[32m0\u001B[0m │ layer_normalization_1… │\n",
      "│ (\u001B[94mGlobalAveragePooling1D\u001B[0m)  │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)            │        \u001B[32m212,992\u001B[0m │ global_average_poolin… │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_3 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)            │              \u001B[32m0\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)            │        \u001B[32m131,328\u001B[0m │ dropout_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_4 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m256\u001B[0m)            │              \u001B[32m0\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m32\u001B[0m)             │          \u001B[32m8,224\u001B[0m │ dropout_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_5 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m32\u001B[0m)             │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_4 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_5 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_6 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_7 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_8 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[32m6\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_6[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_7[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],         │\n",
      "│                           │                        │                │ dense_8[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m7,469,418\u001B[0m (28.49 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m7,469,418\u001B[0m (28.49 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "x_batch shape: (60, 60, 415)\n",
      "y_batch shape: (60, 6)\n",
      "x_batch shape: (60, 60, 415)\n",
      "y_batch shape: (60, 6)\n",
      "Epoch 1/10\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735058671.508207   31245 service.cc:146] XLA service 0x79e6f8062f00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735058671.508259   31245 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-24 16:44:31.626321: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-24 16:44:32.167931: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1735058681.491749   31245 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "    145/Unknown \u001B[1m23s\u001B[0m 60ms/step - loss: 0.7157 - mae: 0.65412024-12-24 16:44:50.255842: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-24 16:44:50.255914: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:44:50.255943: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:44:50.255974: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-24 16:44:57.375484: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:44:57.375558: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:44:57.375583: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 134ms/step - loss: 0.7142 - mae: 0.6535 - val_loss: 0.6029 - val_mae: 0.5781\n",
      "Epoch 2/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.4901 - mae: 0.56892024-12-24 16:45:21.371554: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:45:21.371623: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:45:24.222505: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:45:24.222583: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:45:24.222609: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 97ms/step - loss: 0.4896 - mae: 0.5685 - val_loss: 0.5967 - val_mae: 0.5799\n",
      "Epoch 3/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.4251 - mae: 0.52632024-12-24 16:45:35.786249: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:45:35.786310: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:45:38.794767: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:45:38.794840: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - loss: 0.4247 - mae: 0.5260 - val_loss: 0.5794 - val_mae: 0.5682\n",
      "Epoch 4/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.3771 - mae: 0.49012024-12-24 16:45:50.191711: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:45:50.191786: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:45:53.268857: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:45:53.268926: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:45:53.268948: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 83ms/step - loss: 0.3767 - mae: 0.4897 - val_loss: 0.5692 - val_mae: 0.5644\n",
      "Epoch 5/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.3329 - mae: 0.45382024-12-24 16:46:02.493687: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:46:02.494870: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:46:06.419055: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 89ms/step - loss: 0.3326 - mae: 0.4535 - val_loss: 0.5779 - val_mae: 0.5615\n",
      "Epoch 6/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - loss: 0.3048 - mae: 0.43162024-12-24 16:46:23.131405: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:46:26.019269: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:46:26.019344: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 98ms/step - loss: 0.3045 - mae: 0.4314 - val_loss: 0.5661 - val_mae: 0.5572\n",
      "Epoch 7/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.2754 - mae: 0.40972024-12-24 16:46:43.407658: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:46:43.407723: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:46:47.511259: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 90ms/step - loss: 0.2751 - mae: 0.4095 - val_loss: 0.5902 - val_mae: 0.5605\n",
      "Epoch 8/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - loss: 0.2604 - mae: 0.39672024-12-24 16:46:56.641983: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:47:00.708494: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-12-24 16:47:00.708580: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:47:00.708606: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 90ms/step - loss: 0.2601 - mae: 0.3964 - val_loss: 0.5452 - val_mae: 0.5562\n",
      "Epoch 9/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step - loss: 0.2445 - mae: 0.38392024-12-24 16:47:17.428779: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:47:17.428841: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:47:20.355986: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:47:20.356041: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 84ms/step - loss: 0.2443 - mae: 0.3837 - val_loss: 0.5674 - val_mae: 0.5575\n",
      "Epoch 10/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.2288 - mae: 0.36962024-12-24 16:47:37.650226: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:47:37.650285: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "2024-12-24 16:47:41.609003: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 14874949328919699991\n",
      "2024-12-24 16:47:41.609063: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 15032149457738531683\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 89ms/step - loss: 0.2286 - mae: 0.3694 - val_loss: 0.5626 - val_mae: 0.5498\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Mean Absolute Percentage Error (MAPE):\n",
      "   Carbon_emi_MAPE  Ciclo_combinado_emi_MAPE  Motores_diesel_emi_MAPE  Turbina_de_vapor_emi_MAPE  Turbina_de_gas_emi_MAPE  Cogeneracion_y_residuos_emi_MAPE\n",
      "0        21.159574                 38.267084                15.169479                  22.879925             8.517872e+06                         21.038418\n",
      "Figure(1200x1000)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python \"${BASE_PATH_TFM}/energy_demand_predictor.py\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuzOh9sO16d5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735057009586,
     "user_tz": -60,
     "elapsed": 233637,
     "user": {
      "displayName": "Jose Manuel Rodriguez",
      "userId": "10373499148329024141"
     }
    },
    "outputId": "edd986b7-2d9a-4726-fc55-463d9d12a231"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2024-12-24 16:12:58.523822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-24 16:12:58.555355: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-24 16:12:58.565095: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-24 16:12:58.586583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-24 16:13:00.054309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "    Ano  Mes  Dia  Hora  Minuto  0016A_Altitud  0201D_Altitud  0244X_Altitud  0367_Altitud  1025X_Altitud  1056K_Altitud  1074C_Altitud  1111X_Altitud  1186P_Altitud  1279X_Altitud  1387E_Altitud  1390X_Altitud  1466A_Altitud  1475X_Altitud  1719_Altitud  2044B_Altitud  2048A_Altitud  2331_Altitud  2734D_Altitud  2777K_Altitud  2873X_Altitud  2891A_Altitud  2946X_Altitud  3104Y_Altitud  3140Y_Altitud  3266A_Altitud  3475X_Altitud  3504X_Altitud  3526X_Altitud  3562X_Altitud  4096Y_Altitud  4340_Altitud  5390Y_Altitud  5402_Altitud  5582A_Altitud  5598X_Altitud  5612X_Altitud  5906X_Altitud  5972X_Altitud  6045X_Altitud  6172X_Altitud  6268Y_Altitud  6307X_Altitud  6312E_Altitud  7066Y_Altitud  7195X_Altitud  7275C_Altitud  8025_Altitud  8036Y_Altitud  8177A_Altitud  8270X_Altitud  8486X_Altitud  8500A_Altitud  9016X_Altitud  9257X_Altitud  9301X_Altitud  9352A_Altitud  9377Y_Altitud  9434_Altitud  9573X_Altitud  9677_Altitud  9814X_Altitud  9843A_Altitud  9946X_Altitud  \\\n",
      "0  2022    9   18     0       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "1  2022    9   18     1       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "2  2022    9   18     2       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "3  2022    9   18     3       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "4  2022    9   18     4       0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0          825.0          495.0   \n",
      "\n",
      "   B275E_Altitud  B569X_Altitud  B760X_Altitud  B925_Altitud  C148F_Altitud  C249I_Altitud  C619Y_Altitud  C639M_Altitud  C649R_Altitud  C659H_Altitud  C659M_Altitud  0016A_Humedad_relativa  0201D_Humedad_relativa  0244X_Humedad_relativa  0367_Humedad_relativa  1025X_Humedad_relativa  1056K_Humedad_relativa  1074C_Humedad_relativa  1111X_Humedad_relativa  1186P_Humedad_relativa  1279X_Humedad_relativa  1387E_Humedad_relativa  1390X_Humedad_relativa  1466A_Humedad_relativa  1475X_Humedad_relativa  1719_Humedad_relativa  2044B_Humedad_relativa  2048A_Humedad_relativa  2331_Humedad_relativa  2734D_Humedad_relativa  2777K_Humedad_relativa  2873X_Humedad_relativa  2891A_Humedad_relativa  2946X_Humedad_relativa  3104Y_Humedad_relativa  3140Y_Humedad_relativa  3266A_Humedad_relativa  3475X_Humedad_relativa  3504X_Humedad_relativa  3526X_Humedad_relativa  3562X_Humedad_relativa  4096Y_Humedad_relativa  4340_Humedad_relativa  5390Y_Humedad_relativa  5402_Humedad_relativa  \\\n",
      "0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "1           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "2           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "3           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "4           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0                    72.5                    88.0                    59.5                   60.0                    67.5                    74.0                    74.0                    67.5                    76.0                    77.0                    69.5                    81.0                    60.5                    65.0                   63.5                    56.5                    60.0                   57.5                    47.5                    58.5                    60.0                    50.0                    51.5                    70.5                    55.5                    69.5                    52.5                    54.5                    48.0                    54.0                    73.0                   49.5                    48.5                   50.5   \n",
      "\n",
      "   5582A_Humedad_relativa  5598X_Humedad_relativa  5612X_Humedad_relativa  5906X_Humedad_relativa  5972X_Humedad_relativa  6045X_Humedad_relativa  6172X_Humedad_relativa  6268Y_Humedad_relativa  6307X_Humedad_relativa  6312E_Humedad_relativa  7066Y_Humedad_relativa  7195X_Humedad_relativa  7275C_Humedad_relativa  8025_Humedad_relativa  8036Y_Humedad_relativa  8177A_Humedad_relativa  8270X_Humedad_relativa  8486X_Humedad_relativa  8500A_Humedad_relativa  9016X_Humedad_relativa  9257X_Humedad_relativa  9301X_Humedad_relativa  9352A_Humedad_relativa  9377Y_Humedad_relativa  9434_Humedad_relativa  9573X_Humedad_relativa  9677_Humedad_relativa  9814X_Humedad_relativa  9843A_Humedad_relativa  9946X_Humedad_relativa  B275E_Humedad_relativa  B569X_Humedad_relativa  B760X_Humedad_relativa  B925_Humedad_relativa  C148F_Humedad_relativa  C249I_Humedad_relativa  C619Y_Humedad_relativa  C639M_Humedad_relativa  C649R_Humedad_relativa  C659H_Humedad_relativa  C659M_Humedad_relativa  \\\n",
      "0                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "1                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "2                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "3                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "4                    45.5                    57.5                    59.0                    72.5                    61.5                    68.0               69.166667                    74.0                    74.5                    56.5                    73.0                    80.5                    75.0                   73.0                    77.5                    66.5                    78.5                    89.5                    80.5                    62.5                    62.5                    59.5                    60.5                    69.5                   58.0                    64.5                   53.0                    64.0                    68.5                    73.5                    55.0                    53.0                    72.5                   67.0                    74.0                    67.5                    65.0                    77.0                    72.5                    74.5                    76.5   \n",
      "\n",
      "   0016A_Precipitacion  0201D_Precipitacion  0244X_Precipitacion  0367_Precipitacion  1025X_Precipitacion  1056K_Precipitacion  1074C_Precipitacion  1111X_Precipitacion  1186P_Precipitacion  1279X_Precipitacion  1387E_Precipitacion  1390X_Precipitacion  1466A_Precipitacion  1475X_Precipitacion  1719_Precipitacion  2044B_Precipitacion  2048A_Precipitacion  2331_Precipitacion  2734D_Precipitacion  2777K_Precipitacion  2873X_Precipitacion  2891A_Precipitacion  2946X_Precipitacion  3104Y_Precipitacion  3140Y_Precipitacion  3266A_Precipitacion  3475X_Precipitacion  3504X_Precipitacion  3526X_Precipitacion  3562X_Precipitacion  4096Y_Precipitacion  4340_Precipitacion  5390Y_Precipitacion  5402_Precipitacion  5582A_Precipitacion  5598X_Precipitacion  5612X_Precipitacion  5906X_Precipitacion  5972X_Precipitacion  6045X_Precipitacion  6172X_Precipitacion  6268Y_Precipitacion  6307X_Precipitacion  6312E_Precipitacion  7066Y_Precipitacion  7195X_Precipitacion  7275C_Precipitacion  \\\n",
      "0                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "1                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "2                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "3                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "4                21.85                 18.2                21.85               20.25                 17.5                 15.9                 16.0                 18.4                 16.8                17.05                21.25                18.85                23.85                 22.1                21.9                17.75                 19.3               17.45                 18.3                 18.1                18.85                21.65                21.55                16.55                 20.0                16.65                 26.1                23.55                25.55                 24.8                 21.7                26.4                 24.6                26.8                25.95                 25.6                24.95                 25.6                27.05                21.65            24.132609                23.15                18.35                27.25                22.95                 18.5                 21.9   \n",
      "\n",
      "   8025_Precipitacion  8036Y_Precipitacion  8177A_Precipitacion  8270X_Precipitacion  8486X_Precipitacion  8500A_Precipitacion  9016X_Precipitacion  9257X_Precipitacion  9301X_Precipitacion  9352A_Precipitacion  9377Y_Precipitacion  9434_Precipitacion  9573X_Precipitacion  9677_Precipitacion  9814X_Precipitacion  9843A_Precipitacion  9946X_Precipitacion  B275E_Precipitacion  B569X_Precipitacion  B760X_Precipitacion  B925_Precipitacion  C148F_Precipitacion  C249I_Precipitacion  C619Y_Precipitacion  C639M_Precipitacion  C649R_Precipitacion  C659H_Precipitacion  C659M_Precipitacion  0016A_Presion  0201D_Presion  0244X_Presion  0367_Presion  1025X_Presion  1056K_Presion  1074C_Presion  1111X_Presion  1186P_Presion  1279X_Presion  1387E_Presion  1390X_Presion  1466A_Presion  1475X_Presion  1719_Presion  2044B_Presion  2048A_Presion  2331_Presion  2734D_Presion  2777K_Presion  2873X_Presion  2891A_Presion  2946X_Presion  3104Y_Presion  3140Y_Presion  3266A_Presion  3475X_Presion  \\\n",
      "0               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "1               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "2               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "3               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "4               25.05                24.05                 20.2                21.05                 14.5                22.45                16.45                 17.0                17.65                17.95                 17.7                21.1                 22.1                 9.0                 17.8                 17.4                 21.6                 23.0                24.05                 21.1                24.1                22.05                 26.5                26.75                 25.2                24.75                 25.6                 24.9         1007.9        968.475     969.483333       1001.05         997.99    1004.233333    1004.233333         1010.6      982.66875      982.66875        1001.95     997.442857         996.75     997.442857        996.75         894.85         894.85         915.3          923.8        923.475         903.84         903.84         936.05        910.825        914.475         849.25       970.8625   \n",
      "\n",
      "   3504X_Presion  3526X_Presion  3562X_Presion  4096Y_Presion  4340_Presion  5390Y_Presion  5402_Presion  5582A_Presion  5598X_Presion  5612X_Presion  5906X_Presion  5972X_Presion  6045X_Presion  6172X_Presion  6268Y_Presion  6307X_Presion  6312E_Presion  7066Y_Presion  7195X_Presion  7275C_Presion  8025_Presion  8036Y_Presion  8177A_Presion  8270X_Presion  8486X_Presion  8500A_Presion  9016X_Presion  9257X_Presion  9301X_Presion  9352A_Presion  9377Y_Presion  9434_Presion  9573X_Presion  9677_Presion  9814X_Presion  9843A_Presion  9946X_Presion  B275E_Presion  B569X_Presion  B760X_Presion  B925_Presion  C148F_Presion  C249I_Presion  C619Y_Presion  C639M_Presion  C649R_Presion  C659H_Presion  C659M_Presion  0016A_Temperatura  0201D_Temperatura  0244X_Temperatura  0367_Temperatura  1025X_Temperatura  1056K_Temperatura  1074C_Temperatura  1111X_Temperatura  1186P_Temperatura  1279X_Temperatura  1387E_Temperatura  1390X_Temperatura  1466A_Temperatura  1475X_Temperatura  \\\n",
      "0       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "1       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "2       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "3       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "4       970.8625          975.7       970.8625        934.575    967.166666         928.25        999.65        918.475     959.066666       991.7625     990.728572        1006.55        1002.85        1002.85        918.475     985.641667         946.95        934.575      989.88125          943.0        1004.9    1009.666666         916.15     981.116666     930.983333        1010.85     974.907143        972.475        972.475         894.85        914.475         986.0     930.983333         977.0     919.766667     919.766667       1008.625        1010.15        1008.85    1011.230769        1011.4        960.975         1008.4        1011.15    1009.571429    1009.571429    1009.571429        1009.95              21.85               18.2              21.85             20.25               17.5               15.9               16.0               18.4               16.8              17.05              21.25              18.85              23.85               22.1   \n",
      "\n",
      "   1719_Temperatura  2044B_Temperatura  2048A_Temperatura  2331_Temperatura  2734D_Temperatura  2777K_Temperatura  2873X_Temperatura  2891A_Temperatura  2946X_Temperatura  3104Y_Temperatura  3140Y_Temperatura  3266A_Temperatura  3475X_Temperatura  3504X_Temperatura  3526X_Temperatura  3562X_Temperatura  4096Y_Temperatura  4340_Temperatura  5390Y_Temperatura  5402_Temperatura  5582A_Temperatura  5598X_Temperatura  5612X_Temperatura  5906X_Temperatura  5972X_Temperatura  6045X_Temperatura  6172X_Temperatura  6268Y_Temperatura  6307X_Temperatura  6312E_Temperatura  7066Y_Temperatura  7195X_Temperatura  7275C_Temperatura  8025_Temperatura  8036Y_Temperatura  8177A_Temperatura  8270X_Temperatura  8486X_Temperatura  8500A_Temperatura  9016X_Temperatura  9257X_Temperatura  9301X_Temperatura  9352A_Temperatura  9377Y_Temperatura  9434_Temperatura  9573X_Temperatura  9677_Temperatura  9814X_Temperatura  9843A_Temperatura  9946X_Temperatura  B275E_Temperatura  B569X_Temperatura  \\\n",
      "0              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "1              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "2              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "3              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "4              21.9              17.75               19.3             17.45               18.3               18.1              18.85              21.65              21.55              16.55               20.0              16.65               26.1              23.55              25.55               24.8               21.7              26.4               24.6              26.8              25.95               25.6              24.95               25.6              27.05              21.65          24.132609              23.15              18.35              27.25              22.95               18.5               21.9             25.05              24.05               20.2              21.05               14.5              22.45              16.45               17.0              17.65              17.95               17.7              21.1               22.1               9.0               17.8               17.4               21.6               23.0              24.05   \n",
      "\n",
      "   B760X_Temperatura  B925_Temperatura  C148F_Temperatura  C249I_Temperatura  C619Y_Temperatura  C639M_Temperatura  C649R_Temperatura  C659H_Temperatura  C659M_Temperatura  0016A_Viento  0201D_Viento  0244X_Viento  0367_Viento  1025X_Viento  1056K_Viento  1074C_Viento  1111X_Viento  1186P_Viento  1279X_Viento  1387E_Viento  1390X_Viento  1466A_Viento  1475X_Viento  1719_Viento  2044B_Viento  2048A_Viento  2331_Viento  2734D_Viento  2777K_Viento  2873X_Viento  2891A_Viento  2946X_Viento  3104Y_Viento  3140Y_Viento  3266A_Viento  3475X_Viento  3504X_Viento  3526X_Viento  3562X_Viento  4096Y_Viento  4340_Viento  5390Y_Viento  5402_Viento  5582A_Viento  5598X_Viento  5612X_Viento  5906X_Viento  5972X_Viento  6045X_Viento  6172X_Viento  6268Y_Viento  6307X_Viento  6312E_Viento  7066Y_Viento  7195X_Viento  7275C_Viento  8025_Viento  8036Y_Viento  8177A_Viento  8270X_Viento  8486X_Viento  8500A_Viento  9016X_Viento  9257X_Viento  9301X_Viento  9352A_Viento  9377Y_Viento  9434_Viento  \\\n",
      "0               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "1               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "2               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "3               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "4               21.1              24.1              22.05               26.5              26.75               25.2              24.75               25.6               24.9           2.2           2.2           1.1          2.2           1.4           2.5           1.1           7.5           0.8           1.7           1.9      3.481818           2.8           1.1     1.911111           1.9           1.9          3.3           1.4           0.8           1.7           2.8           1.4           0.3           1.4           3.6           5.0           1.9           4.2           1.4           1.9          1.4           1.7          3.9           2.2           3.9      2.866667           5.3           5.6           3.9      3.126316           1.9           3.6           3.6      3.285714         4.435           3.6          4.4           4.4           5.6           1.7           3.3           1.1           0.8      1.452941      1.452941           3.1           1.9          1.7   \n",
      "\n",
      "   9573X_Viento  9677_Viento  9814X_Viento  9843A_Viento  9946X_Viento  B275E_Viento  B569X_Viento  B760X_Viento  B925_Viento  C148F_Viento  C249I_Viento  C619Y_Viento  C639M_Viento  C649R_Viento  C659H_Viento  C659M_Viento  0016A_Viento_pred  0201D_Viento_pred  0244X_Viento_pred  0367_Viento_pred  1025X_Viento_pred  1056K_Viento_pred  1074C_Viento_pred  1111X_Viento_pred  1186P_Viento_pred  1279X_Viento_pred  1387E_Viento_pred  1390X_Viento_pred  1466A_Viento_pred  1475X_Viento_pred  1719_Viento_pred  2044B_Viento_pred  2048A_Viento_pred  2331_Viento_pred  2734D_Viento_pred  2777K_Viento_pred  2873X_Viento_pred  2891A_Viento_pred  2946X_Viento_pred  3104Y_Viento_pred  3140Y_Viento_pred  3266A_Viento_pred  3475X_Viento_pred  3504X_Viento_pred  3526X_Viento_pred  3562X_Viento_pred  4096Y_Viento_pred  4340_Viento_pred  5390Y_Viento_pred  5402_Viento_pred  5582A_Viento_pred  5598X_Viento_pred  5612X_Viento_pred  5906X_Viento_pred  5972X_Viento_pred  6045X_Viento_pred  6172X_Viento_pred  \\\n",
      "0           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           1.943829          1.479449           1.717177           0.506113           1.437103           0.699526           3.077921           0.797038           1.062248           3.079559           3.527321           1.770954          1.337379           1.186921           2.935063          1.764040           2.938147           1.502103           0.730523           1.471103           3.309237           3.144737           0.259190           0.981486           4.000695           3.736689           1.493466           1.996737           1.195477          1.024277           2.434672          1.944605           2.109376           1.610348           1.629929           1.736365           3.704096           2.812637           1.707109   \n",
      "1           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.025627          1.457594           1.667195           0.492925           1.464666           0.664485           3.110943           0.811082           1.106938           3.229418           3.642670           1.949584          1.315120           1.224410           2.888891          1.706343           2.938147           1.464919           0.729428           1.427311           3.227292           3.150652           0.264778           0.989055           3.962834           3.664406           1.347394           2.030380           1.172130          1.019138           2.420578          1.943563           2.091232           1.623601           1.689690           1.710809           3.710280           2.743318           1.758798   \n",
      "2           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.107308          1.434844           1.613085           0.485157           1.472447           0.618887           3.161249           0.799005           1.142866           3.380415           3.731186           2.081025          1.288763           1.264261           2.847514          1.644860           2.938147           1.396322           0.749744           1.403989           3.169053           3.222362           0.267762           0.999338           3.968915           3.658546           1.350777           2.057055           1.172484          1.027750           2.358795          1.932282           2.047971           1.625315           1.725357           1.686483           3.724195           2.714513           1.833021   \n",
      "3           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.025588          1.457296           1.665819           0.494732           1.458072           0.660966           3.116704           0.802375           1.104017           3.229798           3.633726           1.933855          1.313754           1.225197           2.890489          1.705081           2.938147           1.454448           0.736565           1.434134           3.235194           3.172584           0.263910           0.989960           3.977481           3.686547           1.397212           2.028057           1.180030          1.023721           2.404682          1.940150           2.082860           1.619754           1.681658           1.711219           3.712857           2.756823           1.766309   \n",
      "4           1.9          2.8           1.1           1.4      2.657143           3.3           6.7           1.4          2.8           3.9           5.3           3.6           2.2           2.2           3.6           2.5           2.644345           2.737892           2.066467          1.446219           1.640140           0.489041           1.468556           0.641686           3.136096           0.805043           1.124902           3.304917           3.686928           2.015305          1.301941           1.244335           2.868203          1.675602           2.938147           1.430620           0.739586           1.415650           3.198173           3.186507           0.266270           0.994196           3.965875           3.661476           1.349085           2.043717           1.172307          1.023444           2.389687          1.937923           2.069601           1.624458           1.707523           1.698646           3.717237           2.728915           1.795909   \n",
      "\n",
      "   6268Y_Viento_pred  6307X_Viento_pred  6312E_Viento_pred  7066Y_Viento_pred  7195X_Viento_pred  7275C_Viento_pred  8025_Viento_pred  8036Y_Viento_pred  8177A_Viento_pred  8270X_Viento_pred  8486X_Viento_pred  8500A_Viento_pred  9016X_Viento_pred  9257X_Viento_pred  9301X_Viento_pred  9352A_Viento_pred  9377Y_Viento_pred  9434_Viento_pred  9573X_Viento_pred  9677_Viento_pred  9814X_Viento_pred  9843A_Viento_pred  9946X_Viento_pred  B275E_Viento_pred  B569X_Viento_pred  B760X_Viento_pred  B925_Viento_pred  C148F_Viento_pred  C249I_Viento_pred  C619Y_Viento_pred  C639M_Viento_pred  C649R_Viento_pred  C659H_Viento_pred  C659M_Viento_pred  Eolica_emi  Nuclear_emi  Carbon_emi  Ciclo_combinado_emi  Hidraulica_emi  Intercambios_int_emi  Solar_fotovoltaica_emi  Solar_termica_emi  Termica_renovable_emi  Motores_diesel_emi  Turbina_de_gas_emi  Turbina_de_vapor_emi  Generacion_auxiliar_emi  Cogeneracion_y_residuos_emi  Eolica_gen  Nuclear_gen  Carbon_gen  Ciclo_combinado_gen  Hidraulica_gen  \\\n",
      "0           2.288238           1.668124           1.463399           1.543373           1.609731           1.681400          1.123778           1.092416           1.326636           1.744443           0.665541           2.803017           2.650606           1.352547           1.823641           1.945526           3.260815          1.681861           3.027253          1.064673           6.580015           0.725655           0.297869           1.420418           1.862333           6.593983      9.762467e-02           0.437168           2.352216           4.554829           3.253805           1.457402           2.993989           3.296067           0            0       838.0               3559.0               0                     0                       0                  0                      0               220.0                38.0                 201.0                     0.68                        332.0      7998.0         6919         882                 9275          1927.0   \n",
      "1           2.149992           1.555193           1.463399           1.490385           1.627858           1.668701          1.062609           1.090597           1.331954           1.874320           0.591695           2.808985           2.783953           1.333456           1.842270           1.968959           3.128641          1.678815           2.942154          1.082016           6.583877           0.634895           0.297869           1.496873           1.890221           6.922064      4.126525e-03           0.365818           2.262426           4.531088           3.111320           1.455245           2.964689           3.282041           0            0       720.0               2858.0               0                     0                       0                  0                      0               194.0                43.0                 185.0                     1.40                        331.0      7488.0         6937         758                 7389          2040.0   \n",
      "2           2.008414           1.488367           1.463399           1.447117           1.645798           1.657706          0.999261           1.097296           1.339877           1.978168           0.519294           2.841664           2.904712           1.301297           1.900480           1.991143           3.010926          1.683544           2.827603          1.100459           6.648502           0.582916           0.297869           1.558116           1.909944           7.241610     -1.430512e-07           0.300860           2.192507           4.476672           3.063415           1.471645           2.924891           3.265723           0            0       672.0               3027.0               0                     0                       0                  0                      0               150.0                42.0                 124.0                     0.00                        331.0      6948.0         6939         707                 7809          1525.0   \n",
      "3           2.148881           1.570561           1.463399           1.493625           1.627796           1.669269          1.061883           1.093437           1.332822           1.865644           0.592177           2.817889           2.779757           1.329100           1.855464           1.968543           3.133461          1.681406           2.932337          1.082383           6.604131           0.647822           0.297869           1.491802           1.887499           6.919219      3.391702e-02           0.367949           2.269049           4.520863           3.142847           1.461431           2.961189           3.281277           0            0       674.0               2866.0               0                     0                       0                  0                      0               151.0                43.0                 114.0                     0.00                        333.0      6405.0         6939         709                 7391          1638.0   \n",
      "4           2.079203           1.521780           1.463399           1.468751           1.636828           1.663203          1.030935           1.093947           1.335915           1.926244           0.555495           2.825325           2.844333           1.317377           1.871375           1.980051           3.069784          1.681179           2.884878          1.091238           6.616189           0.608906           0.297869           1.527494           1.900083           7.081837      2.063191e-03           0.333339           2.227466           4.503880           3.087368           1.463445           2.944790           3.273882           0            0       674.0               2858.0               0                     0                       0                  0                      0               150.0                43.0                 114.0                     0.00                        333.0      5926.0         6938         709                 7387          1780.0   \n",
      "\n",
      "   Intercambios_int_gen  Solar_fotovoltaica_gen  Solar_termica_gen  Termica_renovable_gen  Motores_diesel_gen  Turbina_de_gas_gen  Turbina_de_vapor_gen  Generacion_auxiliar_gen  Cogeneracion_y_residuos_gen     Real  Prevista  Programada                                file  Asturias  Cantabria   Navarra  País Vasco  Cataluña    Aragón   Galicia  Islas Baleares  La Rioja  Valencia  Castilla y León  Castilla La Mancha  Extremadura  Andalucía    Murcia    Madrid  Solar_altitude  is_weekend  Real_1day_before  Real_2days_before  Real_3days_before  \n",
      "0                 -4994                    34.0              376.0                    458                 323                  39                   223                        1                         1191  24602.0   24581.0     24568.0  image_2022-09-18T00-00-00.000Z.png  1.000000   1.000000  1.000000    1.000000  0.882925  0.829349  0.822483        0.789877  0.657171  0.622616         0.400481            0.171011     0.121783   0.100546  0.052420  0.001263             0.0           1           24602.0            24602.0            24602.0  \n",
      "1                 -4272                    33.0              339.0                    506                 286                  44                   205                        2                         1190  22860.0   23275.0     22934.0  image_2022-09-18T01-00-00.000Z.png  1.000000   0.987258  0.999529    0.925593  0.876782  0.704849  0.716930        0.855061  0.431284  0.579425         0.380731            0.171980     0.112889   0.092299  0.135067  0.219204             0.0           1           22860.0            22860.0            22860.0  \n",
      "2                 -4183                    17.0              234.0                    520                 220                  43                   138                        0                         1189  22023.0   22126.0     21911.0  image_2022-09-18T02-00-00.000Z.png  1.000000   0.954224  0.964664    0.811646  0.904278  0.623915  0.674565        0.957055  0.130935  0.628286         0.314095            0.179288     0.113952   0.090697  0.318326  0.680354             0.0           1           22023.0            22023.0            22023.0  \n",
      "3                 -3933                    16.0              151.0                    512                 222                  44                   127                        0                         1195  21324.0   21277.0     21384.0  image_2022-09-18T03-00-00.000Z.png  0.964781   0.693723  0.841932    0.854781  0.928629  0.563372  0.551460        0.837040  0.288856  0.720544         0.202483            0.222614     0.150145   0.127495  0.381526  0.551169             0.0           1           21324.0            21324.0            21324.0  \n",
      "4                 -3959                    16.0               24.0                    518                 220                  44                   127                        0                         1195  20834.0   20803.0     20853.0  image_2022-09-18T04-00-00.000Z.png  0.453761   0.220387  0.733569    0.924515  0.938867  0.536491  0.395724        0.849310  0.033483  0.718586         0.107176            0.187683     0.190255   0.103147  0.363560  0.110865             0.0           1           20834.0            20834.0            20834.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17544 entries, 0 to 17543\n",
      "Data columns (total 583 columns):\n",
      " #    Column                       Non-Null Count  Dtype  \n",
      "---   ------                       --------------  -----  \n",
      " 0    Ano                          17544 non-null  int64  \n",
      " 1    Mes                          17544 non-null  int64  \n",
      " 2    Dia                          17544 non-null  int64  \n",
      " 3    Hora                         17544 non-null  int64  \n",
      " 4    Minuto                       17544 non-null  int64  \n",
      " 5    0016A_Altitud                17544 non-null  float64\n",
      " 6    0201D_Altitud                17544 non-null  float64\n",
      " 7    0244X_Altitud                17544 non-null  float64\n",
      " 8    0367_Altitud                 17544 non-null  float64\n",
      " 9    1025X_Altitud                17544 non-null  float64\n",
      " 10   1056K_Altitud                17544 non-null  float64\n",
      " 11   1074C_Altitud                17544 non-null  float64\n",
      " 12   1111X_Altitud                17544 non-null  float64\n",
      " 13   1186P_Altitud                17544 non-null  float64\n",
      " 14   1279X_Altitud                17544 non-null  float64\n",
      " 15   1387E_Altitud                17544 non-null  float64\n",
      " 16   1390X_Altitud                17544 non-null  float64\n",
      " 17   1466A_Altitud                17544 non-null  float64\n",
      " 18   1475X_Altitud                17544 non-null  float64\n",
      " 19   1719_Altitud                 17544 non-null  float64\n",
      " 20   2044B_Altitud                17544 non-null  float64\n",
      " 21   2048A_Altitud                17544 non-null  float64\n",
      " 22   2331_Altitud                 17544 non-null  float64\n",
      " 23   2734D_Altitud                17544 non-null  float64\n",
      " 24   2777K_Altitud                17544 non-null  float64\n",
      " 25   2873X_Altitud                17544 non-null  float64\n",
      " 26   2891A_Altitud                17544 non-null  float64\n",
      " 27   2946X_Altitud                17544 non-null  float64\n",
      " 28   3104Y_Altitud                17544 non-null  float64\n",
      " 29   3140Y_Altitud                17544 non-null  float64\n",
      " 30   3266A_Altitud                17544 non-null  float64\n",
      " 31   3475X_Altitud                17544 non-null  float64\n",
      " 32   3504X_Altitud                17544 non-null  float64\n",
      " 33   3526X_Altitud                17544 non-null  float64\n",
      " 34   3562X_Altitud                17544 non-null  float64\n",
      " 35   4096Y_Altitud                17544 non-null  float64\n",
      " 36   4340_Altitud                 17544 non-null  float64\n",
      " 37   5390Y_Altitud                17544 non-null  float64\n",
      " 38   5402_Altitud                 17544 non-null  float64\n",
      " 39   5582A_Altitud                17544 non-null  float64\n",
      " 40   5598X_Altitud                17544 non-null  float64\n",
      " 41   5612X_Altitud                17544 non-null  float64\n",
      " 42   5906X_Altitud                17544 non-null  float64\n",
      " 43   5972X_Altitud                17544 non-null  float64\n",
      " 44   6045X_Altitud                17544 non-null  float64\n",
      " 45   6172X_Altitud                17544 non-null  float64\n",
      " 46   6268Y_Altitud                17544 non-null  float64\n",
      " 47   6307X_Altitud                17544 non-null  float64\n",
      " 48   6312E_Altitud                17544 non-null  float64\n",
      " 49   7066Y_Altitud                17544 non-null  float64\n",
      " 50   7195X_Altitud                17544 non-null  float64\n",
      " 51   7275C_Altitud                17544 non-null  float64\n",
      " 52   8025_Altitud                 17544 non-null  float64\n",
      " 53   8036Y_Altitud                17544 non-null  float64\n",
      " 54   8177A_Altitud                17544 non-null  float64\n",
      " 55   8270X_Altitud                17544 non-null  float64\n",
      " 56   8486X_Altitud                17544 non-null  float64\n",
      " 57   8500A_Altitud                17544 non-null  float64\n",
      " 58   9016X_Altitud                17544 non-null  float64\n",
      " 59   9257X_Altitud                17544 non-null  float64\n",
      " 60   9301X_Altitud                17544 non-null  float64\n",
      " 61   9352A_Altitud                17544 non-null  float64\n",
      " 62   9377Y_Altitud                17544 non-null  float64\n",
      " 63   9434_Altitud                 17544 non-null  float64\n",
      " 64   9573X_Altitud                17544 non-null  float64\n",
      " 65   9677_Altitud                 17544 non-null  float64\n",
      " 66   9814X_Altitud                17544 non-null  float64\n",
      " 67   9843A_Altitud                17544 non-null  float64\n",
      " 68   9946X_Altitud                17544 non-null  float64\n",
      " 69   B275E_Altitud                17544 non-null  float64\n",
      " 70   B569X_Altitud                17544 non-null  float64\n",
      " 71   B760X_Altitud                17544 non-null  float64\n",
      " 72   B925_Altitud                 17544 non-null  float64\n",
      " 73   C148F_Altitud                17544 non-null  float64\n",
      " 74   C249I_Altitud                17544 non-null  float64\n",
      " 75   C619Y_Altitud                17544 non-null  float64\n",
      " 76   C639M_Altitud                17544 non-null  float64\n",
      " 77   C649R_Altitud                17544 non-null  float64\n",
      " 78   C659H_Altitud                17544 non-null  float64\n",
      " 79   C659M_Altitud                17544 non-null  float64\n",
      " 80   0016A_Humedad_relativa       17544 non-null  float64\n",
      " 81   0201D_Humedad_relativa       17544 non-null  float64\n",
      " 82   0244X_Humedad_relativa       17544 non-null  float64\n",
      " 83   0367_Humedad_relativa        17544 non-null  float64\n",
      " 84   1025X_Humedad_relativa       17544 non-null  float64\n",
      " 85   1056K_Humedad_relativa       17544 non-null  float64\n",
      " 86   1074C_Humedad_relativa       17544 non-null  float64\n",
      " 87   1111X_Humedad_relativa       17544 non-null  float64\n",
      " 88   1186P_Humedad_relativa       17544 non-null  float64\n",
      " 89   1279X_Humedad_relativa       17544 non-null  float64\n",
      " 90   1387E_Humedad_relativa       17544 non-null  float64\n",
      " 91   1390X_Humedad_relativa       17544 non-null  float64\n",
      " 92   1466A_Humedad_relativa       17544 non-null  float64\n",
      " 93   1475X_Humedad_relativa       17544 non-null  float64\n",
      " 94   1719_Humedad_relativa        17544 non-null  float64\n",
      " 95   2044B_Humedad_relativa       17544 non-null  float64\n",
      " 96   2048A_Humedad_relativa       17544 non-null  float64\n",
      " 97   2331_Humedad_relativa        17544 non-null  float64\n",
      " 98   2734D_Humedad_relativa       17544 non-null  float64\n",
      " 99   2777K_Humedad_relativa       17544 non-null  float64\n",
      " 100  2873X_Humedad_relativa       17544 non-null  float64\n",
      " 101  2891A_Humedad_relativa       17544 non-null  float64\n",
      " 102  2946X_Humedad_relativa       17544 non-null  float64\n",
      " 103  3104Y_Humedad_relativa       17544 non-null  float64\n",
      " 104  3140Y_Humedad_relativa       17544 non-null  float64\n",
      " 105  3266A_Humedad_relativa       17544 non-null  float64\n",
      " 106  3475X_Humedad_relativa       17544 non-null  float64\n",
      " 107  3504X_Humedad_relativa       17544 non-null  float64\n",
      " 108  3526X_Humedad_relativa       17544 non-null  float64\n",
      " 109  3562X_Humedad_relativa       17544 non-null  float64\n",
      " 110  4096Y_Humedad_relativa       17544 non-null  float64\n",
      " 111  4340_Humedad_relativa        17544 non-null  float64\n",
      " 112  5390Y_Humedad_relativa       17544 non-null  float64\n",
      " 113  5402_Humedad_relativa        17544 non-null  float64\n",
      " 114  5582A_Humedad_relativa       17544 non-null  float64\n",
      " 115  5598X_Humedad_relativa       17544 non-null  float64\n",
      " 116  5612X_Humedad_relativa       17544 non-null  float64\n",
      " 117  5906X_Humedad_relativa       17544 non-null  float64\n",
      " 118  5972X_Humedad_relativa       17544 non-null  float64\n",
      " 119  6045X_Humedad_relativa       17544 non-null  float64\n",
      " 120  6172X_Humedad_relativa       17544 non-null  float64\n",
      " 121  6268Y_Humedad_relativa       17544 non-null  float64\n",
      " 122  6307X_Humedad_relativa       17544 non-null  float64\n",
      " 123  6312E_Humedad_relativa       17544 non-null  float64\n",
      " 124  7066Y_Humedad_relativa       17544 non-null  float64\n",
      " 125  7195X_Humedad_relativa       17544 non-null  float64\n",
      " 126  7275C_Humedad_relativa       17544 non-null  float64\n",
      " 127  8025_Humedad_relativa        17544 non-null  float64\n",
      " 128  8036Y_Humedad_relativa       17544 non-null  float64\n",
      " 129  8177A_Humedad_relativa       17544 non-null  float64\n",
      " 130  8270X_Humedad_relativa       17544 non-null  float64\n",
      " 131  8486X_Humedad_relativa       17544 non-null  float64\n",
      " 132  8500A_Humedad_relativa       17544 non-null  float64\n",
      " 133  9016X_Humedad_relativa       17544 non-null  float64\n",
      " 134  9257X_Humedad_relativa       17544 non-null  float64\n",
      " 135  9301X_Humedad_relativa       17544 non-null  float64\n",
      " 136  9352A_Humedad_relativa       17544 non-null  float64\n",
      " 137  9377Y_Humedad_relativa       17544 non-null  float64\n",
      " 138  9434_Humedad_relativa        17544 non-null  float64\n",
      " 139  9573X_Humedad_relativa       17544 non-null  float64\n",
      " 140  9677_Humedad_relativa        17544 non-null  float64\n",
      " 141  9814X_Humedad_relativa       17544 non-null  float64\n",
      " 142  9843A_Humedad_relativa       17544 non-null  float64\n",
      " 143  9946X_Humedad_relativa       17544 non-null  float64\n",
      " 144  B275E_Humedad_relativa       17544 non-null  float64\n",
      " 145  B569X_Humedad_relativa       17544 non-null  float64\n",
      " 146  B760X_Humedad_relativa       17544 non-null  float64\n",
      " 147  B925_Humedad_relativa        17544 non-null  float64\n",
      " 148  C148F_Humedad_relativa       17544 non-null  float64\n",
      " 149  C249I_Humedad_relativa       17544 non-null  float64\n",
      " 150  C619Y_Humedad_relativa       17544 non-null  float64\n",
      " 151  C639M_Humedad_relativa       17544 non-null  float64\n",
      " 152  C649R_Humedad_relativa       17544 non-null  float64\n",
      " 153  C659H_Humedad_relativa       17544 non-null  float64\n",
      " 154  C659M_Humedad_relativa       17544 non-null  float64\n",
      " 155  0016A_Precipitacion          17544 non-null  float64\n",
      " 156  0201D_Precipitacion          17544 non-null  float64\n",
      " 157  0244X_Precipitacion          17544 non-null  float64\n",
      " 158  0367_Precipitacion           17544 non-null  float64\n",
      " 159  1025X_Precipitacion          17544 non-null  float64\n",
      " 160  1056K_Precipitacion          17544 non-null  float64\n",
      " 161  1074C_Precipitacion          17544 non-null  float64\n",
      " 162  1111X_Precipitacion          17544 non-null  float64\n",
      " 163  1186P_Precipitacion          17544 non-null  float64\n",
      " 164  1279X_Precipitacion          17544 non-null  float64\n",
      " 165  1387E_Precipitacion          17544 non-null  float64\n",
      " 166  1390X_Precipitacion          17544 non-null  float64\n",
      " 167  1466A_Precipitacion          17544 non-null  float64\n",
      " 168  1475X_Precipitacion          17544 non-null  float64\n",
      " 169  1719_Precipitacion           17544 non-null  float64\n",
      " 170  2044B_Precipitacion          17544 non-null  float64\n",
      " 171  2048A_Precipitacion          17544 non-null  float64\n",
      " 172  2331_Precipitacion           17544 non-null  float64\n",
      " 173  2734D_Precipitacion          17544 non-null  float64\n",
      " 174  2777K_Precipitacion          17544 non-null  float64\n",
      " 175  2873X_Precipitacion          17544 non-null  float64\n",
      " 176  2891A_Precipitacion          17544 non-null  float64\n",
      " 177  2946X_Precipitacion          17544 non-null  float64\n",
      " 178  3104Y_Precipitacion          17544 non-null  float64\n",
      " 179  3140Y_Precipitacion          17544 non-null  float64\n",
      " 180  3266A_Precipitacion          17544 non-null  float64\n",
      " 181  3475X_Precipitacion          17544 non-null  float64\n",
      " 182  3504X_Precipitacion          17544 non-null  float64\n",
      " 183  3526X_Precipitacion          17544 non-null  float64\n",
      " 184  3562X_Precipitacion          17544 non-null  float64\n",
      " 185  4096Y_Precipitacion          17544 non-null  float64\n",
      " 186  4340_Precipitacion           17544 non-null  float64\n",
      " 187  5390Y_Precipitacion          17544 non-null  float64\n",
      " 188  5402_Precipitacion           17544 non-null  float64\n",
      " 189  5582A_Precipitacion          17544 non-null  float64\n",
      " 190  5598X_Precipitacion          17544 non-null  float64\n",
      " 191  5612X_Precipitacion          17544 non-null  float64\n",
      " 192  5906X_Precipitacion          17544 non-null  float64\n",
      " 193  5972X_Precipitacion          17544 non-null  float64\n",
      " 194  6045X_Precipitacion          17544 non-null  float64\n",
      " 195  6172X_Precipitacion          17544 non-null  float64\n",
      " 196  6268Y_Precipitacion          17544 non-null  float64\n",
      " 197  6307X_Precipitacion          17544 non-null  float64\n",
      " 198  6312E_Precipitacion          17544 non-null  float64\n",
      " 199  7066Y_Precipitacion          17544 non-null  float64\n",
      " 200  7195X_Precipitacion          17544 non-null  float64\n",
      " 201  7275C_Precipitacion          17544 non-null  float64\n",
      " 202  8025_Precipitacion           17544 non-null  float64\n",
      " 203  8036Y_Precipitacion          17544 non-null  float64\n",
      " 204  8177A_Precipitacion          17544 non-null  float64\n",
      " 205  8270X_Precipitacion          17544 non-null  float64\n",
      " 206  8486X_Precipitacion          17544 non-null  float64\n",
      " 207  8500A_Precipitacion          17544 non-null  float64\n",
      " 208  9016X_Precipitacion          17544 non-null  float64\n",
      " 209  9257X_Precipitacion          17544 non-null  float64\n",
      " 210  9301X_Precipitacion          17544 non-null  float64\n",
      " 211  9352A_Precipitacion          17544 non-null  float64\n",
      " 212  9377Y_Precipitacion          17544 non-null  float64\n",
      " 213  9434_Precipitacion           17544 non-null  float64\n",
      " 214  9573X_Precipitacion          17544 non-null  float64\n",
      " 215  9677_Precipitacion           17544 non-null  float64\n",
      " 216  9814X_Precipitacion          17544 non-null  float64\n",
      " 217  9843A_Precipitacion          17544 non-null  float64\n",
      " 218  9946X_Precipitacion          17544 non-null  float64\n",
      " 219  B275E_Precipitacion          17544 non-null  float64\n",
      " 220  B569X_Precipitacion          17544 non-null  float64\n",
      " 221  B760X_Precipitacion          17544 non-null  float64\n",
      " 222  B925_Precipitacion           17544 non-null  float64\n",
      " 223  C148F_Precipitacion          17544 non-null  float64\n",
      " 224  C249I_Precipitacion          17544 non-null  float64\n",
      " 225  C619Y_Precipitacion          17544 non-null  float64\n",
      " 226  C639M_Precipitacion          17544 non-null  float64\n",
      " 227  C649R_Precipitacion          17544 non-null  float64\n",
      " 228  C659H_Precipitacion          17544 non-null  float64\n",
      " 229  C659M_Precipitacion          17544 non-null  float64\n",
      " 230  0016A_Presion                17544 non-null  float64\n",
      " 231  0201D_Presion                17544 non-null  float64\n",
      " 232  0244X_Presion                17544 non-null  float64\n",
      " 233  0367_Presion                 17544 non-null  float64\n",
      " 234  1025X_Presion                17544 non-null  float64\n",
      " 235  1056K_Presion                17544 non-null  float64\n",
      " 236  1074C_Presion                17544 non-null  float64\n",
      " 237  1111X_Presion                17544 non-null  float64\n",
      " 238  1186P_Presion                17544 non-null  float64\n",
      " 239  1279X_Presion                17544 non-null  float64\n",
      " 240  1387E_Presion                17544 non-null  float64\n",
      " 241  1390X_Presion                17544 non-null  float64\n",
      " 242  1466A_Presion                17544 non-null  float64\n",
      " 243  1475X_Presion                17544 non-null  float64\n",
      " 244  1719_Presion                 17544 non-null  float64\n",
      " 245  2044B_Presion                17544 non-null  float64\n",
      " 246  2048A_Presion                17544 non-null  float64\n",
      " 247  2331_Presion                 17544 non-null  float64\n",
      " 248  2734D_Presion                17544 non-null  float64\n",
      " 249  2777K_Presion                17544 non-null  float64\n",
      " 250  2873X_Presion                17544 non-null  float64\n",
      " 251  2891A_Presion                17544 non-null  float64\n",
      " 252  2946X_Presion                17544 non-null  float64\n",
      " 253  3104Y_Presion                17544 non-null  float64\n",
      " 254  3140Y_Presion                17544 non-null  float64\n",
      " 255  3266A_Presion                17544 non-null  float64\n",
      " 256  3475X_Presion                17544 non-null  float64\n",
      " 257  3504X_Presion                17544 non-null  float64\n",
      " 258  3526X_Presion                17544 non-null  float64\n",
      " 259  3562X_Presion                17544 non-null  float64\n",
      " 260  4096Y_Presion                17544 non-null  float64\n",
      " 261  4340_Presion                 17544 non-null  float64\n",
      " 262  5390Y_Presion                17544 non-null  float64\n",
      " 263  5402_Presion                 17544 non-null  float64\n",
      " 264  5582A_Presion                17544 non-null  float64\n",
      " 265  5598X_Presion                17544 non-null  float64\n",
      " 266  5612X_Presion                17544 non-null  float64\n",
      " 267  5906X_Presion                17544 non-null  float64\n",
      " 268  5972X_Presion                17544 non-null  float64\n",
      " 269  6045X_Presion                17544 non-null  float64\n",
      " 270  6172X_Presion                17544 non-null  float64\n",
      " 271  6268Y_Presion                17544 non-null  float64\n",
      " 272  6307X_Presion                17544 non-null  float64\n",
      " 273  6312E_Presion                17544 non-null  float64\n",
      " 274  7066Y_Presion                17544 non-null  float64\n",
      " 275  7195X_Presion                17544 non-null  float64\n",
      " 276  7275C_Presion                17544 non-null  float64\n",
      " 277  8025_Presion                 17544 non-null  float64\n",
      " 278  8036Y_Presion                17544 non-null  float64\n",
      " 279  8177A_Presion                17544 non-null  float64\n",
      " 280  8270X_Presion                17544 non-null  float64\n",
      " 281  8486X_Presion                17544 non-null  float64\n",
      " 282  8500A_Presion                17544 non-null  float64\n",
      " 283  9016X_Presion                17544 non-null  float64\n",
      " 284  9257X_Presion                17544 non-null  float64\n",
      " 285  9301X_Presion                17544 non-null  float64\n",
      " 286  9352A_Presion                17544 non-null  float64\n",
      " 287  9377Y_Presion                17544 non-null  float64\n",
      " 288  9434_Presion                 17544 non-null  float64\n",
      " 289  9573X_Presion                17544 non-null  float64\n",
      " 290  9677_Presion                 17544 non-null  float64\n",
      " 291  9814X_Presion                17544 non-null  float64\n",
      " 292  9843A_Presion                17544 non-null  float64\n",
      " 293  9946X_Presion                17544 non-null  float64\n",
      " 294  B275E_Presion                17544 non-null  float64\n",
      " 295  B569X_Presion                17544 non-null  float64\n",
      " 296  B760X_Presion                17544 non-null  float64\n",
      " 297  B925_Presion                 17544 non-null  float64\n",
      " 298  C148F_Presion                17544 non-null  float64\n",
      " 299  C249I_Presion                17544 non-null  float64\n",
      " 300  C619Y_Presion                17544 non-null  float64\n",
      " 301  C639M_Presion                17544 non-null  float64\n",
      " 302  C649R_Presion                17544 non-null  float64\n",
      " 303  C659H_Presion                17544 non-null  float64\n",
      " 304  C659M_Presion                17544 non-null  float64\n",
      " 305  0016A_Temperatura            17544 non-null  float64\n",
      " 306  0201D_Temperatura            17544 non-null  float64\n",
      " 307  0244X_Temperatura            17544 non-null  float64\n",
      " 308  0367_Temperatura             17544 non-null  float64\n",
      " 309  1025X_Temperatura            17544 non-null  float64\n",
      " 310  1056K_Temperatura            17544 non-null  float64\n",
      " 311  1074C_Temperatura            17544 non-null  float64\n",
      " 312  1111X_Temperatura            17544 non-null  float64\n",
      " 313  1186P_Temperatura            17544 non-null  float64\n",
      " 314  1279X_Temperatura            17544 non-null  float64\n",
      " 315  1387E_Temperatura            17544 non-null  float64\n",
      " 316  1390X_Temperatura            17544 non-null  float64\n",
      " 317  1466A_Temperatura            17544 non-null  float64\n",
      " 318  1475X_Temperatura            17544 non-null  float64\n",
      " 319  1719_Temperatura             17544 non-null  float64\n",
      " 320  2044B_Temperatura            17544 non-null  float64\n",
      " 321  2048A_Temperatura            17544 non-null  float64\n",
      " 322  2331_Temperatura             17544 non-null  float64\n",
      " 323  2734D_Temperatura            17544 non-null  float64\n",
      " 324  2777K_Temperatura            17544 non-null  float64\n",
      " 325  2873X_Temperatura            17544 non-null  float64\n",
      " 326  2891A_Temperatura            17544 non-null  float64\n",
      " 327  2946X_Temperatura            17544 non-null  float64\n",
      " 328  3104Y_Temperatura            17544 non-null  float64\n",
      " 329  3140Y_Temperatura            17544 non-null  float64\n",
      " 330  3266A_Temperatura            17544 non-null  float64\n",
      " 331  3475X_Temperatura            17544 non-null  float64\n",
      " 332  3504X_Temperatura            17544 non-null  float64\n",
      " 333  3526X_Temperatura            17544 non-null  float64\n",
      " 334  3562X_Temperatura            17544 non-null  float64\n",
      " 335  4096Y_Temperatura            17544 non-null  float64\n",
      " 336  4340_Temperatura             17544 non-null  float64\n",
      " 337  5390Y_Temperatura            17544 non-null  float64\n",
      " 338  5402_Temperatura             17544 non-null  float64\n",
      " 339  5582A_Temperatura            17544 non-null  float64\n",
      " 340  5598X_Temperatura            17544 non-null  float64\n",
      " 341  5612X_Temperatura            17544 non-null  float64\n",
      " 342  5906X_Temperatura            17544 non-null  float64\n",
      " 343  5972X_Temperatura            17544 non-null  float64\n",
      " 344  6045X_Temperatura            17544 non-null  float64\n",
      " 345  6172X_Temperatura            17544 non-null  float64\n",
      " 346  6268Y_Temperatura            17544 non-null  float64\n",
      " 347  6307X_Temperatura            17544 non-null  float64\n",
      " 348  6312E_Temperatura            17544 non-null  float64\n",
      " 349  7066Y_Temperatura            17544 non-null  float64\n",
      " 350  7195X_Temperatura            17544 non-null  float64\n",
      " 351  7275C_Temperatura            17544 non-null  float64\n",
      " 352  8025_Temperatura             17544 non-null  float64\n",
      " 353  8036Y_Temperatura            17544 non-null  float64\n",
      " 354  8177A_Temperatura            17544 non-null  float64\n",
      " 355  8270X_Temperatura            17544 non-null  float64\n",
      " 356  8486X_Temperatura            17544 non-null  float64\n",
      " 357  8500A_Temperatura            17544 non-null  float64\n",
      " 358  9016X_Temperatura            17544 non-null  float64\n",
      " 359  9257X_Temperatura            17544 non-null  float64\n",
      " 360  9301X_Temperatura            17544 non-null  float64\n",
      " 361  9352A_Temperatura            17544 non-null  float64\n",
      " 362  9377Y_Temperatura            17544 non-null  float64\n",
      " 363  9434_Temperatura             17544 non-null  float64\n",
      " 364  9573X_Temperatura            17544 non-null  float64\n",
      " 365  9677_Temperatura             17544 non-null  float64\n",
      " 366  9814X_Temperatura            17544 non-null  float64\n",
      " 367  9843A_Temperatura            17544 non-null  float64\n",
      " 368  9946X_Temperatura            17544 non-null  float64\n",
      " 369  B275E_Temperatura            17544 non-null  float64\n",
      " 370  B569X_Temperatura            17544 non-null  float64\n",
      " 371  B760X_Temperatura            17544 non-null  float64\n",
      " 372  B925_Temperatura             17544 non-null  float64\n",
      " 373  C148F_Temperatura            17544 non-null  float64\n",
      " 374  C249I_Temperatura            17544 non-null  float64\n",
      " 375  C619Y_Temperatura            17544 non-null  float64\n",
      " 376  C639M_Temperatura            17544 non-null  float64\n",
      " 377  C649R_Temperatura            17544 non-null  float64\n",
      " 378  C659H_Temperatura            17544 non-null  float64\n",
      " 379  C659M_Temperatura            17544 non-null  float64\n",
      " 380  0016A_Viento                 17544 non-null  float64\n",
      " 381  0201D_Viento                 17544 non-null  float64\n",
      " 382  0244X_Viento                 17544 non-null  float64\n",
      " 383  0367_Viento                  17544 non-null  float64\n",
      " 384  1025X_Viento                 17544 non-null  float64\n",
      " 385  1056K_Viento                 17544 non-null  float64\n",
      " 386  1074C_Viento                 17544 non-null  float64\n",
      " 387  1111X_Viento                 17544 non-null  float64\n",
      " 388  1186P_Viento                 17544 non-null  float64\n",
      " 389  1279X_Viento                 17544 non-null  float64\n",
      " 390  1387E_Viento                 17544 non-null  float64\n",
      " 391  1390X_Viento                 17544 non-null  float64\n",
      " 392  1466A_Viento                 17544 non-null  float64\n",
      " 393  1475X_Viento                 17544 non-null  float64\n",
      " 394  1719_Viento                  17544 non-null  float64\n",
      " 395  2044B_Viento                 17544 non-null  float64\n",
      " 396  2048A_Viento                 17544 non-null  float64\n",
      " 397  2331_Viento                  17544 non-null  float64\n",
      " 398  2734D_Viento                 17544 non-null  float64\n",
      " 399  2777K_Viento                 17544 non-null  float64\n",
      " 400  2873X_Viento                 17544 non-null  float64\n",
      " 401  2891A_Viento                 17544 non-null  float64\n",
      " 402  2946X_Viento                 17544 non-null  float64\n",
      " 403  3104Y_Viento                 17544 non-null  float64\n",
      " 404  3140Y_Viento                 17544 non-null  float64\n",
      " 405  3266A_Viento                 17544 non-null  float64\n",
      " 406  3475X_Viento                 17544 non-null  float64\n",
      " 407  3504X_Viento                 17544 non-null  float64\n",
      " 408  3526X_Viento                 17544 non-null  float64\n",
      " 409  3562X_Viento                 17544 non-null  float64\n",
      " 410  4096Y_Viento                 17544 non-null  float64\n",
      " 411  4340_Viento                  17544 non-null  float64\n",
      " 412  5390Y_Viento                 17544 non-null  float64\n",
      " 413  5402_Viento                  17544 non-null  float64\n",
      " 414  5582A_Viento                 17544 non-null  float64\n",
      " 415  5598X_Viento                 17544 non-null  float64\n",
      " 416  5612X_Viento                 17544 non-null  float64\n",
      " 417  5906X_Viento                 17544 non-null  float64\n",
      " 418  5972X_Viento                 17544 non-null  float64\n",
      " 419  6045X_Viento                 17544 non-null  float64\n",
      " 420  6172X_Viento                 17544 non-null  float64\n",
      " 421  6268Y_Viento                 17544 non-null  float64\n",
      " 422  6307X_Viento                 17544 non-null  float64\n",
      " 423  6312E_Viento                 17544 non-null  float64\n",
      " 424  7066Y_Viento                 17544 non-null  float64\n",
      " 425  7195X_Viento                 17544 non-null  float64\n",
      " 426  7275C_Viento                 17544 non-null  float64\n",
      " 427  8025_Viento                  17544 non-null  float64\n",
      " 428  8036Y_Viento                 17544 non-null  float64\n",
      " 429  8177A_Viento                 17544 non-null  float64\n",
      " 430  8270X_Viento                 17544 non-null  float64\n",
      " 431  8486X_Viento                 17544 non-null  float64\n",
      " 432  8500A_Viento                 17544 non-null  float64\n",
      " 433  9016X_Viento                 17544 non-null  float64\n",
      " 434  9257X_Viento                 17544 non-null  float64\n",
      " 435  9301X_Viento                 17544 non-null  float64\n",
      " 436  9352A_Viento                 17544 non-null  float64\n",
      " 437  9377Y_Viento                 17544 non-null  float64\n",
      " 438  9434_Viento                  17544 non-null  float64\n",
      " 439  9573X_Viento                 17544 non-null  float64\n",
      " 440  9677_Viento                  17544 non-null  float64\n",
      " 441  9814X_Viento                 17544 non-null  float64\n",
      " 442  9843A_Viento                 17544 non-null  float64\n",
      " 443  9946X_Viento                 17544 non-null  float64\n",
      " 444  B275E_Viento                 17544 non-null  float64\n",
      " 445  B569X_Viento                 17544 non-null  float64\n",
      " 446  B760X_Viento                 17544 non-null  float64\n",
      " 447  B925_Viento                  17544 non-null  float64\n",
      " 448  C148F_Viento                 17544 non-null  float64\n",
      " 449  C249I_Viento                 17544 non-null  float64\n",
      " 450  C619Y_Viento                 17544 non-null  float64\n",
      " 451  C639M_Viento                 17544 non-null  float64\n",
      " 452  C649R_Viento                 17544 non-null  float64\n",
      " 453  C659H_Viento                 17544 non-null  float64\n",
      " 454  C659M_Viento                 17544 non-null  float64\n",
      " 455  0016A_Viento_pred            17544 non-null  float64\n",
      " 456  0201D_Viento_pred            17544 non-null  float64\n",
      " 457  0244X_Viento_pred            17544 non-null  float64\n",
      " 458  0367_Viento_pred             17544 non-null  float64\n",
      " 459  1025X_Viento_pred            17544 non-null  float64\n",
      " 460  1056K_Viento_pred            17544 non-null  float64\n",
      " 461  1074C_Viento_pred            17544 non-null  float64\n",
      " 462  1111X_Viento_pred            17544 non-null  float64\n",
      " 463  1186P_Viento_pred            17544 non-null  float64\n",
      " 464  1279X_Viento_pred            17544 non-null  float64\n",
      " 465  1387E_Viento_pred            17544 non-null  float64\n",
      " 466  1390X_Viento_pred            17544 non-null  float64\n",
      " 467  1466A_Viento_pred            17544 non-null  float64\n",
      " 468  1475X_Viento_pred            17544 non-null  float64\n",
      " 469  1719_Viento_pred             17544 non-null  float64\n",
      " 470  2044B_Viento_pred            17544 non-null  float64\n",
      " 471  2048A_Viento_pred            17544 non-null  float64\n",
      " 472  2331_Viento_pred             17544 non-null  float64\n",
      " 473  2734D_Viento_pred            17544 non-null  float64\n",
      " 474  2777K_Viento_pred            17544 non-null  float64\n",
      " 475  2873X_Viento_pred            17544 non-null  float64\n",
      " 476  2891A_Viento_pred            17544 non-null  float64\n",
      " 477  2946X_Viento_pred            17544 non-null  float64\n",
      " 478  3104Y_Viento_pred            17544 non-null  float64\n",
      " 479  3140Y_Viento_pred            17544 non-null  float64\n",
      " 480  3266A_Viento_pred            17544 non-null  float64\n",
      " 481  3475X_Viento_pred            17544 non-null  float64\n",
      " 482  3504X_Viento_pred            17544 non-null  float64\n",
      " 483  3526X_Viento_pred            17544 non-null  float64\n",
      " 484  3562X_Viento_pred            17544 non-null  float64\n",
      " 485  4096Y_Viento_pred            17544 non-null  float64\n",
      " 486  4340_Viento_pred             17544 non-null  float64\n",
      " 487  5390Y_Viento_pred            17544 non-null  float64\n",
      " 488  5402_Viento_pred             17544 non-null  float64\n",
      " 489  5582A_Viento_pred            17544 non-null  float64\n",
      " 490  5598X_Viento_pred            17544 non-null  float64\n",
      " 491  5612X_Viento_pred            17544 non-null  float64\n",
      " 492  5906X_Viento_pred            17544 non-null  float64\n",
      " 493  5972X_Viento_pred            17544 non-null  float64\n",
      " 494  6045X_Viento_pred            17544 non-null  float64\n",
      " 495  6172X_Viento_pred            17544 non-null  float64\n",
      " 496  6268Y_Viento_pred            17544 non-null  float64\n",
      " 497  6307X_Viento_pred            17544 non-null  float64\n",
      " 498  6312E_Viento_pred            17544 non-null  float64\n",
      " 499  7066Y_Viento_pred            17544 non-null  float64\n",
      " 500  7195X_Viento_pred            17544 non-null  float64\n",
      " 501  7275C_Viento_pred            17544 non-null  float64\n",
      " 502  8025_Viento_pred             17544 non-null  float64\n",
      " 503  8036Y_Viento_pred            17544 non-null  float64\n",
      " 504  8177A_Viento_pred            17544 non-null  float64\n",
      " 505  8270X_Viento_pred            17544 non-null  float64\n",
      " 506  8486X_Viento_pred            17544 non-null  float64\n",
      " 507  8500A_Viento_pred            17544 non-null  float64\n",
      " 508  9016X_Viento_pred            17544 non-null  float64\n",
      " 509  9257X_Viento_pred            17544 non-null  float64\n",
      " 510  9301X_Viento_pred            17544 non-null  float64\n",
      " 511  9352A_Viento_pred            17544 non-null  float64\n",
      " 512  9377Y_Viento_pred            17544 non-null  float64\n",
      " 513  9434_Viento_pred             17544 non-null  float64\n",
      " 514  9573X_Viento_pred            17544 non-null  float64\n",
      " 515  9677_Viento_pred             17544 non-null  float64\n",
      " 516  9814X_Viento_pred            17544 non-null  float64\n",
      " 517  9843A_Viento_pred            17544 non-null  float64\n",
      " 518  9946X_Viento_pred            17544 non-null  float64\n",
      " 519  B275E_Viento_pred            17544 non-null  float64\n",
      " 520  B569X_Viento_pred            17544 non-null  float64\n",
      " 521  B760X_Viento_pred            17544 non-null  float64\n",
      " 522  B925_Viento_pred             17544 non-null  float64\n",
      " 523  C148F_Viento_pred            17544 non-null  float64\n",
      " 524  C249I_Viento_pred            17544 non-null  float64\n",
      " 525  C619Y_Viento_pred            17544 non-null  float64\n",
      " 526  C639M_Viento_pred            17544 non-null  float64\n",
      " 527  C649R_Viento_pred            17544 non-null  float64\n",
      " 528  C659H_Viento_pred            17544 non-null  float64\n",
      " 529  C659M_Viento_pred            17544 non-null  float64\n",
      " 530  Eolica_emi                   17544 non-null  int64  \n",
      " 531  Nuclear_emi                  17544 non-null  int64  \n",
      " 532  Carbon_emi                   17544 non-null  float64\n",
      " 533  Ciclo_combinado_emi          17544 non-null  float64\n",
      " 534  Hidraulica_emi               17544 non-null  int64  \n",
      " 535  Intercambios_int_emi         17544 non-null  int64  \n",
      " 536  Solar_fotovoltaica_emi       17544 non-null  int64  \n",
      " 537  Solar_termica_emi            17544 non-null  int64  \n",
      " 538  Termica_renovable_emi        17544 non-null  int64  \n",
      " 539  Motores_diesel_emi           17544 non-null  float64\n",
      " 540  Turbina_de_gas_emi           17544 non-null  float64\n",
      " 541  Turbina_de_vapor_emi         17544 non-null  float64\n",
      " 542  Generacion_auxiliar_emi      17544 non-null  float64\n",
      " 543  Cogeneracion_y_residuos_emi  17544 non-null  float64\n",
      " 544  Eolica_gen                   17544 non-null  float64\n",
      " 545  Nuclear_gen                  17544 non-null  int64  \n",
      " 546  Carbon_gen                   17544 non-null  int64  \n",
      " 547  Ciclo_combinado_gen          17544 non-null  int64  \n",
      " 548  Hidraulica_gen               17544 non-null  float64\n",
      " 549  Intercambios_int_gen         17544 non-null  int64  \n",
      " 550  Solar_fotovoltaica_gen       17544 non-null  float64\n",
      " 551  Solar_termica_gen            17544 non-null  float64\n",
      " 552  Termica_renovable_gen        17544 non-null  int64  \n",
      " 553  Motores_diesel_gen           17544 non-null  int64  \n",
      " 554  Turbina_de_gas_gen           17544 non-null  int64  \n",
      " 555  Turbina_de_vapor_gen         17544 non-null  int64  \n",
      " 556  Generacion_auxiliar_gen      17544 non-null  int64  \n",
      " 557  Cogeneracion_y_residuos_gen  17544 non-null  int64  \n",
      " 558  Real                         17544 non-null  float64\n",
      " 559  Prevista                     17544 non-null  float64\n",
      " 560  Programada                   17544 non-null  float64\n",
      " 561  file                         17544 non-null  object \n",
      " 562  Asturias                     17544 non-null  float64\n",
      " 563  Cantabria                    17544 non-null  float64\n",
      " 564  Navarra                      17544 non-null  float64\n",
      " 565  País Vasco                   17544 non-null  float64\n",
      " 566  Cataluña                     17544 non-null  float64\n",
      " 567  Aragón                       17544 non-null  float64\n",
      " 568  Galicia                      17544 non-null  float64\n",
      " 569  Islas Baleares               17544 non-null  float64\n",
      " 570  La Rioja                     17544 non-null  float64\n",
      " 571  Valencia                     17544 non-null  float64\n",
      " 572  Castilla y León              17544 non-null  float64\n",
      " 573  Castilla La Mancha           17544 non-null  float64\n",
      " 574  Extremadura                  17544 non-null  float64\n",
      " 575  Andalucía                    17544 non-null  float64\n",
      " 576  Murcia                       17544 non-null  float64\n",
      " 577  Madrid                       17544 non-null  float64\n",
      " 578  Solar_altitude               17544 non-null  float64\n",
      " 579  is_weekend                   17544 non-null  int64  \n",
      " 580  Real_1day_before             17544 non-null  float64\n",
      " 581  Real_2days_before            17544 non-null  float64\n",
      " 582  Real_3days_before            17544 non-null  float64\n",
      "dtypes: float64(559), int64(23), object(1)\n",
      "memory usage: 78.0+ MB\n",
      "None\n",
      "                Ano           Mes           Dia          Hora   Minuto  0016A_Altitud  0201D_Altitud  0244X_Altitud  0367_Altitud  1025X_Altitud  1056K_Altitud  1074C_Altitud  1111X_Altitud  1186P_Altitud  1279X_Altitud  1387E_Altitud  1390X_Altitud  1466A_Altitud  1475X_Altitud  1719_Altitud  2044B_Altitud  2048A_Altitud  2331_Altitud  2734D_Altitud  2777K_Altitud  2873X_Altitud  2891A_Altitud  2946X_Altitud  3104Y_Altitud  3140Y_Altitud  3266A_Altitud  3475X_Altitud  3504X_Altitud  3526X_Altitud  3562X_Altitud  4096Y_Altitud  4340_Altitud  5390Y_Altitud  5402_Altitud  5582A_Altitud  5598X_Altitud  5612X_Altitud  5906X_Altitud  5972X_Altitud  6045X_Altitud  6172X_Altitud  6268Y_Altitud  6307X_Altitud  6312E_Altitud  7066Y_Altitud  7195X_Altitud  7275C_Altitud  8025_Altitud  8036Y_Altitud  8177A_Altitud  8270X_Altitud  8486X_Altitud  8500A_Altitud  9016X_Altitud  9257X_Altitud  9301X_Altitud  9352A_Altitud  9377Y_Altitud  9434_Altitud  9573X_Altitud  9677_Altitud  9814X_Altitud  \\\n",
      "count  17544.000000  17544.000000  17544.000000  17544.000000  17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0       17544.0        17544.0   \n",
      "mean    2023.213406      6.519836     15.738714     11.500000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "std        0.674661      3.449649      8.804172      6.922384      0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0           0.0            0.0           0.0            0.0   \n",
      "min     2022.000000      1.000000      1.000000      0.000000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "25%     2023.000000      4.000000      8.000000      5.750000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "50%     2023.000000      7.000000     16.000000     11.500000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "75%     2024.000000     10.000000     23.000000     17.250000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "max     2024.000000     12.000000     31.000000     23.000000      0.0           71.0           26.0           56.0         143.0          255.0           45.0          100.0           51.0          370.0          240.0           98.0           98.0          435.0          240.0         560.0         1100.0          978.0         891.0          919.0          737.0          817.0          690.0          680.0         1159.0          990.0         1532.0          373.0          724.0          313.0          321.0          918.0         313.0          750.0          90.0          760.0          465.0          450.0           10.0           28.0          676.0           25.0            1.0         1518.0          601.0          680.0          985.0          640.0          81.0           36.0          880.0          305.0         1515.0           43.0          770.0          615.0          410.0         1000.0         1185.0         249.0          334.0        2410.0         1076.0   \n",
      "\n",
      "       9843A_Altitud  9946X_Altitud  B275E_Altitud  B569X_Altitud  B760X_Altitud  B925_Altitud  C148F_Altitud  C249I_Altitud  C619Y_Altitud  C639M_Altitud  C649R_Altitud  C659H_Altitud  C659M_Altitud  0016A_Humedad_relativa  0201D_Humedad_relativa  0244X_Humedad_relativa  0367_Humedad_relativa  1025X_Humedad_relativa  1056K_Humedad_relativa  1074C_Humedad_relativa  1111X_Humedad_relativa  1186P_Humedad_relativa  1279X_Humedad_relativa  1387E_Humedad_relativa  1390X_Humedad_relativa  1466A_Humedad_relativa  1475X_Humedad_relativa  1719_Humedad_relativa  2044B_Humedad_relativa  2048A_Humedad_relativa  2331_Humedad_relativa  2734D_Humedad_relativa  2777K_Humedad_relativa  2873X_Humedad_relativa  2891A_Humedad_relativa  2946X_Humedad_relativa  3104Y_Humedad_relativa  3140Y_Humedad_relativa  3266A_Humedad_relativa  3475X_Humedad_relativa  3504X_Humedad_relativa  3526X_Humedad_relativa  3562X_Humedad_relativa  4096Y_Humedad_relativa  4340_Humedad_relativa  5390Y_Humedad_relativa  \\\n",
      "count        17544.0        17544.0        17544.0        17544.0        17544.0       17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0        17544.0            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000   \n",
      "mean           825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               78.645505               85.298503               73.703971              79.549966               83.341061               87.932414               86.955535               84.639564               82.369211               88.507275               84.361469               90.605800               89.375963               88.018811              88.927185               88.934172               84.555380              85.852212               85.244499               81.782440               83.053693               82.640602               77.558665               84.977518               84.109440               94.236775               72.661909               79.014367               73.680327               72.998705               86.776954              73.741861               74.705176   \n",
      "std              0.0            0.0            0.0            0.0            0.0           0.0            0.0            0.0            0.0            0.0            0.0            0.0            0.0               12.982027                7.321991                9.220527              13.361466               12.949354               11.680500               11.048939                8.768136               15.194815                9.002921                9.570424                5.269272                7.560695               11.288062               9.367725               12.388408               12.526677               9.763116               13.444214               12.316739                7.415661                8.167666               10.775970               14.493382               15.170472                8.549972               12.758881               10.142724               15.405912               11.547168               12.327831              11.834436               10.694130   \n",
      "min            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               35.143417               44.376778               44.055698              35.257401               34.121571               45.781467               44.224327               41.570076               26.824883               51.351650               41.626255               69.196899               48.224895               31.320835              53.042210               35.862324               32.653690              43.500000               42.588963               33.633232               53.116501               48.782921               38.614082               23.211906               24.716419               51.223278               27.438637               41.801983               21.076496               36.332546               32.382313              34.467346               37.831699   \n",
      "25%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               69.355709               84.045591               67.481009              69.158333               74.194418               79.404572               79.047640               79.850397               72.173241               82.498598               78.167864               87.665756               86.605227               83.264822              83.348827               83.629280               77.947329              79.988995               77.839939               75.635609               78.815414               77.627405               72.039148               79.133202               76.291180               90.934404               64.325819               72.744003               63.933352               65.629507               80.770510              65.417509               68.761271   \n",
      "50%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               82.040009               88.000000               75.149952              80.952877               86.333858               91.402016               89.744781               86.704533               86.221016               90.301041               85.052002               91.740906               91.158131               91.158867              89.618397               93.283924               89.886299              88.417191               90.148373               86.548225               84.936806               83.539944               80.797291               89.664982               89.155544               99.345173               74.113888               81.075363               75.596615               75.931007               90.075855              75.838520               75.943535   \n",
      "75%            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0               89.243284               88.873730               80.633869              90.897900               94.273117               98.646008               96.268223               91.064487               95.250309               95.710987               91.675144               94.470640               94.286194               95.767588              97.387156               98.607418               93.393618              93.041420               94.334354               90.800747               88.641708               89.005104               85.457214               95.388365               95.807928              100.000000               81.967384               86.378958               85.048122               81.950157               96.159042              83.297071               82.492586   \n",
      "max            825.0          495.0           49.0           57.0           35.0          32.0          362.0           25.0           13.0           45.0            9.0           55.0           15.0              100.000000               96.201492               92.850372             100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000             100.000000              100.000000              100.000000             100.000000              100.000000               99.131729               97.361641              100.000000               94.833328              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000               94.312561              100.000000              97.440346              100.000000   \n",
      "\n",
      "       5402_Humedad_relativa  5582A_Humedad_relativa  5598X_Humedad_relativa  5612X_Humedad_relativa  5906X_Humedad_relativa  5972X_Humedad_relativa  6045X_Humedad_relativa  6172X_Humedad_relativa  6268Y_Humedad_relativa  6307X_Humedad_relativa  6312E_Humedad_relativa  7066Y_Humedad_relativa  7195X_Humedad_relativa  7275C_Humedad_relativa  8025_Humedad_relativa  8036Y_Humedad_relativa  8177A_Humedad_relativa  8270X_Humedad_relativa  8486X_Humedad_relativa  8500A_Humedad_relativa  9016X_Humedad_relativa  9257X_Humedad_relativa  9301X_Humedad_relativa  9352A_Humedad_relativa  9377Y_Humedad_relativa  9434_Humedad_relativa  9573X_Humedad_relativa  9677_Humedad_relativa  9814X_Humedad_relativa  9843A_Humedad_relativa  9946X_Humedad_relativa  B275E_Humedad_relativa  B569X_Humedad_relativa  B760X_Humedad_relativa  B925_Humedad_relativa  C148F_Humedad_relativa  C249I_Humedad_relativa  C619Y_Humedad_relativa  C639M_Humedad_relativa  C649R_Humedad_relativa  C659H_Humedad_relativa  \\\n",
      "count           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000           17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000            17544.000000   \n",
      "mean               80.843474               65.984625               77.721553               71.278969               83.337645               78.539585               69.841095               66.752875               68.890195               64.526055               56.298102               62.965265               67.730889               60.391305              62.182325               68.963085               79.861424               77.134832               75.276632               74.595074               82.451906               90.247060               73.866613               85.167041               80.173777              77.837580               72.373922              83.534727               88.388428               90.161758               68.925591               71.004521               70.477186               77.031025              72.318358               78.359576               76.524213               66.051938               73.697290               68.512010               71.234412   \n",
      "std                11.637168               12.537599               11.789865               14.512291               12.052667                9.779350               10.656257               10.071838                9.992100               19.807887                8.720392               10.673023               19.723460               16.625849              13.979420               16.503389               15.759683               14.935848               14.700770               17.934932               13.347211               10.667925               12.116113                8.522143               14.041692              14.133208               18.927590               7.878008               14.102295               11.068081               13.155611                9.787736               12.391906               10.714328              12.576636                9.094445                8.243105                7.640214                6.874119                6.586608                6.279021   \n",
      "min                37.692486               29.544971               42.347481               25.950035               44.248131               40.709927               34.167091               26.718437               28.022259                7.479774               22.343262               32.434418               11.742886               10.707302              13.668671               15.541855               21.931377               30.822079               25.917404                7.757622               36.054359               39.345749               29.955261               55.516972               29.068771              32.500000                3.610710              43.236923               32.303753               37.843056               11.726532               38.816624               22.912579               42.907055              35.587482               50.042141               39.191170               37.095474               51.824158               46.707489               49.194000   \n",
      "25%                72.671116               56.236443               69.777998               61.495058               74.771177               72.316351               62.982457               61.163270               63.504913               49.027180               53.463772               55.594232               53.412779               47.153008              53.003728               57.764785               69.548813               66.428484               66.390749               63.616263               73.067299               85.759663               66.170622               79.680525               73.350519              67.926935               61.957980              79.889631               81.683283               87.750759               61.245316               64.272018               62.437084               69.073812              62.225524               73.113358               71.896402               61.387473               68.832514               63.859560               67.071508   \n",
      "50%                83.489407               69.057770               78.315510               73.324638               84.654812               80.083447               71.878860               68.868912               70.353279               62.858538               56.500000               62.780642               70.248062               61.238964              65.100990               70.229424               84.382259               77.008659               78.242172               78.870411               85.677258               94.445236               77.019798               87.481106               84.382023              79.793217               76.222572              85.039711               93.894150               94.401333               71.817127               72.540852               73.684387               78.043419              72.306442               79.324535               78.000000               66.713184               73.885296               69.311081               71.679039   \n",
      "75%                89.837851               75.929123               86.141176               81.759026               93.289244               85.824846               78.320145               74.197710               76.229778               80.094517               58.325874               70.866915               83.138556               74.187828              73.385374               81.347984               92.313303               88.737213               84.548050               88.864719               93.056423               97.988979               83.395292               91.725817               90.032566              88.891224               87.323256              88.854485              100.000000               97.144718               78.844570               78.428860               80.002470               85.017656              82.662029               84.603144               82.434813               71.021030               79.152464               73.741716               76.240509   \n",
      "max               100.000000               91.630592              100.000000              100.000000              100.000000              100.000000               92.108795               96.406479               87.178169              100.000000               88.901840               93.853462              100.000000               96.862877              91.209732              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000              100.000000               93.607864              100.000000              100.000000             100.000000              100.000000             100.000000              100.000000              100.000000               92.716568               91.639984               93.311371              100.000000             100.000000              100.000000               93.166740               97.710999               92.280533               84.835785               85.018021   \n",
      "\n",
      "       C659M_Humedad_relativa  0016A_Precipitacion  0201D_Precipitacion  0244X_Precipitacion  0367_Precipitacion  1025X_Precipitacion  1056K_Precipitacion  1074C_Precipitacion  1111X_Precipitacion  1186P_Precipitacion  1279X_Precipitacion  1387E_Precipitacion  1390X_Precipitacion  1466A_Precipitacion  1475X_Precipitacion  1719_Precipitacion  2044B_Precipitacion  2048A_Precipitacion  2331_Precipitacion  2734D_Precipitacion  2777K_Precipitacion  2873X_Precipitacion  2891A_Precipitacion  2946X_Precipitacion  3104Y_Precipitacion  3140Y_Precipitacion  3266A_Precipitacion  3475X_Precipitacion  3504X_Precipitacion  3526X_Precipitacion  3562X_Precipitacion  4096Y_Precipitacion  4340_Precipitacion  5390Y_Precipitacion  5402_Precipitacion  5582A_Precipitacion  5598X_Precipitacion  5612X_Precipitacion  5906X_Precipitacion  5972X_Precipitacion  6045X_Precipitacion  6172X_Precipitacion  6268Y_Precipitacion  6307X_Precipitacion  6312E_Precipitacion  7066Y_Precipitacion  7195X_Precipitacion  \\\n",
      "count            17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000   \n",
      "mean                73.937804             0.086270             5.799117             0.084422            0.076727             0.109597             0.306239             0.148288             0.219429             0.107739             0.122511             0.294979             0.287854             0.258130             0.755983            0.578420             0.206820             0.111771            0.156214             0.144083             0.075956             0.129096             0.115862             0.093961             0.225793             0.085555             0.448395             0.142831             0.251492             0.227675             0.095650             0.079924            0.096416             0.113967            0.111405             0.096916             0.318046             0.189814             0.096850             0.270403             0.129004             0.155680             0.107539             0.069924            10.913621             0.089270             0.130954   \n",
      "std                  3.736788             1.374799             8.484172             1.363624            1.239648             1.058549             1.134688             1.035027             1.165866             1.094386             1.080889             1.351003             1.260762             1.540217             1.939839            1.799674             1.168006             1.189521            1.140424             1.612680             1.195590             1.233106             1.335515             1.317835             1.005618             1.290313             1.279893             1.590243             1.481956             1.656410             1.544702             1.290607            1.558440             1.492397            1.659046             1.547786             1.578015             1.571832             1.536314             1.828903             1.421918             1.515145             1.454879             1.129484            13.349852             1.442049             1.195240   \n",
      "min                 60.982677             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "25%                 71.405075             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.029266             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "50%                 74.044674             0.000000             0.000000             0.000000            0.000000             0.000000             0.006182             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.096921            0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.101011             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000   \n",
      "75%                 76.563118             0.000000            18.200000             0.000000            0.000000             0.000000             0.260014             0.038770             0.152167             0.000000             0.000000             0.223184             0.074588             0.051720             0.545405            0.301644             0.176452             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.259023             0.000000             0.392523             0.000000             0.055863             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.364491             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            27.250000             0.000000             0.000000   \n",
      "max                 84.846054            23.650000            19.900000            22.500000           20.700000            17.550000            17.450000            17.500000            18.700000            18.050000            17.450000            21.250000            18.850000            23.850000            22.850000           22.700000            20.050000            19.300000           19.650000            18.600000            20.500000            20.600000            22.400000            21.750000            17.150000            21.950000            16.850000            26.250000            23.550000            25.700000            25.550000            21.700000           26.400000            24.600000           27.150000            25.950000            25.600000            25.400000            25.600000            27.700000            24.800000            24.782608            24.500000            18.650000            27.250000            23.900000            19.850000   \n",
      "\n",
      "       7275C_Precipitacion  8025_Precipitacion  8036Y_Precipitacion  8177A_Precipitacion  8270X_Precipitacion  8486X_Precipitacion  8500A_Precipitacion  9016X_Precipitacion  9257X_Precipitacion  9301X_Precipitacion  9352A_Precipitacion  9377Y_Precipitacion  9434_Precipitacion  9573X_Precipitacion  9677_Precipitacion  9814X_Precipitacion  9843A_Precipitacion  9946X_Precipitacion  B275E_Precipitacion  B569X_Precipitacion  B760X_Precipitacion  B925_Precipitacion  C148F_Precipitacion  C249I_Precipitacion  C619Y_Precipitacion  C639M_Precipitacion  C649R_Precipitacion  C659H_Precipitacion  C659M_Precipitacion  0016A_Presion  0201D_Presion  0244X_Presion  0367_Presion  1025X_Presion  1056K_Presion  1074C_Presion  1111X_Presion  1186P_Presion  1279X_Presion  1387E_Presion  1390X_Presion  1466A_Presion  1475X_Presion  1719_Presion  2044B_Presion  2048A_Presion  2331_Presion  2734D_Presion  2777K_Presion  2873X_Presion  2891A_Presion  2946X_Presion  3104Y_Presion  3140Y_Presion  3266A_Presion  \\\n",
      "count         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000        17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000         17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   \n",
      "mean              0.089959            0.092795             0.117184             0.079202             0.215752             0.170503             0.090567             0.106948             0.275423             0.094790             0.071674             0.083917            0.102274             0.094026            0.201007             0.577843             0.344400             0.220856             0.088819             0.095017             0.105574            0.089201             0.084306             0.094933             0.095212             0.094453             0.091629             0.166037             0.094156    1006.614252     977.252804     985.597277    999.981778    1035.812160     993.382497    1001.733697    1010.459009     958.134798     942.912221    1001.429373     992.573671    1024.976641    1008.116474   1040.306780     895.236082     881.694108    915.033602     894.915049     915.742427     882.707738     868.261462     937.138042     896.920626     918.711744     847.784480   \n",
      "std               1.358939            1.499219             1.468069             1.279182             1.421547             0.987977             1.463988             1.006781             1.073314             1.175622             1.158436             1.116244            1.357365             1.333767            0.693020             1.539587             1.317198             2.119091             1.427753             1.535106             1.348240            1.439229             1.361748             1.535215             1.540097             1.525360             1.480200             2.044305             1.519918       5.476445       7.599955       6.609672      5.892336       7.229404       8.594393       6.886549       6.587984       7.254397       5.314445       8.553263       7.359677       6.838308       9.956167      8.763675       5.113925       5.093212      5.654577       5.668929       5.654209       6.627094       5.584496       5.884323       6.422975       4.977187       4.984431   \n",
      "min               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000     992.366089     949.485779     964.743591    983.063538     997.990000     958.150818     976.806641     986.516174     936.622559     930.074646     962.035034     955.824158     995.485779     970.484375    996.750000     883.023132     868.765564    894.983398     879.485291     890.274109     859.702454     850.983704     917.551514     876.032593     907.584656     833.643311   \n",
      "25%               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1002.686615     968.475000     981.283859    995.967575    1032.246307     988.083115     998.079941    1006.156403     953.482544     939.567642     997.939453     989.363266    1021.765793    1001.700000   1035.568878     891.322952     877.897263    911.431488     891.041199     912.623840     879.086426     865.239792     933.137497     893.129227     915.257111     844.435928   \n",
      "50%               0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000            0.007991             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1006.488434     978.150238     986.059235   1000.070221    1037.249878     994.859924    1003.100616    1010.734467     957.847473     942.041840    1004.164734     994.475311    1026.458130    1010.365326   1041.600952     895.172333     881.989471    915.850189     894.715790     916.239166     883.839813     868.553101     937.685974     897.582153     918.454773     848.212219   \n",
      "75%               0.000000            0.000000             0.000000             0.000000             0.076567             0.000000             0.000000             0.000000             0.259751             0.000000             0.000000             0.000000            0.000000             0.000000            0.119636             0.457875             0.135307             0.000000             0.000000             0.000000             0.000000            0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000             0.000000    1010.068298     983.446930     989.980331   1003.922028    1040.510040     999.399033    1006.367859    1015.289383     961.944427     945.551041    1007.079727     997.462631    1029.393127    1015.010147   1045.943237     898.912323     885.372894    919.091141     897.697845     919.564087     887.034073     871.075089     941.187515     901.554733     922.006622     851.416428   \n",
      "max              22.150000           25.050000            24.050000            21.200000            23.550000            16.050000            24.700000            16.650000            17.000000            20.050000            19.600000            19.150000           22.600000            22.100000           10.200000            19.450000            18.850000            21.600000            23.700000            25.650000            22.000000           24.100000            22.550000            26.500000            26.750000            25.200000            24.750000            25.600000            24.900000    1021.202148     995.585205    1002.250305   1017.098450    1050.263794    1010.408813    1015.991089    1026.792114     995.608032     986.618750    1016.074036    1007.719849    1044.007202    1036.501831   1062.736816     908.773560     897.100000    927.990601     933.289001     929.542603     907.490000     907.490000     950.734985     913.570000     932.370972     858.993896   \n",
      "\n",
      "       3475X_Presion  3504X_Presion  3526X_Presion  3562X_Presion  4096Y_Presion  4340_Presion  5390Y_Presion  5402_Presion  5582A_Presion  5598X_Presion  5612X_Presion  5906X_Presion  5972X_Presion  6045X_Presion  6172X_Presion  6268Y_Presion  6307X_Presion  6312E_Presion  7066Y_Presion  7195X_Presion  7275C_Presion  8025_Presion  8036Y_Presion  8177A_Presion  8270X_Presion  8486X_Presion  8500A_Presion  9016X_Presion  9257X_Presion  9301X_Presion  9352A_Presion  9377Y_Presion  9434_Presion  9573X_Presion  9677_Presion  9814X_Presion  9843A_Presion  9946X_Presion  B275E_Presion  B569X_Presion  B760X_Presion  B925_Presion  C148F_Presion  C249I_Presion  C619Y_Presion  C639M_Presion  C649R_Presion  C659H_Presion  C659M_Presion  0016A_Temperatura  0201D_Temperatura  0244X_Temperatura  0367_Temperatura  1025X_Temperatura  1056K_Temperatura  1074C_Temperatura  1111X_Temperatura  1186P_Temperatura  1279X_Temperatura  1387E_Temperatura  1390X_Temperatura  1466A_Temperatura  \\\n",
      "count   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000  17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000   17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean      978.182358    1022.088209     980.324093     971.959972     958.970244    968.920842     931.726001   1004.652934     776.135546     963.627151    1004.847004     962.037143    1012.914593    1082.939882     999.080664     681.213721    1080.510991     947.321480     931.512748    1079.891410     944.743914   1006.288915    1009.773076     916.244223     952.367380    1027.035862    1009.602701     905.604791    1002.642391     976.772294     884.050188     942.072987    986.699917     879.289106   1099.530471     930.624311     899.860563    1063.415144    1011.156408    1013.196395    1010.904770   1011.572907     941.384272    1014.843741    1016.350211    1019.665010    1014.381467    1020.355702    1015.674169          17.489967          18.770380          20.453208         18.530294          15.427593          16.435829          15.660039          16.364449          16.727039          16.015887          17.629651          15.882819          15.418910   \n",
      "std         5.253027       4.860617       5.855291       3.958558       4.216329      4.027742       3.475018      4.867036       9.398215       3.141394       4.086339       4.639425       3.165797       7.721168       5.561200      15.030891       7.394253       3.153458       3.022272       8.056099       3.959151      4.783542       4.547660       4.186292       6.095021       7.286145       7.498415       6.967444       5.720381       3.390610       3.986678       4.319986      5.180013       6.140727      7.585651       5.092917       5.083053       8.306629       3.431824       3.408402       3.525275      4.330479       3.597388       2.630717       1.762385       2.361539       2.874364       2.999345       2.719656           3.302484           1.620038           1.611769          3.105052           3.101791           3.158015           3.007023           1.846490           3.994400           3.461672           2.213679           2.240891           2.201555   \n",
      "min       959.423035     970.862500     955.227112     957.285767     934.575000    954.535583     922.320312    990.035156     765.530762     951.886047     989.008606     945.097412     980.242615    1002.850000     984.777893     671.704712     985.641667     939.561218     926.313232     989.881250     935.171814    993.696350     998.052856     906.491333     936.578857     930.983333     872.974243     887.746948     972.475000     965.304626     871.060059     914.475000    970.670471     866.347778    976.150000     915.358582     885.355347    1005.100000     999.310181    1003.111206     998.752502    998.169739     933.985535    1008.400000    1011.150000    1009.571429    1006.880188    1009.571429    1007.661194           9.209106          13.724069          15.392507          9.331562           8.075424           7.018330           9.550410          11.091537           6.235204           6.672863          10.656863           7.899129           8.772388   \n",
      "25%       974.632492    1019.830032     976.934433     969.752319     956.082428    966.798859     929.252747   1001.481491     773.595261     961.696198    1002.355347     959.291245    1011.198288    1077.952972     995.238068     678.269257    1077.994049     945.973740     929.190857    1075.890961     942.011215   1002.867050    1006.574997     913.244125     948.327881    1024.631958    1006.046295     902.177795     998.858521     974.912476     881.271774     939.340485    983.441452     875.379028   1100.000122     927.141281     896.366028    1058.921051    1008.934097    1011.085815    1008.539612   1008.740738     939.269470    1012.756836    1015.122742    1017.840347    1012.343079    1018.271484    1013.830933          14.992661          18.200000          19.113176         16.343008          13.017057          14.358105          13.118847          15.012233          13.771352          13.555547          16.187253          14.381362          13.779011   \n",
      "50%       978.435181    1021.785126     981.989288     972.106323     958.596863    969.106293     930.882233   1003.713745     775.752899     963.748627    1004.527863     962.489288    1012.973877    1082.939209     998.339539     680.731781    1081.056274     946.950000     930.728455    1079.659302     943.950165   1005.953583    1009.225159     915.791046     951.422394    1027.783264    1009.910522     905.141632    1002.764709     976.926056     883.793610     941.511749    986.664795     878.901764   1100.000122     931.027740     900.634003    1063.812073    1010.934357    1012.791504    1010.830597   1011.565765     940.958282    1014.492462    1016.039429    1019.106415    1013.835541    1019.902466    1015.338623          17.187369          18.200000          20.376690         18.308249          14.882962          16.114405          15.404482          16.225961          16.384774          15.826605          17.367743          16.110589          15.492554   \n",
      "75%       981.787674    1024.690216     984.354156     974.487991     961.721680    971.620285     933.675232   1008.151367     777.765137     965.898560    1007.570816     964.889557    1014.807434    1087.701538    1002.332230     682.326584    1084.336151     947.312393     933.250092    1084.523468     946.958954   1009.539078    1012.478287     918.691635     955.224838    1030.534729    1013.846512     907.897202    1006.775650     978.925629     886.630753     944.780624    989.808594     882.591721   1100.000122     934.494980     903.618088    1068.642059    1013.134659    1015.174881    1013.295547   1014.245544     942.886185    1016.809479    1017.349579    1021.254456    1016.187485    1022.326355    1017.391373          20.069508          19.784244          21.684522         20.708230          17.426626          18.631975          17.842211          17.542095          19.531332          18.537333          18.808368          17.559852          17.054851   \n",
      "max       990.219971    1033.520508     991.270874     982.035156     971.077942    977.858215     943.090820   1018.321228     921.175000     971.401001    1014.922058     996.007143    1022.048340    1100.000000    1016.390259     921.175000    1091.871216     959.018799     941.973206    1095.334106     958.357239   1019.943787    1022.909363     939.146240     982.516667    1036.435059    1024.199951     978.728572    1016.572693     987.387268     897.100000     956.076233   1001.355530     933.516667   1100.000122     942.693359     920.900000    1077.724365    1021.391663    1024.071045    1019.663147   1023.080688     975.747009    1022.594727    1022.710083    1027.051147    1022.991089    1028.691162    1023.201904          25.365870          23.720308          24.801941         27.454216          29.653635          26.357777          26.198933          22.144009          29.071087          26.330053          27.271729          22.133320          23.850000   \n",
      "\n",
      "       1475X_Temperatura  1719_Temperatura  2044B_Temperatura  2048A_Temperatura  2331_Temperatura  2734D_Temperatura  2777K_Temperatura  2873X_Temperatura  2891A_Temperatura  2946X_Temperatura  3104Y_Temperatura  3140Y_Temperatura  3266A_Temperatura  3475X_Temperatura  3504X_Temperatura  3526X_Temperatura  3562X_Temperatura  4096Y_Temperatura  4340_Temperatura  5390Y_Temperatura  5402_Temperatura  5582A_Temperatura  5598X_Temperatura  5612X_Temperatura  5906X_Temperatura  5972X_Temperatura  6045X_Temperatura  6172X_Temperatura  6268Y_Temperatura  6307X_Temperatura  6312E_Temperatura  7066Y_Temperatura  7195X_Temperatura  7275C_Temperatura  8025_Temperatura  8036Y_Temperatura  8177A_Temperatura  8270X_Temperatura  8486X_Temperatura  8500A_Temperatura  9016X_Temperatura  9257X_Temperatura  9301X_Temperatura  9352A_Temperatura  9377Y_Temperatura  9434_Temperatura  9573X_Temperatura  9677_Temperatura  9814X_Temperatura  9843A_Temperatura  9946X_Temperatura  B275E_Temperatura  \\\n",
      "count       17544.000000      17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean           17.604202         15.709500          12.152934          11.258528         12.424384          13.797902          13.693619          14.585602          14.073021          14.462330          10.236292          13.941308           9.673314          16.510689          15.162141          18.716862          18.115146          13.363093         18.323821          16.635097         19.237422          17.191880          17.880045          18.839378          20.520656          20.223832          18.087552          20.124534          20.968311          13.200191          22.977973          18.628024          14.742133          18.063653         21.764830          21.527819          15.330488          16.315153          12.304849          19.969096          12.382028          12.020784          16.251534          11.842602          11.803982         17.095796          16.129618          4.094196          11.730402          11.841330          16.500180          20.667096   \n",
      "std             2.012191          2.104158           2.855156           3.870807          3.894740           3.347185           3.403999           2.903663           2.386122           3.435158           3.464440           4.232740           2.190034           2.338979           2.692598           3.072061           2.860887           3.019844          3.420430           2.595066          2.697898           4.134224           3.454291           3.431958           1.804940           1.887249           3.645309           1.467471           1.444196           3.757836           3.763338           2.841842           4.254519           3.323264          2.795092           2.889968           3.977368           3.141722           3.298735           3.060675           4.471427           2.962623           3.004662           3.284912           3.712586          2.837490           3.937884          2.676851           3.277672           3.310015           3.319882           2.168583   \n",
      "min            10.800522          9.213299           5.528142           1.097467          1.238998           4.032483           3.276657           6.129852           6.669375           4.529089          -2.571681           3.833361           1.310746          10.209183           6.670433          11.093131          11.029390           3.581458          9.014250           6.408361         11.711831           8.770741           8.870099           9.871223          15.437985          12.654667           8.906227          15.487394          15.691759           3.845679          14.349721           9.966097           3.986917           8.902047         13.657481          14.803053           6.134442           6.581284           3.846155          11.195189           0.124064           5.566590           9.428516           3.859474           1.933386          9.993331           5.996670         -3.659091           2.881428           3.597418           9.786832          14.762064   \n",
      "25%            16.301046         14.254015          10.129621           8.511592          9.776810          11.749185          11.402154          12.488989          12.427768          12.086294           8.317264          10.931274           8.526004          14.877525          13.182480          16.500592          16.016516          11.367220         15.733006          14.902228         17.555050          13.950561          15.459084          16.358899          19.280191          19.202837          15.504602          19.122458          20.019773          10.391383          19.577219          16.606481          11.608628          15.694075         19.673180          19.243611          12.515400          14.072957           9.953700          17.636591           9.224771           9.808533          14.158523           9.485501           9.137678         14.987630          13.376353          2.429696           9.632200           9.716738          14.058077          18.993347   \n",
      "50%            17.494437         15.708643          11.750570          10.574811         12.007071          13.190019          12.962425          14.626769          14.261396          14.415085          10.160548          12.970313           9.788213          16.079656          14.994461          18.366067          17.721582          13.153453         18.212631          16.770646         19.039738          16.405367          17.302588          17.969643          20.402181          20.058752          17.413295          19.991214          21.059481          12.886318          22.068759          18.453574          13.973454          17.749334         21.682583          21.101799          14.256949          15.995227          11.742260          19.399300          12.204132          11.648264          15.714405          11.176358          11.146039         16.731733          15.659365          4.394750          11.331325          11.472409          15.758046          20.677589   \n",
      "75%            18.764968         17.281470          13.868133          13.440237         14.842039          15.518197          15.508738          16.782843          15.718676          16.565770          11.934982          16.407528          11.063738          17.794713          16.846859          20.625689          20.024064          15.160230         20.657561          17.865079         21.002017          19.963594          19.883599          21.071764          21.662644          21.179765          20.062195          20.968554          22.035738          15.904459          27.250000          20.522395          17.638625          20.406354         23.779818          23.709703          17.932578          18.272719          14.187555          22.186184          15.509917          13.896821          18.015180          13.832473          13.744866         18.841123          18.589514          6.188663          13.246682          13.685354          18.486175          22.456505   \n",
      "max            24.922523         22.700000          22.651524          26.387339         24.050709          25.494793          26.770939          22.092087          22.400000          24.363865          22.255838          28.357948          16.850000          26.250000          23.550000          29.267820          28.075588          24.471287         28.790947          25.220070         29.241638          28.805784          29.312561          29.956688          26.455339          27.700000          31.344837          26.799393          25.327328          24.299139          27.250000          28.008907          28.096182          28.659342         29.971210          28.957285          27.564781          28.460930          24.085773          30.013544          25.595163          22.743074          26.838495          22.942966          24.660479         27.190504          30.258717         10.200000          24.747490          23.148859          28.849724          25.698637   \n",
      "\n",
      "       B569X_Temperatura  B760X_Temperatura  B925_Temperatura  C148F_Temperatura  C249I_Temperatura  C619Y_Temperatura  C639M_Temperatura  C649R_Temperatura  C659H_Temperatura  C659M_Temperatura  0016A_Viento  0201D_Viento  0244X_Viento   0367_Viento  1025X_Viento  1056K_Viento  1074C_Viento  1111X_Viento  1186P_Viento  1279X_Viento  1387E_Viento  1390X_Viento  1466A_Viento  1475X_Viento   1719_Viento  2044B_Viento  2048A_Viento   2331_Viento  2734D_Viento  2777K_Viento  2873X_Viento  2891A_Viento  2946X_Viento  3104Y_Viento  3140Y_Viento  3266A_Viento  3475X_Viento  3504X_Viento  3526X_Viento  3562X_Viento  4096Y_Viento   4340_Viento  5390Y_Viento   5402_Viento  5582A_Viento  5598X_Viento  5612X_Viento  5906X_Viento  5972X_Viento  6045X_Viento  6172X_Viento  6268Y_Viento  6307X_Viento  6312E_Viento  7066Y_Viento  7195X_Viento  7275C_Viento   8025_Viento  8036Y_Viento  8177A_Viento  8270X_Viento  8486X_Viento  8500A_Viento  9016X_Viento  9257X_Viento  9301X_Viento  9352A_Viento  \\\n",
      "count       17544.000000       17544.000000      17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000   \n",
      "mean           22.175810          19.457712         21.104257          19.859160          22.777946          23.088667          23.471840          23.229189          22.320892          23.295468      3.566689      3.083995      2.060858      3.082791      1.378386      2.237893      1.670337      4.692886      1.543998      1.961286      3.858413      4.068246      2.090287      1.250848      2.335673      3.331115      3.622886      4.601094      2.624350      2.567130      2.979754      3.311218      2.775559      1.190698      2.287510      4.532285      3.459781      2.017870      2.699864      2.480564      1.758413      2.617510      2.608071      2.609713      2.039537      3.056088      2.400275      3.151792      3.214833      2.046058      2.533365      2.551456      3.418905      3.060055      2.501297      2.714915      2.983721      2.168673      1.969083      3.698632      1.976334      4.247606      2.260876      2.393335      2.549918      2.549918      4.657127   \n",
      "std             1.187085           2.793852          2.621041           2.023586           1.386558           1.760407           1.649422           1.394975           1.005794           1.065554      1.788271      1.221325      0.937617      1.474555      0.834112      1.044251      0.954031      2.252141      1.366792      1.183998      1.676486      1.707074      1.067278      0.680950      0.984947      1.529467      1.948656      1.977438      1.429239      1.583025      1.559272      1.716609      1.232713      0.871661      0.976504      2.429797      1.653960      0.979043      1.316941      1.292564      0.807034      1.333638      1.008313      1.307442      0.807340      1.307723      0.941489      1.358722      1.460060      0.860881      1.073682      1.549198      1.876561      1.025727      1.118278      0.855564      1.452967      0.751247      0.842957      1.645469      0.996617      2.458352      0.755160      1.224393      1.090900      1.090900      2.395900   \n",
      "min            18.977245          10.938687         13.592285          15.553852          18.225531          17.152431          20.034756          20.064423          19.554756          20.974348      0.800000      0.800000      0.300000      0.000000      0.000000      0.300000      0.000000      1.100000      0.000000      0.000000      0.600000      1.170000      0.300000      0.000000      0.700000      0.600000      0.000000      0.800000      0.600000      0.000000      0.300000      0.300000      0.600000      0.000000      0.750000      0.000000      0.000000      0.300000      0.600000      0.000000      0.000000      0.300000      0.800000      0.000000      0.000000      0.600000      0.821429      0.300000      0.300000      0.000000      0.300000      0.300000      0.600000      0.800000      0.528571      0.923810      0.800000      0.600000      0.600000      0.600000      0.000000      0.300000      0.800000      0.000000      0.547059      0.547059      0.300000   \n",
      "25%            21.290448          17.564327         19.028690          18.358079          21.731564          21.791207          22.069849          22.084247          21.599735          22.462121      2.500000      2.200000      1.400000      1.900000      0.800000      1.700000      1.100000      3.100000      0.800000      1.100000      2.800000      2.772727      1.400000      0.800000      1.688889      2.200000      2.200000      3.100000      1.700000      1.400000      1.700000      2.200000      1.900000      0.600000      1.600000      2.800000      2.200000      1.400000      1.700000      1.400000      1.100000      1.700000      1.900000      1.700000      1.400000      2.200000      1.740000      2.200000      2.200000      1.400000      1.700000      1.400000      2.200000      2.200000      1.750000      2.133333      1.900000      1.700000      1.400000      2.500000      1.400000      2.500000      1.700000      1.700000      1.658824      1.658824      2.800000   \n",
      "50%            22.038592          19.243238         21.210130          19.282922          22.650744          22.852086          23.188914          22.885611          22.276049          23.162720      3.100000      2.500000      1.900000      2.800000      1.100000      1.900000      1.400000      4.200000      1.100000      1.700000      3.600000      3.710000      1.900000      1.100000      2.088889      3.100000      3.300000      4.400000      2.500000      2.200000      2.800000      3.100000      2.500000      1.100000      2.133333      3.900000      3.300000      1.900000      2.500000      2.200000      1.700000      2.500000      2.500000      2.500000      1.900000      2.800000      2.226667      3.100000      3.100000      1.900000      2.200000      1.900000      3.100000      3.600000      2.325000      2.609524      2.500000      1.900000      1.700000      3.600000      1.900000      3.600000      2.200000      2.200000      2.482353      2.482353      4.200000   \n",
      "75%            22.869579          21.500885         22.936416          21.026951          23.743445          24.403316          24.786349          24.491677          22.949311          24.080912      3.900000      3.900000      2.500000      3.900000      1.700000      2.500000      2.200000      5.800000      1.700000      2.200000      4.700000      4.927273      2.500000      1.700000      2.688889      4.200000      4.700000      5.800000      3.300000      3.600000      3.900000      4.200000      3.300000      1.400000      2.783333      5.800000      4.400000      2.500000      3.300000      3.300000      2.200000      3.300000      3.300000      3.300000      2.500000      3.900000      2.921429      3.900000      3.900000      2.500000      3.100000      3.300000      4.200000      3.600000      3.012500      3.128571      3.600000      2.500000      2.200000      4.700000      2.500000      5.300000      2.500000      3.100000      3.276471      3.276471      6.100000   \n",
      "max            26.307381          29.159519         29.609585          27.030048          28.227129          27.728361          28.512505          26.828087          25.985081          26.754694     13.100000     11.400000      6.900000      8.600000      6.700000      6.400000      5.800000     16.100000     10.800000      7.500000     10.800000     11.563636      6.700000      4.890000      6.888889     10.300000     12.800000     12.500000      8.300000      8.900000      9.700000     10.300000      8.100000      5.300000      6.616667     16.400000     10.600000      8.300000      9.700000      9.200000      5.300000      8.900000      6.900000     10.600000      7.438462      8.900000      7.385714      8.100000      9.200000      6.700000      6.400000      9.200000     13.900000      8.600000      8.375000      7.414286     10.000000      6.400000      6.700000     10.600000      8.300000     14.700000      7.500000      8.100000      6.341176      6.341176     14.400000   \n",
      "\n",
      "       9377Y_Viento   9434_Viento  9573X_Viento   9677_Viento  9814X_Viento  9843A_Viento  9946X_Viento  B275E_Viento  B569X_Viento  B760X_Viento   B925_Viento  C148F_Viento  C249I_Viento  C619Y_Viento  C639M_Viento  C649R_Viento  C659H_Viento  C659M_Viento  0016A_Viento_pred  0201D_Viento_pred  0244X_Viento_pred  0367_Viento_pred  1025X_Viento_pred  1056K_Viento_pred  1074C_Viento_pred  1111X_Viento_pred  1186P_Viento_pred  1279X_Viento_pred  1387E_Viento_pred  1390X_Viento_pred  1466A_Viento_pred  1475X_Viento_pred  1719_Viento_pred  2044B_Viento_pred  2048A_Viento_pred  2331_Viento_pred  2734D_Viento_pred  2777K_Viento_pred  2873X_Viento_pred  2891A_Viento_pred  2946X_Viento_pred  3104Y_Viento_pred  3140Y_Viento_pred  3266A_Viento_pred  3475X_Viento_pred  3504X_Viento_pred  3526X_Viento_pred  3562X_Viento_pred  4096Y_Viento_pred  4340_Viento_pred  5390Y_Viento_pred  5402_Viento_pred  5582A_Viento_pred  5598X_Viento_pred  5612X_Viento_pred  5906X_Viento_pred  5972X_Viento_pred  \\\n",
      "count  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000       17544.000000       1.754400e+04       1.754400e+04      17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04       17544.000000      17544.000000       17544.000000       1.754400e+04      1.754400e+04       1.754400e+04       17544.000000       1.754400e+04       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000       1.754400e+04       17544.000000       1.754400e+04       17544.000000       1.754400e+04      17544.000000       17544.000000      17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000   \n",
      "mean       3.121012      4.441040      2.622982      5.154408      1.708892      0.937483      3.054909      3.074419      4.120703      1.700649      1.823556      2.839261      6.014727      5.543107      2.702736      3.959371      3.830369      2.082763           3.502574       3.054826e+00       2.093478e+00          2.863463       1.031352e+00           1.947906       1.150054e+00           4.654116       1.329484e+00           1.216716           4.068267           3.403831       1.678753e+00           1.519296          2.198826           3.432234       2.924124e+00      3.798754e+00       1.702220e+00           1.616963       2.679557e+00       2.796130e+00           2.397041           0.680294           1.508194           4.750925       4.087664e+00           1.673326       2.751048e+00           3.152891       1.360146e+00          2.693929           2.101242          2.395552       1.455887e+00           2.858989           2.199925           3.690791           3.308808   \n",
      "std        1.545910      2.550068      1.654951      2.781921      1.351560      0.592922      1.269931      1.080546      2.612561      1.030439      1.008613      0.851002      2.136947      2.465146      0.729031      1.510392      1.793071      1.014482           1.695044       1.493670e+00       1.106617e+00          1.273009       8.529574e-01           1.099124       1.121743e+00           1.841026       1.124715e+00           0.773667           1.821747           0.985485       1.100548e+00           0.652917          1.366796           1.412604       1.562717e+00      1.840021e+00       9.494523e-01           1.133712       1.908050e+00       1.630094e+00           1.200222           0.569684           0.698808           1.851237       1.682830e+00           0.939994       1.801133e+00           1.542633       5.819541e-01          1.265801           0.652193          1.080223       5.182822e-01           1.468373           0.983901           1.807052           1.223006   \n",
      "min        0.000000      0.300000      0.300000      0.000000      0.000000      0.000000      1.000000      0.300000      0.000000      0.000000      0.300000      1.100000      1.900000      1.100000      0.800000      0.600000      0.000000      0.000000           0.930373      -4.768372e-08      -7.152558e-08          0.872286      -2.384186e-08           0.393672      -3.576279e-08           0.618887      -1.192093e-08           0.071303           0.685538           1.405635       1.192093e-07           0.000000          0.029825           1.034376      -1.907349e-07     -9.536743e-08      -7.152558e-08           0.000000       2.384186e-07      -1.430512e-07           0.461356           0.000000           0.011601           0.111854      -1.430512e-07           0.463061      -9.536743e-08           0.007112       4.768372e-08          0.553799           0.618831          0.259464      -1.430512e-07           0.248019           0.247877           0.136652           0.615769   \n",
      "25%        1.900000      2.500000      1.400000      3.300000      0.800000      0.600000      2.157143      2.200000      2.500000      1.100000      1.100000      2.200000      4.200000      3.600000      2.200000      2.800000      2.500000      1.400000           2.405411       2.368129e+00       1.243448e+00          1.872667       4.505958e-01           1.246473       4.666421e-01           3.346554       5.983505e-01           0.624921           2.791798           2.727972       9.729265e-01           1.068194          1.314782           2.296774       1.915791e+00      2.469829e+00       9.161426e-01           0.888215       1.281017e+00       1.683555e+00           1.453040           0.288449           1.035524           3.574698       2.832839e+00           1.220018       1.523649e+00           2.026030       9.669124e-01          1.908180           1.707514          1.748925       1.116567e+00           1.741931           1.456883           2.225953           2.354108   \n",
      "50%        2.800000      3.900000      2.200000      4.400000      1.400000      0.800000      2.800000      3.100000      3.600000      1.700000      1.700000      2.800000      5.800000      5.000000      2.800000      4.200000      3.900000      1.900000           2.781387       2.737892e+00       1.924190e+00          2.575836       7.719551e-01           1.549044       7.707570e-01           4.129161       9.159085e-01           0.973346           3.551844           3.169767       1.406674e+00           1.439278          1.883941           3.198754       2.710014e+00      3.652136e+00       1.407724e+00           1.316244       2.184665e+00       2.514146e+00           2.066940           0.567969           1.456435           4.341561       3.938899e+00           1.437954       2.226022e+00           2.881435       1.221724e+00          2.378489           2.075264          2.219876       1.449691e+00           2.515260           2.007789           3.313184           3.170051   \n",
      "75%        3.900000      5.800000      3.300000      6.700000      2.200000      1.400000      3.528571      3.600000      5.000000      2.200000      2.200000      3.300000      7.500000      7.200000      3.100000      5.300000      5.000000      2.800000           4.146969       3.182052e+00       2.793903e+00          3.545115       1.386682e+00           2.299429       1.309654e+00           5.511336       1.702399e+00           1.620648           4.791794           3.857039       2.107288e+00           1.908223          2.564327           4.366620       3.613290e+00      4.851503e+00       2.292380e+00           1.969712       3.567029e+00       3.648388e+00           3.107151           0.911896           1.893628           5.522279       5.187990e+00           1.741781       3.467566e+00           3.971207       1.652332e+00          3.099040           2.300103          2.768104       1.791480e+00           3.701739           2.783813           4.985096           4.161756   \n",
      "max       10.300000     13.900000      9.700000     17.500000     10.300000      3.600000      8.057143      8.600000     21.700000      6.700000      7.200000      7.200000     13.100000     13.900000      6.900000      7.500000      9.200000      6.100000          12.013194       1.182693e+01       6.061497e+00          8.793547       6.915824e+00           8.135352       7.100425e+00          13.919512       8.171537e+00           4.751741          12.210758           8.745016       8.746185e+00           4.445849         11.506269           9.003029       1.116309e+01      1.325397e+01       6.073560e+00           9.335615       1.200705e+01       9.755122e+00           7.052167           4.059801           5.163090          12.833286       9.753407e+00          10.730083       1.459449e+01          10.061859       4.454509e+00          9.215698           5.481841          8.783508       3.435004e+00           9.332878           6.114094           9.133139           7.414166   \n",
      "\n",
      "       6045X_Viento_pred  6172X_Viento_pred  6268Y_Viento_pred  6307X_Viento_pred  6312E_Viento_pred  7066Y_Viento_pred  7195X_Viento_pred  7275C_Viento_pred  8025_Viento_pred  8036Y_Viento_pred  8177A_Viento_pred  8270X_Viento_pred  8486X_Viento_pred  8500A_Viento_pred  9016X_Viento_pred  9257X_Viento_pred  9301X_Viento_pred  9352A_Viento_pred  9377Y_Viento_pred  9434_Viento_pred  9573X_Viento_pred  9677_Viento_pred  9814X_Viento_pred  9843A_Viento_pred  9946X_Viento_pred  B275E_Viento_pred  B569X_Viento_pred  B760X_Viento_pred  B925_Viento_pred  C148F_Viento_pred  C249I_Viento_pred  C619Y_Viento_pred  C639M_Viento_pred  C649R_Viento_pred  C659H_Viento_pred  C659M_Viento_pred  Eolica_emi  Nuclear_emi    Carbon_emi  Ciclo_combinado_emi  Hidraulica_emi  Intercambios_int_emi  Solar_fotovoltaica_emi  Solar_termica_emi  Termica_renovable_emi  Motores_diesel_emi  Turbina_de_gas_emi  Turbina_de_vapor_emi  Generacion_auxiliar_emi  Cogeneracion_y_residuos_emi    Eolica_gen   Nuclear_gen  \\\n",
      "count       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000       17544.000000      17544.000000       17544.000000       1.754400e+04       1.754400e+04       17544.000000       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       17544.000000      1.754400e+04       1.754400e+04      1.754400e+04       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04      1.754400e+04       17544.000000       17544.000000       1.754400e+04       17544.000000       17544.000000       17544.000000       1.754400e+04     17544.0      17544.0  17544.000000         17544.000000         17544.0               17544.0                 17544.0            17544.0                17544.0        17544.000000        17544.000000          17544.000000             17544.000000                 17544.000000  17544.000000  17544.000000   \n",
      "mean            1.865158           2.709366           2.700732           3.124711           2.082592           2.394795           2.359891           2.875419          1.823194           2.372697       2.661456e+00       1.454021e+00           4.561255           2.352710       1.669170e+00           2.366235           2.211951           3.988125           2.755274      2.581999e+00       1.889652e+00      5.608468e+00           0.998021       5.037560e-01           2.322657           2.528423           4.950884       1.108113e+00      1.501856e+00           2.504380           6.561965       5.255149e+00           2.306585           3.848910           3.826168       5.093732e-01         0.0          0.0    406.556498          1951.771719             0.0                   0.0                     0.0                0.0                    0.0          197.824544           84.262332            129.414878                -0.481487                   522.167362   7090.423424   6131.148199   \n",
      "std             0.658790           1.206750           1.581191           1.412589           0.965062           0.716391           1.203238           1.405209          0.932994           0.963338       1.129467e+00       1.092955e+00           2.559706           0.856766       8.571942e-01           0.986332           0.721111           1.506682           1.103817      1.837516e+00       1.382891e+00      1.963084e+00           0.900788       4.543699e-01           1.237326           0.989330           1.867884       8.823155e-01      7.857791e-01           0.693882           1.257182       1.751829e+00           0.910522           1.123061           0.925837       5.921536e-01         0.0          0.0    186.870420          1092.248812             0.0                   0.0                     0.0                0.0                    0.0           42.098668           53.934862             37.745711                 5.084623                   108.430299   4070.266947    967.099452   \n",
      "min             0.092406           0.035823           0.204197           0.389800           0.930947           1.114078           0.302807           0.480837          0.008742           0.560222       1.430512e-07      -1.192093e-07           0.519294           0.000000       2.384186e-08           0.448436           0.865277           0.226453           0.082034     -4.768372e-08       4.768372e-08     -1.907349e-07           0.103416      -5.960465e-09           0.297869           0.985805           0.042060      -1.430512e-07     -1.430512e-07           0.300860           2.192507      -5.722046e-07           0.524536           0.519669           1.024795      -2.980232e-09         0.0          0.0      0.000000           420.000000             0.0                   0.0                     0.0                0.0                    0.0           97.000000            0.000000             50.000000               -10.200000                   248.000000    230.000000   3182.000000   \n",
      "25%             1.366765           1.847467           1.416246           2.015932           1.463399           1.868325           1.426366           1.848651          1.092009           1.531584       1.870265e+00       7.085955e-01           2.800054           1.724072       9.915155e-01           1.600827           1.665384           2.985022           1.904739      1.374174e+00       9.178240e-01      4.067207e+00           0.459281       2.687879e-01           1.455889           1.813106           3.851011       3.747150e-01      9.619623e-01           2.060631           5.673308       3.950123e+00           1.532702           3.081089           3.189215       1.034051e-02         0.0          0.0    248.000000          1087.000000             0.0                   0.0                     0.0                0.0                    0.0          166.000000           40.000000            109.000000                -2.000000                   443.000000   3825.750000   5206.000000   \n",
      "50%             1.774779           2.439348           2.363294           2.847945           1.606271           2.244938           2.075258           2.512853          1.578446           2.233920       2.620764e+00       1.198556e+00           3.677251           2.166882       1.422052e+00           2.190168           2.030777           3.765626           2.596174      2.136026e+00       1.377830e+00      5.329531e+00           0.672981       3.911455e-01           1.853972           2.094728           4.630023       1.009905e+00      1.387929e+00           2.473274           6.509245       5.252019e+00           2.083751           3.902415           3.735010       3.078863e-01         0.0          0.0    339.000000          1643.000000             0.0                   0.0                     0.0                0.0                    0.0          199.000000           71.000000            117.000000                 0.000000                   541.500000   6394.000000   6470.000000   \n",
      "75%             2.330174           3.299323           3.647673           3.954103           2.421060           2.796731           3.105172           3.603674          2.447649           3.056704       3.338524e+00       1.948196e+00           5.403150           2.775839       2.222895e+00           2.959257           2.598284           4.713784           3.447564      3.253609e+00       2.525415e+00      7.118515e+00           1.114335       5.253567e-01           2.841559           3.121076           5.718204       1.731261e+00      1.972326e+00           2.899246           7.370386       6.477822e+00           3.090322           4.676681           4.352696       7.671019e-01         0.0          0.0    500.000000          2612.250000             0.0                   0.0                     0.0                0.0                    0.0          228.000000          118.000000            151.000000                 0.000000                   606.000000   9766.000000   6979.000000   \n",
      "max             4.292424           9.071002           8.903175           8.937109           8.299777           5.431123           7.718726           9.267033          6.522239           6.503942       7.043380e+00       7.540772e+00          15.620208           7.392799       6.813485e+00           6.996884           5.639403          16.023735           7.899948      1.191945e+01       8.143102e+00      1.232651e+01           6.648502       4.145511e+00           7.476842           6.823880          13.377789       7.241610e+00      4.769161e+00           6.410732          11.299067       1.041230e+01           5.309681           6.897284           7.968153       3.296067e+00         0.0          0.0    878.000000          4886.000000             0.0                   0.0                     0.0                0.0                    0.0          321.000000          230.000000            216.000000               156.000000                   754.000000  18649.500000   7119.000000   \n",
      "\n",
      "         Carbon_gen  Ciclo_combinado_gen  Hidraulica_gen  Intercambios_int_gen  Solar_fotovoltaica_gen  Solar_termica_gen  Termica_renovable_gen  Motores_diesel_gen  Turbina_de_gas_gen  Turbina_de_vapor_gen  Generacion_auxiliar_gen  Cogeneracion_y_residuos_gen          Real      Prevista    Programada      Asturias     Cantabria       Navarra    País Vasco      Cataluña        Aragón       Galicia  Islas Baleares      La Rioja      Valencia  Castilla y León  Castilla La Mancha   Extremadura     Andalucía        Murcia        Madrid  Solar_altitude    is_weekend  Real_1day_before  Real_2days_before  Real_3days_before  \n",
      "count  17544.000000         17544.000000    17544.000000          17544.000000            17544.000000       17544.000000           17544.000000        17544.000000        17544.000000          17544.000000             17544.000000                 17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000  17544.000000    17544.000000  17544.000000  17544.000000     17544.000000        17544.000000  17544.000000  17544.000000  17544.000000  17544.000000    17544.000000  17544.000000      17544.000000       17544.000000       17544.000000  \n",
      "mean     442.173906          5022.660454     2833.230186          -1608.621751             4404.033915         493.703575             435.113657          290.902189           84.615310            144.657832                -0.711069                  1868.015105  27876.522344  27900.049191  27933.161423      0.547439      0.584148      0.539761      0.619689      0.497620      0.451877      0.556311        0.443983      0.517853      0.425188         0.485263            0.405453      0.392776      0.350409      0.378957      0.407795       15.710192      0.285910      27870.075296       27870.804264       27878.937642  \n",
      "std      244.423468          3056.857537     3010.507817           2155.902834             5678.263321         576.136772              91.264443           61.953186           75.847646             44.425835                 7.476221                   387.460523   4438.707024   4423.429476   4456.988054      0.370360      0.379620      0.382336      0.381871      0.325386      0.347191      0.358586        0.341983      0.395463      0.332800         0.343812            0.348163      0.378472      0.323767      0.369518      0.403726       20.564777      0.451859       4440.285492        4440.662727        4438.893446  \n",
      "min        0.000000           958.000000    -3732.000000          -8088.000000                0.000000           0.000000             188.000000           71.000000           -4.000000              0.000000               -15.000000                    33.000000  17180.000000  17236.000000  17065.000000      0.000000      0.002832      0.000000      0.000000      0.000439      0.000000      0.001197        0.000000      0.000000      0.000000         0.000000            0.000000      0.000000      0.001261      0.000000      0.000000        0.000000      0.000000      17180.000000       17180.000000       17180.000000  \n",
      "25%      261.000000          2669.000000      673.750000          -3192.000000               24.000000          15.000000             394.000000          244.000000           41.000000            121.000000                -3.000000                  1586.000000  24149.750000  24204.750000  24191.750000      0.173597      0.186881      0.139870      0.222861      0.191865      0.118682      0.195149        0.125383      0.077836      0.117411         0.148319            0.064437      0.018908      0.057680      0.039104      0.004422        0.000000      0.000000      24144.750000       24144.750000       24154.000000  \n",
      "50%      357.000000          4147.000000     2579.000000          -1516.000000              203.000000         239.000000             442.000000          293.000000           71.000000            130.000000                 0.000000                  1937.000000  27946.500000  27970.500000  28028.000000      0.586003      0.685937      0.587515      0.769590      0.459378      0.394526      0.607348        0.380752      0.557221      0.352902         0.458889            0.329503      0.269328      0.238653      0.231769      0.266267        1.721577      0.000000      27930.500000       27930.500000       27946.000000  \n",
      "75%      526.000000          6748.250000     4885.250000            -13.750000             9150.000000         746.000000             490.000000          336.000000          115.000000            168.000000                 0.000000                  2167.000000  31099.000000  31118.000000  31178.250000      0.932515      0.966022      0.941814      0.982746      0.810274      0.790150      0.916627        0.763804      0.941529      0.726136         0.826517            0.735617      0.777061      0.620561      0.734781      0.861734       28.918652      1.000000      31097.000000       31101.000000       31113.250000  \n",
      "max     4820.000000         17969.000000    11363.500000           5240.000000            20278.000000        1855.000000            5418.000000          475.000000         5512.000000            279.000000               229.000000                  2697.000000  41281.000000  41358.000000  41108.000000      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000        1.000000      1.000000      1.000000         1.000000            1.000000      1.000000      1.000000      1.000000      1.000000       72.814595      1.000000      41281.000000       41281.000000       41281.000000  \n",
      "Index(['Ano', 'Mes', 'Dia', 'Hora', 'Minuto', '0016A_Altitud', '0201D_Altitud', '0244X_Altitud', '0367_Altitud', '1025X_Altitud',\n",
      "       ...\n",
      "       'Castilla La Mancha', 'Extremadura', 'Andalucía', 'Murcia', 'Madrid', 'Solar_altitude', 'is_weekend', 'Real_1day_before', 'Real_2days_before', 'Real_3days_before'], dtype='object', length=583)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735056784.883835   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056784.938215   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056784.938533   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056784.939174   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056784.939410   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056784.939612   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056785.030883   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735056785.031196   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 16:13:05.031342: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1735056785.031469   22780 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 16:13:05.031627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)             \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m       Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to          \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001B[94mInputLayer\u001B[0m)  │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │              \u001B[32m0\u001B[0m │ -                      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ multi_head_attention      │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │      \u001B[32m6,412,400\u001B[0m │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],     │\n",
      "│ (\u001B[94mMultiHeadAttention\u001B[0m)      │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],     │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_1 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │              \u001B[32m0\u001B[0m │ multi_head_attention[\u001B[32m…\u001B[0m │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ add (\u001B[94mAdd\u001B[0m)                 │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │              \u001B[32m0\u001B[0m │ dropout_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],       │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ layer_normalization       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │            \u001B[32m800\u001B[0m │ add[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]              │\n",
      "│ (\u001B[94mLayerNormalization\u001B[0m)      │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d (\u001B[94mConv1D\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │        \u001B[32m205,312\u001B[0m │ layer_normalization[\u001B[32m0\u001B[0m… │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_2 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)      │              \u001B[32m0\u001B[0m │ conv1d[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]           │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ conv1d_1 (\u001B[94mConv1D\u001B[0m)         │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │        \u001B[32m205,200\u001B[0m │ dropout_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ add_1 (\u001B[94mAdd\u001B[0m)               │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │              \u001B[32m0\u001B[0m │ conv1d_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m],        │\n",
      "│                           │                        │                │ input_layer[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]      │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ layer_normalization_1     │ (\u001B[96mNone\u001B[0m, \u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)      │            \u001B[32m800\u001B[0m │ add_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "│ (\u001B[94mLayerNormalization\u001B[0m)      │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ global_average_pooling1d  │ (\u001B[96mNone\u001B[0m, \u001B[32m400\u001B[0m)            │              \u001B[32m0\u001B[0m │ layer_normalization_1… │\n",
      "│ (\u001B[94mGlobalAveragePooling1D\u001B[0m)  │                        │                │                        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense (\u001B[94mDense\u001B[0m)             │ (\u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)            │        \u001B[32m205,312\u001B[0m │ global_average_poolin… │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_3 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m512\u001B[0m)            │              \u001B[32m0\u001B[0m │ dense[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]            │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_1 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)            │         \u001B[32m65,664\u001B[0m │ dropout_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_4 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m128\u001B[0m)            │              \u001B[32m0\u001B[0m │ dense_1[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_2 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m32\u001B[0m)             │          \u001B[32m4,128\u001B[0m │ dropout_4[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dropout_5 (\u001B[94mDropout\u001B[0m)       │ (\u001B[96mNone\u001B[0m, \u001B[32m32\u001B[0m)             │              \u001B[32m0\u001B[0m │ dense_2[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ dense_3 (\u001B[94mDense\u001B[0m)           │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │             \u001B[32m33\u001B[0m │ dropout_5[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]        │\n",
      "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
      "│ concatenate (\u001B[94mConcatenate\u001B[0m) │ (\u001B[96mNone\u001B[0m, \u001B[32m1\u001B[0m)              │              \u001B[32m0\u001B[0m │ dense_3[\u001B[32m0\u001B[0m][\u001B[32m0\u001B[0m]          │\n",
      "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
      "\u001B[1m Total params: \u001B[0m\u001B[32m7,099,649\u001B[0m (27.08 MB)\n",
      "\u001B[1m Trainable params: \u001B[0m\u001B[32m7,099,649\u001B[0m (27.08 MB)\n",
      "\u001B[1m Non-trainable params: \u001B[0m\u001B[32m0\u001B[0m (0.00 B)\n",
      "x_batch shape: (60, 60, 400)\n",
      "y_batch shape: (60, 1)\n",
      "x_batch shape: (60, 60, 400)\n",
      "y_batch shape: (60, 1)\n",
      "Epoch 1/10\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735056790.525950   22831 service.cc:146] XLA service 0x7aede4033480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735056790.526011   22831 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-24 16:13:10.628836: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-24 16:13:11.102868: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1735056799.823702   22831 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "    145/Unknown \u001B[1m22s\u001B[0m 62ms/step - loss: 0.7381 - mae: 0.65172024-12-24 16:13:28.820662: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-24 16:13:28.820721: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-24 16:13:28.820756: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:13:28.820785: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-24 16:13:35.652653: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-24 16:13:35.652707: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:13:35.652732: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 109ms/step - loss: 0.7362 - mae: 0.6510 - val_loss: 0.4275 - val_mae: 0.5370\n",
      "Epoch 2/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - loss: 0.3621 - mae: 0.51042024-12-24 16:14:00.554939: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:00.554998: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:14:03.554491: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-24 16:14:03.554566: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:03.554587: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 98ms/step - loss: 0.3618 - mae: 0.5101 - val_loss: 0.4144 - val_mae: 0.5332\n",
      "Epoch 3/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step - loss: 0.3052 - mae: 0.46512024-12-24 16:14:15.148725: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:15.148802: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:14:18.125733: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:18.125806: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 84ms/step - loss: 0.3049 - mae: 0.4648 - val_loss: 0.4208 - val_mae: 0.5174\n",
      "Epoch 4/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.2655 - mae: 0.42742024-12-24 16:14:35.370718: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:35.370797: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:14:39.527223: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-24 16:14:39.527277: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:39.527306: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 97ms/step - loss: 0.2652 - mae: 0.4271 - val_loss: 0.4209 - val_mae: 0.5158\n",
      "Epoch 5/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.2378 - mae: 0.40162024-12-24 16:14:55.931233: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:55.931311: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:14:58.900314: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:14:58.900378: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 83ms/step - loss: 0.2375 - mae: 0.4013 - val_loss: 0.3761 - val_mae: 0.4902\n",
      "Epoch 6/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 0.1986 - mae: 0.36372024-12-24 16:15:16.269365: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:15:16.269431: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:15:20.604976: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:15:20.605024: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 97ms/step - loss: 0.1984 - mae: 0.3635 - val_loss: 0.4422 - val_mae: 0.5277\n",
      "Epoch 7/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - loss: 0.1838 - mae: 0.35032024-12-24 16:15:36.887792: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:15:36.887866: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:15:39.886544: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:15:39.886625: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 84ms/step - loss: 0.1836 - mae: 0.3501 - val_loss: 0.4191 - val_mae: 0.5106\n",
      "Epoch 8/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - loss: 0.1823 - mae: 0.34182024-12-24 16:15:57.150753: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:15:57.150815: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:16:01.348816: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-24 16:16:01.348892: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:16:01.348931: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 91ms/step - loss: 0.1821 - mae: 0.3416 - val_loss: 0.3946 - val_mae: 0.5025\n",
      "Epoch 9/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - loss: 0.1543 - mae: 0.31572024-12-24 16:16:17.846159: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:16:17.846234: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:16:20.798236: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:16:20.798297: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 83ms/step - loss: 0.1542 - mae: 0.3155 - val_loss: 0.4111 - val_mae: 0.5061\n",
      "Epoch 10/10\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - loss: 0.1519 - mae: 0.31392024-12-24 16:16:30.103813: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:16:30.103865: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "2024-12-24 16:16:33.581260: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10196664899587344447\n",
      "2024-12-24 16:16:33.581315: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8321748073099160658\n",
      "\u001B[1m145/145\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - loss: 0.1518 - mae: 0.3138 - val_loss: 0.4497 - val_mae: 0.5296\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 26ms/step\n",
      "Figure(1000x600)\n",
      "Figure(1200x500)\n",
      "Mean Absolute Percentage Error (MAPE):\n",
      "   Real_MAPE\n",
      "0  12.450274\n",
      "Figure(1200x1000)\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/intro.ipynb",
     "timestamp": 1732171526223
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
